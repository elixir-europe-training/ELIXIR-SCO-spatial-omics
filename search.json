[
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "Overview",
    "text": "Overview\nThis course delves into the cutting-edge field of Spatial Omics, focusing on Spatially-Resolved Transcriptomics (SRT) technology which provides unprecedented insights into the spatial organization of gene expression within tissues. The rapid and recent advances in SRT technology are transforming our understanding of biological systems, and this course is designed to equip researchers with the tools to harness the power of SRT, adding significant value to biological knowledge and opening new avenues for scientific discovery.\nParticipants will explore both imaging-based and sequencing-based SRT technologies, learning to navigate the entire workflow of SRT data analysis. The course covers essential topics such as pre-processing techniques for data cleaning, normalization, and quality control, methods for identifying and characterizing spatial domains within tissues, strategies for integrating SRT data with single-cell RNA sequencing data, and statistical approaches to analyze spatial patterns and relationships. Additionally, participants will investigate interactions between cells within their spatial context. By the end of this course, participants will be equipped with the knowledge and skills to construct a complete workflow for SRT data analysis, from raw data to meaningful biological insights. The course combines lectures with practical sessions, ensuring a balanced approach to theory and hands-on experience.\nThe course materials will be on the dedicated GitHub page."
  },
  {
    "objectID": "index.html#audience",
    "href": "index.html#audience",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "Audience",
    "text": "Audience\nThis 3-day course is addressed to PhD students, postdocs, and researchers who are involved (or will be in the near future) in projects including spatially-resolved transcriptomics data, and want to acquire the skills to get started with spatial data analysis."
  },
  {
    "objectID": "index.html#learning-outcomes",
    "href": "index.html#learning-outcomes",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "Learning outcomes",
    "text": "Learning outcomes\nAt the end of the course, the participants will be able to:\n\nIdentify and recall key concepts and terminology related to imaging- and sequencing-based SRT technologies.\nAssess and evaluate quality of SRT data.\nPerform standard SRT data analysis, including data cleaning, normalization, quality control.\nExamine and interpret spatial patterns and relationships within SRT data using statistical and machine learning approaches.\nConstruct a comprehensive workflow for SRT data analysis, from raw data to meaningful biological insights."
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nKnowledge / competencies\nParticipants should be proficient in Python and R, for basic data analysis.\nParticipants should be familiar with NGS technologies, have experience with analyzing (spatial/single-cell) transcriptomics data as well as basic knowledge of machine learning.\nParticipants should also have a basic understanding of working with command line tools on Unix-based systems. You can test your skills with Unix with the quiz here. If you do not feel comfortable with UNIX commands, please take our Unix fundamentals e-learning module.\n\n\nTechnical\nParticipants are required to bring your own laptop.\nWe will be mainly working on an Amazon Web Services (AWS) Elastic Cloud (EC2) server. Our Ubuntu server behaves like a ‘normal’ remote server, and can be approached through a web browser (safari, firefox, chrome etc.). All participants will be granted access to a personal workspace to be used during the course. The web interface will be approached through http (not https!), so make sure you can access http sites. You can validate it here.\nPlease perform these installations PRIOR to the course and contact us if you have any trouble."
  },
  {
    "objectID": "index.html#schedule---cet-time-zone",
    "href": "index.html#schedule---cet-time-zone",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "Schedule - CET time zone",
    "text": "Schedule - CET time zone\nDay 1 (13:00 -17:00)\n\nOverview of technologies\nImaging-based data preprocessing\nSegmentation-free analysis\n\nDay 2 (09:00 -17:00)\n\nSequence-based data preprocessing\nIntegration with scRNA-seq\nMulti-omics spatial data analysis\n\nDay 3 (09:00 -17:00)\n\nGraph representations and Niche reconstruction\nSpatial domain identification/spatial annotation\nSpatial statistics\n\nDay 4 (09:00 -12:30)\n\nCell-cell communication"
  },
  {
    "objectID": "index.html#the-trainers",
    "href": "index.html#the-trainers",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "The trainers",
    "text": "The trainers\nThe course will feature the following lecturers and trainers:\n\nLars Borm (Katholieke Universiteit (KU) Leuven & Vlaams Instituut voor Biotechnologie (VIB), BE)\nHelena Crowell (Centro Nacional de Análisis Genómico (CNAG), ES)\nFrancesca Drummer (Helmholtz Zentrum München, DE)\nGeorge Gavrillidis (Centre for Research and Technology Hellas (CERTH), GR)\nGeert van Geest (SIB Swiss Institute of Bioinformatics, CH)\nNaveed Ishaque (Berlin Institute of Health (BIH), DE)\nAhmed Mahfouz (Leiden University Medical Center (LUMC), NL)\nMark Robinson (University of Zurich (UZH) & SIB, CH)\nYvan Saeys (University of Ghent (UGent) & Vlaams Instituut voor Biotechnologie (VIB), BE)\nRasool Saghaleyni (SciLifeLab, SE)\nAnna Schaar (Helmholtz Zentrum München, DE)\nMarco Varrone (University of Lausanne (UNIL) & SIB, CH)"
  },
  {
    "objectID": "index.html#application",
    "href": "index.html#application",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "Application",
    "text": "Application\nRegistration fees are 150 CHF for academics and 750 CHF for for-profit companies.\nParticipants will be selected based on several criteria. Selection criteria include correct entry requirements, motivation to attend the course as well as gender and ELIXIR nodes balance.\nTo apply to this course and enter the selection process, please fill in this questionnaire.\nApplications will close 01/11/2024. The applications selection will start the week of the 05/11/2024. Accepted applicants will be notified by email by during the week of the 11/11/2024 and they will have until 27/11/2024 to confirm their attendance by paying the fees within 5 days.\nDeadline for free-of-charge cancellation is set to 27/11/2024. Cancellation after this date will not be reimbursed."
  },
  {
    "objectID": "index.html#venue-and-time",
    "href": "index.html#venue-and-time",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "Venue and Time",
    "text": "Venue and Time\nThis course will take place at the University of Lausanne, in the Synathlon building of the campus.\nThe course will start the first day at 13:00. A lunch will be provided before the start of the course as well as at the end of the course on the last day.\nAll participants are invited to the social dinner, organized on 21 January 2024.\nPrecise information will be provided to the participants in due time."
  },
  {
    "objectID": "index.html#additional-information",
    "href": "index.html#additional-information",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "Additional information",
    "text": "Additional information\nThis is an international course hosted by the SIB Swiss Institute of Bioinformatics (ELIXIR-CH) in collaboration with the ELIXIR Single-Cell Omics community, and trainers’ own institutions and affiliations to ELIXIR nodes (KU Leuven, VIB, CNAG, Helmholtz Zentrum München, CERTH, SIB, BIH, LUMC, UZH, UGent, SciLifeLab, UNIL).\nCourse organizers:\n\nAhmed Mahfouz, Leiden University Medical Center (LUMC), ELIXIR - Netherlands\nDiana Marek, SIB Training group, ELIXIR - Switzerland\nPatricia Palagi, SIB Training group, ELIXIR - Switzerland\nEija Korpelainen, CSC, ELIXIR - Finland\n\nThis course is partially funded by an ELIXIR Staff Exchange Programme.\nWe will recommend 0.75 ECTS credits for this course (given a passed assessment).\nYou are welcome to register to the SIB courses mailing list to be informed of all future courses and workshops, as well as all important deadlines using the form here.\nPlease note that participation in SIB courses is subject to our general conditions.\nCourse organizers and trainers abide by the ELIXIR Code of Conduct. Participants are also required to abide by the same code."
  },
  {
    "objectID": "day_2/practical_3/workdir/practical_3.html",
    "href": "day_2/practical_3/workdir/practical_3.html",
    "title": "Computational analysis of spatial transcriptomics data",
    "section": "",
    "text": "1. Spatial data download and format\n2. Spatial imputation with SpaGE\n3. Spatial clusering with BANKSY\n4. Cell-cell communication with LIANA+"
  },
  {
    "objectID": "day_2/practical_3/workdir/practical_3.html#brainomics-2.0---day-3",
    "href": "day_2/practical_3/workdir/practical_3.html#brainomics-2.0---day-3",
    "title": "Computational analysis of spatial transcriptomics data",
    "section": "",
    "text": "1. Spatial data download and format\n2. Spatial imputation with SpaGE\n3. Spatial clusering with BANKSY\n4. Cell-cell communication with LIANA+"
  },
  {
    "objectID": "day_1/practical_1/data/READM.html",
    "href": "day_1/practical_1/data/READM.html",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "",
    "text": "Download and extract the data from the following link:\nhttps://cf.10xgenomics.com/samples/xenium/1.4.0/Xenium_V1_FFPE_TgCRND8_17_9_months/Xenium_V1_FFPE_TgCRND8_17_9_months_outs.zip"
  },
  {
    "objectID": "day_1/practical_1/practical_1_2.html",
    "href": "day_1/practical_1/practical_1_2.html",
    "title": "Loading packages",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\nimport seaborn as sns\nimport scanpy as sc\nimport squidpy as sq\nimport scipy.sparse as sp\nfrom scipy.stats import gaussian_kde\nfrom scipy.signal import find_peaks, argrelextrema\nfrom scipy.sparse import issparse, csr_matrix\nfrom diptest import diptest\nimport statsmodels.api as sm\nfrom shapely.geometry import Point, Polygon, MultiPoint\nfrom scipy.spatial import ConvexHull\nimport sys\nsys.path.append('custom')\nimport tenx_method_nb_helper_functions as hf"
  },
  {
    "objectID": "day_1/practical_1/practical_1_2.html#loading-data-and-primary-inspections",
    "href": "day_1/practical_1/practical_1_2.html#loading-data-and-primary-inspections",
    "title": "Loading packages",
    "section": "Loading data and primary inspections",
    "text": "Loading data and primary inspections\nMaking adata object considering the transcripts that should be used for the analysis. Running analysis on the transcripts that are only in the nucleus.\n\nsample_path = \"data/Xenium_V1_FFPE_TgCRND8_17_9_months_outs\"\ntranscripts_csv_path = os.path.join(sample_path, \"transcripts.csv.gz\")\ntranscripts_df = pd.read_csv(transcripts_csv_path, compression='gzip')\nnucleus_boundaries_gz_path = os.path.join(sample_path, \"nucleus_boundaries.csv.gz\")\nnucleus_df = pd.read_csv(nucleus_boundaries_gz_path, compression='gzip')\n\n\nMaking the adata object\n\nif not os.path.exists(os.path.join(sample_path, \"cells.csv\")):\n    hf.decompress_file(os.path.join(sample_path, \"cells.csv.gz\"))\nadata = hf.create_adata(sample_path, nucleus_genes_only = False)\nadata\n\nAnnData object with n_obs × n_vars = 62268 × 347\n    obs: 'cell_id', 'x_centroid', 'y_centroid', 'transcript_counts', 'control_probe_counts', 'control_codeword_counts', 'unassigned_codeword_counts', 'total_counts', 'cell_area', 'nucleus_area'\n    var: 'gene_ids', 'feature_types', 'genome'\n    obsm: 'spatial'\n\n\nThe AnnData object, adata, contains a structured dataset with cells as observations (n_obs = 62268) and genes as variables (n_vars = 347). Here’s a breakdown of the main components within adata:\nobs (Observations): This table contains metadata about each cell, where each row corresponds to a cell, and each column holds information about a specific attribute:\n\ncell_id: Unique identifier for each cell.\nx_centroid and y_centroid: Coordinates of each cell’s center in the spatial layout, indicating where each cell is located within the tissue.\ntranscript_counts: Total transcript counts for each cell, showing the overall gene expression level.\ncontrol_probe_counts and control_codeword_counts: Counts related to control probes and codewords, which are often used for quality control in spatial transcriptomics.\nunassigned_codeword_counts and deprecated_codeword_counts: Counts of unassigned or deprecated codewords, indicating low-confidence or outdated identifiers.\ntotal_counts: Total counts across all measured attributes, representing the cell’s total signal.\ncell_area and nucleus_area: Physical measurements of the cell and its nucleus area, in pixels or micrometers.\n\nvar (Variables): This table contains metadata about each gene, where each row is a gene and each column is an attribute:\n\ngene_ids: Unique identifiers for each gene, often in Ensembl or another standardized format.\nfeature_types: Type of feature associated with each gene, such as “gene” or “transcript.”\ngenome: Information about the genome source of each gene, like “human” or “mouse.”\n\nobsm (Multi-dimensional Observations): This slot contains multi-dimensional data related to cells. Here, spatial stores spatial coordinates for each cell, allowing visualization and spatial analysis of cells in their tissue context.\n\nadata.obs['total_counts'] = adata.X.sum(axis=1)\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['total_counts'], kde=True, bins=50)\nplt.xlabel(\"Total Transcript Counts per Cell\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Total Transcript Counts per Cell\")\nplt.show()\n\n\n\n\n\n\n\n\nWe calculate the total transcript counts for each cell by summing gene expression values across all genes and the number of genes detected in each cell. The resulting distributions gives us an overview of the data quality and cellular diversity in terms of RNA content.\nThese provide a measure of each cell’s transcriptional activity or RNA content. High total counts typically indicate cells with higher transcriptional activity, while very low total counts may suggest low-quality cells or empty spots with minimal RNA. Examining this distribution helps us assess data quality and identify potential outliers:\n\nCells with Very Low Counts: These may represent low-quality cells or background noise, which could be filtered out in subsequent steps to improve analysis accuracy.\nCells with Very High Counts: High total counts may indicate cell types with naturally high transcriptional activity or potential doublets (two cells counted as one).\n\nThis plot provides a quick check of the dataset’s quality and helps inform any initial filtering steps. A typical goal is to ensure the data has a reasonable distribution of RNA counts per cell, without excessive noise or artifacts that might skew downstream analysis.\n\nadata.obs['n_genes'] = (adata.X &gt; 0).sum(axis=1)\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['n_genes'], kde=True, bins=50)\nplt.xlabel(\"Number of Genes Detected per Cell\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Genes Detected per Cell\")\nplt.show()\n\n\n\n\n\n\n\n\nNow lets find genes with the highest expression across the whole dataset. We calculate the mean expression level of each gene across all cells and identify the top 10 most highly expressed genes, then plot them to understand which genes dominate the transcriptional landscape. This helps us quickly identify genes with the highest abundance, which are often either essential housekeeping genes or specific markers that define particular cell types. Examining the top expressed genes serves both technical and biological purposes: it allows us to check for any potential technical artifacts (e.g., genes with unusually high background expression) and offers biological insight by highlighting key genes likely involved in core cellular functions or distinguishing cell types.\n\n#calculate mean expression for each gene\nmean_expression = adata.X.mean(axis=0).A1\ntop_genes_idx = mean_expression.argsort()[::-1][:10]\ntop_genes = adata.var_names[top_genes_idx]\ntop_expression = mean_expression[top_genes_idx]\nplt.figure(figsize=(10, 5))\nsns.barplot(x=top_genes, y=top_expression)\nplt.xlabel(\"Genes\")\nplt.ylabel(\"Mean Expression\")\nplt.title(\"Top 10 Most Expressed Genes\")\nplt.xticks(rotation=45)\nplt.show()\n\n\n\n\n\n\n\n\nWe can also look into the distributions of cell and nucleus areas to assess segmentation quality and examine cell size diversity across the dataset. These distributions provide an overview of the range of cell and nucleus sizes, helping to identify segmentation artifacts or inconsistencies, such as unusually small areas (which may indicate partial cells or segmentation errors) or large areas (potentially indicating doublets or merged cells).\n\n#distribution of cell and nucleus areas\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['cell_area'], kde=True, bins=50)\nplt.xlabel(\"Cell Area\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Cell Areas\")\nplt.show()\n\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['nucleus_area'], kde=True, bins=50)\nplt.xlabel(\"Nucleus Area\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Nucleus Areas\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCell Area vs Nucleus Area\n\nplt.figure(figsize=(8, 6))\nplt.scatter(adata.obs['cell_area'], adata.obs['nucleus_area'], alpha=0.5)\nplt.xlabel(\"Cell Area\")\nplt.ylabel(\"Nucleus Area\")\nplt.title(\"Cell Area vs Nucleus Area\")\nplt.show()\n\n\n\n\n\n\n\n\nCalculate cell-to-nucleus area ratio and plot it. This ratio provides a measure of the relative size of the nucleus compared to the whole cell, which can be informative for understanding cell morphology and the distribution of nuclear material within cells. A high ratio may indicate cells with large nuclei relative to their overall size, which could be relevant for cell type classification or biological interpretation. Examining this ratio helps identify potential outliers or unusual cell morphologies that may require further investigation or filtering.\n\nadata.obs['area_ratio'] = adata.obs['nucleus_area'] / adata.obs['cell_area']\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['area_ratio'], kde=True, bins=50)\nplt.xlabel(\"Nucleus-to-Cell Area Ratio\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Nucleus-to-Cell Area Ratios\")\nplt.show()\n\n\n\n\n\n\n\n\nScatter plot of Cell Area vs Total Counts\n\nplt.figure(figsize=(8, 6))\nplt.scatter(adata.obs['cell_area'], adata.obs['total_counts'], alpha=0.5)\nplt.xlabel(\"Cell Area\")\nplt.ylabel(\"Total Transcript Counts\")\nplt.title(\"Cell Area vs Total Transcript Counts\")\nplt.show()\n\n\n\n\n\n\n\n\nSpatial plot of cell and nucleus areas.\n\n#cell area\nsc.pl.spatial(adata, color='cell_area', spot_size=10, title=\"Spatial Distribution of Cell Area\")\n#nucleus area\nsc.pl.spatial(adata, color='nucleus_area', spot_size=10, title=\"Spatial Distribution of Nucleus Area\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLooking to spatial distibution of one of the genes. For example the gene “MALL”\n\nsc.pl.spatial(adata, color=['Cst3'], spot_size=10, title=\"Cst3 Gene Expression\")\n\n\n\n\n\n\n\n\n\n# Filter cells with nucleus area &lt; 5\ninitial_cells_count = adata.n_obs\nadata = adata[adata.obs['nucleus_area'] &gt;= 5].copy()\nfiltered_cells_count = adata.n_obs\nprint(f\"Filtered out {initial_cells_count - filtered_cells_count} cells with nucleus_area &lt; 5. Remaining cells: {filtered_cells_count}\")\n\nFiltered out 314 cells with nucleus_area &lt; 5. Remaining cells: 61954\n\n\nPlot distribution of total transcript counts per cell and distribution of Nucleus area after filtering\n\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['total_counts'], kde=True, bins=50)\nplt.xlabel(\"Total Transcript Counts per Cell\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Total Transcript Counts per Cell After Filtering\")\nplt.show()\n\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['nucleus_area'], kde=True, bins=50)\nplt.xlabel(\"Nucleus Area\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Nucleus Area After Filtering\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwe can also look into the control probe counts and their spatial distribution to assess background noise and technical quality in the dataset. First, we plot the distribution of control probe counts across cells to understand how frequently control probes are detected. This distribution provides insights into potential technical noise or background signals, as higher-than-expected control counts may suggest artifacts or contamination. Next, we create a spatial plot of control probe counts, which allows us to see if any regions in the tissue exhibit unexpectedly high control counts, possibly indicating localized technical issues.\n\n# Plot distribution of control probe counts\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['control_probe_counts'], kde=True, bins=50)\nplt.xlabel(\"Control Probe Counts\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Control Probe Counts\")\nplt.show()\n\n# Spatial plot of control probe counts\nsc.pl.spatial(adata, color='control_probe_counts', spot_size=10, title=\"Spatial Distribution of Control Probe Counts\")"
  },
  {
    "objectID": "day_1/practical_1/practical_1_2.html#filtering-normalizing-and-cleaning-data",
    "href": "day_1/practical_1/practical_1_2.html#filtering-normalizing-and-cleaning-data",
    "title": "Loading packages",
    "section": "Filtering, Normalizing and Cleaning data",
    "text": "Filtering, Normalizing and Cleaning data\nFilter out the cells that have nuclei smaller than 7 microns.\nWhat do you think could be a good cutoff for filtering out lowly expressed genes and cells with low transcript count? Lets removes low-quality cells and genes from the dataset, which helps reduce noise and computational load in downstream analyses. This filtering step ensures that the dataset is focused on cells and genes with a minimum level of expression, which are more likely to be biologically relevant.\n\n# Cell and gene filtering\ninitial_cells_count = adata.n_obs\ninitial_genes_count = adata.n_vars\n\nsc.pp.filter_cells(adata, min_counts=10, inplace=True)\nsc.pp.filter_genes(adata, min_cells=5, inplace=True)\n\nfiltered_cells_count = adata.n_obs\nfiltered_genes_count = adata.n_vars\nprint(f\"Filtered {initial_cells_count - filtered_cells_count} (out of intial {initial_cells_count} cells)\")\nprint(f\"Filtered {initial_genes_count - filtered_genes_count} (out of intial {initial_genes_count} genes)\")\n\nFiltered 2189 (out of intial 61954 cells)\nFiltered 0 (out of intial 347 genes)\n\n\n\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['total_counts'], kde=True, bins=50)\nplt.xlabel(\"Total Transcript Counts per Cell\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Total Transcript Counts per Cell After Filtering\")\nplt.show()\n\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['nucleus_area'], kde=True, bins=50)\nplt.xlabel(\"Nucleus Area\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Nucleus Area After Filtering\")\nplt.show()"
  },
  {
    "objectID": "day_1/practical_1/practical_1_2.html#normaliation-and-scaling",
    "href": "day_1/practical_1/practical_1_2.html#normaliation-and-scaling",
    "title": "Loading packages",
    "section": "Normaliation and scaling",
    "text": "Normaliation and scaling\nNormalization adjusts for cell-specific technical differences, and log transformation makes the data easier to analyze by reducing the effects of extreme values. This normalization and transformation make the dataset more appropriate for dimensionality reduction, clustering, and other analyses.\n\nadata.raw = adata.copy()\nsc.pp.normalize_total(adata, target_sum=1e4)\nsc.pp.log1p(adata)\n\nComparing the effect of normalization\n\noriginal_counts = adata.raw.X.sum(axis=1)\nnormalized_counts = adata.X.sum(axis=1)\n#plt distributions\nplt.figure(figsize=(10, 5))\nsns.histplot(original_counts.A1, color=\"blue\", label=\"Before Normalization\", kde=True) \nsns.histplot(normalized_counts.A1, color=\"orange\", label=\"After Normalization\", kde=True)\nplt.xlabel(\"Total Transcript Counts per Cell\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Effect of Normalization on Total Transcript Counts per Cell\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nHow the normalization and scaling of the data affects the distribution of gene expression values in the dataset. We can have a look at the distribution of gene expression values before and after normalization and scaling for MALL gene.\n\ngene_name = \"Cst3\"\nif gene_name in adata.var_names:\n    # Extract MALL expression values before normalization\n    original_mall_expression = adata.raw[:, gene_name].X.toarray().flatten()  # Use `.toarray()` for sparse matrices\n\n    # Extract MALL expression values after normalization\n    normalized_mall_expression = adata[:, gene_name].X.toarray().flatten()  # Use `.toarray()` for sparse matrices\n\n    # Plot distributions\n    plt.figure(figsize=(10, 5))\n    sns.histplot(original_mall_expression, color=\"blue\", label=\"Before Normalization\", kde=True, bins=50)\n    sns.histplot(normalized_mall_expression, color=\"orange\", label=\"After Normalization\", kde=True, bins=50)\n    plt.xlabel(f\"{gene_name} Expression\")\n    plt.ylabel(\"Number of Cells\")\n    plt.title(f\"Effect of Normalization and Scaling on {gene_name} Expression\")\n    plt.legend()\n    plt.show()"
  },
  {
    "objectID": "day_1/practical_1/practical_1_2.html#dimensionality-reduction",
    "href": "day_1/practical_1/practical_1_2.html#dimensionality-reduction",
    "title": "Loading packages",
    "section": "Dimensionality reduction",
    "text": "Dimensionality reduction\nWe use dimensionality reduction, clustering, and visualization techniques to analyze the structure of our dataset, group similar cells, and visualize their relationships. First, we apply Principal Component Analysis (PCA) to reduce the high-dimensional gene expression data into a smaller set of principal components, retaining the main patterns of variation while reducing noise. Then, we create a neighbors graph, which identifies connections between cells based on their similarity in the reduced PCA space, capturing local relationships essential for clustering. Using the Leiden clustering algorithm, we group cells into clusters based on these connections, allowing us to identify groups of similar cells that may represent distinct cell types or states. We then apply UMAP (Uniform Manifold Approximation and Projection), a technique that reduces the data to two dimensions for visualization, preserving both local and global structures in the data. Finally, we generate a UMAP plot with cells colored by their assigned clusters, providing an overview of the dataset’s structure and making it easy to spot distinct cell populations or clusters. This visualization gives us an interpretable view of the relationships within our data, helping us understand its organization before further analysis.\n\nsc.pp.pca(adata)\nsc.pp.neighbors(adata)\nsc.tl.leiden(adata)\nsc.tl.umap(adata)\nsc.pl.umap(adata, color='leiden', title='UMAP before filtering suspected false positives')\n\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n/var/folders/8l/yj6nz8296zd7wwj0xy6pw3880000gn/T/ipykernel_54309/2024658743.py:3: FutureWarning: In the future, the default backend for leiden will be igraph instead of leidenalg.\n\n To achieve the future defaults please pass: flavor=\"igraph\" and n_iterations=2.  directed must also be False to work with igraph's implementation.\n  sc.tl.leiden(adata)"
  },
  {
    "objectID": "day_1/practical_1/practical_1_2.html#systematic-filtering-of-suspected-false-positives",
    "href": "day_1/practical_1/practical_1_2.html#systematic-filtering-of-suspected-false-positives",
    "title": "Loading packages",
    "section": "Systematic Filtering of Suspected False Positives",
    "text": "Systematic Filtering of Suspected False Positives\nIn Xenium data, some genes may appear to be “expressed” across large areas or in many cells due to background noise or technical artifacts, rather than true biological expression. To address this, we are implementing a gene-specific filtering approach to identify and remove suspected false positives systematically. By filtering out these spurious signals, we can focus our analysis on more reliable gene expression patterns, improving the quality of downstream analyses.\n\n1- Calculate the Mean Expression per Gene per Cluster\nIn the first step, we calculate the mean expression of each gene within each cluster. Clustering organizes cells into groups that likely share biological characteristics, and taking the average expression of each gene within clusters provides a baseline for typical expression levels. This allows us to identify clusters where a gene has unusually low expression, which might indicate noise rather than true expression.\n\nmean_expression = adata.to_df().groupby(adata.obs['leiden']).mean()\n\n/var/folders/8l/yj6nz8296zd7wwj0xy6pw3880000gn/T/ipykernel_54309/2069805196.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  mean_expression = adata.to_df().groupby(adata.obs['leiden']).mean()\n\n\n\n\n2- Determine the Maximum Expression Level of Each Gene Across Clusters\nThen, we find the maximum expression level for each gene across all clusters. This maximum value serves as a reference point for each gene’s typical expression level in the dataset. The highest expression level of each gene is assumed to represent meaningful expression, while lower values may be more likely to represent noise or background.\n\nmax_expression_levels = mean_expression.max(axis=0)\n\n\n\n3- Calculate Spurious Expression Threshold for Each Gene\nWe define a threshold, here set at 5%, which will be used to identify potential false positives. This threshold means that if a gene’s expression in a given cluster is below 5% of its highest expression level across all clusters, we will consider it to be a likely false positive. This step allows us to systematically identify clusters where the gene’s expression is likely due to background noise rather than true biological signal. Then, we calculate a spurious expression threshold for each gene, which is 5% of its maximum expression level. This threshold provides a cut-off below which we consider expression values to be suspected false positives. By applying this threshold, we can filter out clusters where a gene’s expression level is unlikely to be biologically meaningful.\n\nthreshold = 0.05\nspurious_expression_threshold = max_expression_levels * threshold\n\n\n\n4- Identify Suspected False Positives for Each Cluster and Gene\nNext we creat a dictionary, suspected_false_positives, to store suspected false positive genes for each cluster. For each cluster, it checks each gene’s mean expression level within that cluster. If the gene’s mean expression is below the spurious expression threshold (5% of its maximum expression), the gene is flagged as a suspected false positive in that cluster.\n\nsuspected_false_positives = {}\nfor cluster in mean_expression.index:\n    suspected_genes = []\n    for gene in adata.var_names:\n        if mean_expression.at[cluster, gene] &lt; spurious_expression_threshold[gene]:\n            suspected_genes.append(gene)\n    suspected_false_positives[cluster] = suspected_genes\n\nNow we can see a quick summary of the suspected false positives across clusters\n\n#Showing first 10 genes for brevity\nfor cluster, genes in suspected_false_positives.items():\n    print(f\"Cluster {cluster} has {len(genes)} suspected false positive genes: {genes[:10]}\")\n\ncluster_counts = {cluster: len(genes) for cluster, genes in suspected_false_positives.items()}\nclusters = list(cluster_counts.keys())\ncounts = list(cluster_counts.values())\nplt.figure(figsize=(12, 6))\nsns.barplot(x=clusters, y=counts, palette='viridis')\nplt.title('Count of Suspected False Positive Genes per Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Count of Suspected False Positive Genes')\nplt.xticks(rotation=45)\nplt.show()\n\nCluster 0 has 133 suspected false positive genes: ['2010300C02Rik', 'Acvrl1', 'Adgrl4', 'Aldh1a2', 'Ano1', 'Arhgap25', 'Arhgap6', 'Bcl11b', 'Bdnf', 'Bhlhe22']\nCluster 1 has 64 suspected false positive genes: ['Acvrl1', 'Adamtsl1', 'Aldh1a2', 'C3', 'Cd24a', 'Cd93', 'Chat', 'Cldn5', 'Col19a1', 'Col6a1']\nCluster 2 has 52 suspected false positive genes: ['Acvrl1', 'Adgrl4', 'Aldh1a2', 'Ano1', 'Arhgap25', 'C3', 'Carmn', 'Cd14', 'Cd33', 'Cd93']\nCluster 3 has 66 suspected false positive genes: ['Adamts2', 'Adamtsl1', 'Aldh1a2', 'Ano1', 'Arhgap6', 'C3', 'Cd24a', 'Chat', 'Chodl', 'Cldn5']\nCluster 4 has 41 suspected false positive genes: ['Adamtsl1', 'C3', 'Cd24a', 'Chat', 'Chodl', 'Col19a1', 'Col1a1', 'Col6a1', 'Crh', 'Cwh43']\nCluster 5 has 51 suspected false positive genes: ['Acvrl1', 'Adgrl4', 'Aldh1a2', 'Ano1', 'Arhgap6', 'C3', 'Calb2', 'Carmn', 'Cd93', 'Chat']\nCluster 6 has 68 suspected false positive genes: ['Acvrl1', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Ano1', 'Arhgap25', 'C3', 'Carmn', 'Cbln1', 'Cd14']\nCluster 7 has 103 suspected false positive genes: ['Arc', 'Bcl11b', 'Bdnf', 'Btbd11', 'C3', 'Cacna2d2', 'Calb1', 'Calb2', 'Cbln1', 'Cbln4']\nCluster 8 has 69 suspected false positive genes: ['Acvrl1', 'Aldh1a2', 'Ano1', 'Arc', 'Arhgap25', 'C3', 'Carmn', 'Cd14', 'Cd33', 'Cd93']\nCluster 9 has 118 suspected false positive genes: ['Acvrl1', 'Adamts2', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Ano1', 'Arhgap25', 'Arhgap6', 'Bcl11b', 'C3']\nCluster 10 has 60 suspected false positive genes: ['Acvrl1', 'Adgrl4', 'Aldh1a2', 'Ano1', 'Arhgap6', 'C3', 'Calb2', 'Carmn', 'Cbln4', 'Cd14']\nCluster 11 has 40 suspected false positive genes: ['Acvrl1', 'Aldh1a2', 'Ano1', 'C3', 'Carmn', 'Cd93', 'Chat', 'Cldn5', 'Col1a1', 'Col6a1']\nCluster 12 has 165 suspected false positive genes: ['Acvrl1', 'Adamts2', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Ano1', 'Apod', 'Arc', 'Arhgap25', 'Arhgap6']\nCluster 13 has 92 suspected false positive genes: ['Acvrl1', 'Adgrl4', 'Aldh1a2', 'Ano1', 'Arhgap25', 'Bdnf', 'Bhlhe22', 'C3', 'Carmn', 'Ccn2']\nCluster 14 has 45 suspected false positive genes: ['Acvrl1', 'Aldh1a2', 'Ano1', 'Arhgap25', 'C3', 'Carmn', 'Cd33', 'Cd93', 'Chat', 'Cldn5']\nCluster 15 has 102 suspected false positive genes: ['2010300C02Rik', 'Aldh1a2', 'Ano1', 'Arhgap25', 'Arhgap6', 'Bcl11b', 'Bhlhe22', 'C3', 'Cabp7', 'Carmn']\nCluster 16 has 48 suspected false positive genes: ['Acvrl1', 'Aldh1a2', 'Ano1', 'Arhgap6', 'C3', 'Carmn', 'Cd24a', 'Cd93', 'Chat', 'Chodl']\nCluster 17 has 43 suspected false positive genes: ['Adgrl4', 'Aldh1a2', 'Ano1', 'Arhgap25', 'C3', 'Carmn', 'Ccn2', 'Cd93', 'Chat', 'Cldn5']\nCluster 18 has 110 suspected false positive genes: ['Acvrl1', 'Adgrl4', 'Aldh1a2', 'Ano1', 'Arhgap25', 'Arhgap6', 'C3', 'Calb2', 'Cbln1', 'Ccn2']\nCluster 19 has 143 suspected false positive genes: ['Abca7', 'Adgrl4', 'Aldh1a2', 'Ano1', 'Arc', 'Arhgap25', 'Bcl11b', 'Bdnf', 'Bhlhe22', 'Cabp7']\nCluster 20 has 71 suspected false positive genes: ['Aldh1a2', 'Ano1', 'Arhgap6', 'Btbd11', 'C3', 'Cacna2d2', 'Calb1', 'Cbln4', 'Ccn2', 'Cd14']\nCluster 21 has 44 suspected false positive genes: ['Adamtsl1', 'Aldh1a2', 'Ano1', 'Arhgap6', 'C3', 'Calb2', 'Cbln4', 'Cd93', 'Chat', 'Chodl']\nCluster 22 has 186 suspected false positive genes: ['Acsbg1', 'Adamts2', 'Adgrl4', 'Aldh1a2', 'Ano1', 'Aqp4', 'Arc', 'Arhgap25', 'Arhgap6', 'Bcl11b']\nCluster 23 has 146 suspected false positive genes: ['Acvrl1', 'Adamts2', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Arc', 'Arhgap25', 'Arhgap6', 'Bhlhe22', 'C1qc']\n\n\n/var/folders/8l/yj6nz8296zd7wwj0xy6pw3880000gn/T/ipykernel_54309/225620550.py:9: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x=clusters, y=counts, palette='viridis')\n\n\n\n\n\n\n\n\n\n\nall_suspected_fp_genes = set()\nfor genes in suspected_false_positives.values():\n    all_suspected_fp_genes.update(genes)\nall_suspected_fp_genes_list = sorted(all_suspected_fp_genes)\nclusters = list(suspected_false_positives.keys())\nheatmap_data = pd.DataFrame(0, index=list(all_suspected_fp_genes_list), columns=clusters)\n\nfor cluster, genes in suspected_false_positives.items():\n    heatmap_data.loc[genes, cluster] = 1\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(heatmap_data, cmap=\"viridis\", cbar_kws={'label': 'Presence of Suspected False Positives'})\nplt.title(\"Heatmap of Suspected False Positive Genes Across Clusters\")\nplt.xlabel(\"Cluster\")\nplt.ylabel(\"Gene\")\nplt.show()\n\n\n\n\n\n\n\n\n\nbackground_noise_counts = {gene: 0 for gene in adata.var_names}\nfor gene in adata.var_names:\n    for cluster in mean_expression.index:\n        if mean_expression.at[cluster, gene] &lt; spurious_expression_threshold[gene]:\n            background_noise_counts[gene] += 1\n\n# Find the gene with the highest background noise\nhighest_noise_gene = max(background_noise_counts, key=background_noise_counts.get)\nhighest_noise_count = background_noise_counts[highest_noise_gene]\n\nprint(f\"The gene with the highest background noise is '{highest_noise_gene}', detected below the threshold in {highest_noise_count} clusters.\")\n\nThe gene with the highest background noise is 'C3', detected below the threshold in 23 clusters.\n\n\n\n\n5- Adjusting gene expression values across the dataset (background noise reduction)\nNow, we aim to reduce background noise by adjusting gene expression levels across all cells based on suspected false positives. Specifically, if a gene has low expression (below the spurious expression threshold) in any cluster, we take the highest of those low expression levels and subtract it from all cells for that gene. This method removes unspecific, potentially spurious expression, which can help improve cluster separation and make biologically relevant expression patterns clearer.\n\nadata_app_1 = adata.copy()\n\nmax_filtered_expression = {}\nadata_df = adata_app_1.to_df()\n\nfor gene in adata_app_1.var_names:\n    below_threshold_values = []\n    for cluster in mean_expression.index:\n        expression_level = mean_expression.at[cluster, gene]\n        if expression_level &lt; spurious_expression_threshold[gene]:\n            below_threshold_values.append(expression_level)\n            \n    if below_threshold_values:\n        max_filtered_expression[gene] = max(below_threshold_values)\n    else:\n        max_filtered_expression[gene] = 0  \n        #no values below threshold = no subtraction needed\n\n#subtract the maximum filtered expression value from all cells for each gene\nfor gene in adata_app_1.var_names:\n    max_expr = max_filtered_expression[gene]\n    if max_expr &gt; 0:\n        adata_df[gene] -= max_expr\n        #ensure that no negative values are introduced\n        adata_df[gene] = np.maximum(adata_df[gene], 0)\n\n#update AnnData object with adjusted gene expressions\nadata_app_1 = sc.AnnData(X=adata_df.values, obs=adata_app_1.obs, var=adata_app_1.var, obsm=adata_app_1.obsm)\nsc.pp.pca(adata_app_1)\nsc.pp.neighbors(adata_app_1)\nsc.tl.leiden(adata_app_1)\nsc.tl.umap(adata_app_1)\nsc.pl.umap(adata_app_1, color='leiden', title='UMAP after filtering suspected false positives')\n\n\n\n\n\n\n\n\n\ngene_of_interest = \"C3\"\nsc.pl.spatial(adata, color=[gene_of_interest], spot_size=10, title=f'{gene_of_interest} Expression Before Adjustment')\nsc.pl.spatial(adata_app_1, color=[gene_of_interest], spot_size=10, title=f'{gene_of_interest} Expression After Adjustment')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\noriginal_expression = adata.to_df()[gene_of_interest]\nadjusted_expression = adata_app_1.to_df()[gene_of_interest]\n\nplt.figure(figsize=(10, 5))\nsns.kdeplot(original_expression, label=\"Original\", color=\"blue\")\nsns.kdeplot(adjusted_expression, label=\"Adjusted\", color=\"orange\")\nplt.xlabel(f'Expression of {gene_of_interest}')\nplt.ylabel('Density')\nplt.title(f'Expression Distribution of {gene_of_interest} Before and After Adjustment')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Calculate mean expression per gene\nmean_expression_original = adata.to_df().mean(axis=0)\nmean_expression_adjusted = adata_app_1.to_df().mean(axis=0)\n\n# Plot a scatter plot comparing mean expression before and after adjustment\nplt.figure(figsize=(8, 8))\nplt.scatter(mean_expression_original, mean_expression_adjusted, alpha=0.5)\nplt.plot([0, max(mean_expression_original)], [0, max(mean_expression_adjusted)], color=\"red\", linestyle=\"--\")\nplt.xlabel('Mean Expression (Original)')\nplt.ylabel('Mean Expression (Adjusted)')\nplt.title('Mean Gene Expression Before and After Adjustment')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSecond approach\nCheck the histogram of the gene expression for every gene and if it has a multimodal expression distribution to set based on that histogram a thereshold below which we consider the expression to be background. And we could remove from all cells the expression below that therahold. First making helper functions performing dip test and plotting the histogram of the gene expression. I’ve used dip test to check if the distribution is multimodal or not. If the p-value is smaller than 0.05 we consider the distribution to be multimodal. A question here would be that should we only consider non-zero expression values for this analysis or should we consider all expression values? If consider all values we might get a multimodal distribution all for genes, however if we only consider non-zero values we might miss some genes that are suspected to have multimodal distribution. What do you think?\n\ngenes_to_analyze = adata.var_names[0:len(adata.var_names)]\nthresholds = {}\nfor gene in genes_to_analyze:\n    threshold = hf.analyze_gene_expressions(adata, gene, bandwidth=0.05, plot=False, filter_zeros=False)\n    if threshold is not None:\n        thresholds[gene] = threshold\n\nSort genes by threshold values in descending order and display the top genes with the highest thresholds\n\nsorted_thresholds = sorted(thresholds.items(), key=lambda x: x[1], reverse=True)\nprint(\"Top genes with the highest thresholds:\")\nfor gene, threshold_value in sorted_thresholds[:10]:\n    print(f\"{gene}: {threshold_value}\")\n\nTop genes with the highest thresholds:\nIgf2: 5.790457594740737\nCalb1: 5.102079337065643\nCarmn: 5.04996848559833\nApod: 4.911531774847357\nCldn5: 4.804661403308521\nGjc3: 4.763423601786296\nSlc17a6: 4.709977990991479\nCol6a1: 4.677103303216241\nDcn: 4.673891974402381\nCpne6: 4.656482888413621\n\n\n\ngene_of_interest = \"Calb1\"\nhf.analyze_gene_expressions(adata, gene_of_interest, bandwidth=0.05, plot=True, filter_zeros=False)\n\n\n\n\n\n\n\n\nCalb1 has a Multimodal modality (p-value=0.00)\nBackground threshold for Calb1 is 5.102\n\n\n5.102079337065643\n\n\nNow we can do the subtraction of genes with a background expression from their original values in each cell.\n\n# 1. Reverse the log1p transformation on adata.X\nadata_app_2 = adata.copy()\nif sp.issparse(adata_app_2.X):\n    adata_app_2.X = sp.csr_matrix(np.expm1(adata_app_2.X.toarray()))\nelse:\n    adata_app_2.X = np.expm1(adata_app_2.X)\n\n# 2. Reverse the log1p transformation on thresholds\nthresholds = {gene: np.expm1(thresh) for gene, thresh in thresholds.items()}\n\n# 3. Perform the subtraction and ensure non-negative values\nfor gene, threshold in thresholds.items():\n    if gene in adata_app_2.var_names:  # Ensure the gene exists in adata\n        gene_index = adata_app_2.var_names.get_loc(gene)\n        \n        # Extract the column as a dense numpy array\n        gene_data = adata_app_2[:, gene].X\n        if sp.issparse(gene_data):\n            gene_data = gene_data.toarray().flatten()\n\n        # Perform the subtraction and ensure non-negative values\n        updated_gene_data = np.maximum(gene_data - threshold, 0)\n\n        # Update the AnnData object\n        if sp.issparse(adata_app_2.X):\n            adata_app_2[:, gene_index].X = sp.csr_matrix(updated_gene_data[:, np.newaxis])\n        else:\n            adata_app_2[:, gene_index].X = updated_gene_data[:, np.newaxis]\n\n# 4. Reapply the log1p transformation\nsc.pp.log1p(adata_app_2)\n\nWARNING: adata.X seems to be already log-transformed.\n\n\n\ngene_of_interest = \"Calb1\"\n\nsc.pl.spatial(adata, color=[gene_of_interest], spot_size=10, title=f'{gene_of_interest} Expression Before Adjustment')\nsc.pl.spatial(adata_app_2, color=[gene_of_interest], spot_size=10, title=f'{gene_of_interest} Expression After Adjustment')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\noriginal_expression = adata.to_df()[gene_of_interest]\nadjusted_expression = adata_app_2.to_df()[gene_of_interest]\n\n# Plot expression distributions\nplt.figure(figsize=(10, 5))\nsns.kdeplot(original_expression, label=\"Original\", color=\"blue\")\nsns.kdeplot(adjusted_expression, label=\"Adjusted\", color=\"orange\")\nplt.xlabel(f'Expression of {gene_of_interest}')\nplt.ylabel('Density')\nplt.title(f'Expression Distribution of {gene_of_interest} Before and After Adjustment')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Principal component analysis for dimension reduction\nsc.pp.pca(adata_app_2)\nsc.pp.neighbors(adata_app_2)\nsc.tl.leiden(adata_app_2)\nsc.tl.umap(adata_app_2)\nsc.pl.umap(adata_app_2, color='leiden', title='UMAP after filtering suspected false positives (approach 2)')"
  },
  {
    "objectID": "day_1/practical_1/segmentation.html",
    "href": "day_1/practical_1/segmentation.html",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom cellpose import models, io, plot\nfrom tifffile import imread\nimport os\nimport tifffile\nfrom cellpose import plot\nimport shapely.geometry as geometry\nfrom shapely.geometry import Polygon\nfrom shapely.affinity import translate, scale\nfrom shapely.errors import TopologicalError\nfrom rasterio import features\nfrom sklearn.metrics import jaccard_score\nfrom skimage.measure import regionprops_table\n\n\n# Set up plotting aesthetics\nsns.set(style='whitegrid')\n%matplotlib inline\n\nLoading and inspecting the morphology image is a foundational step in the analysis. Understanding the image’s dimensions helps guide downstream processing, including selecting channels or slices for segmentation and defining an ROI if needed.\n\nimage_data_path = 'data/Xenium_V1_FFPE_TgCRND8_17_9_months_outs/morphology.ome.tif'\nimage = tifffile.imread(image_data_path)\nprint(f\"Image shape: {image.shape}\")\n\nImage shape: (26, 24864, 31348)\n\n\nwe retrieve and inspect the metadata embedded within the morphology image file. Opening the file with tifffile.TiffFile allows us to access not only the pixel data but also any associated metadata stored in OME (Open Microscopy Environment) format. By using a context manager (with statement), we ensure that the file is properly handled, meaning it will close automatically once we’re done, helping to avoid potential file-handling errors.\nThe OME metadata contains crucial information about the image acquisition settings. Extracting it with ome_metadata = tif.ome_metadata provides us with details about the microscope settings, pixel size, and other experimental parameters. This metadata appears in XML format, which is printed for review. Examining this data is essential to understand the spatial resolution of the image, enabling us to relate image coordinates to real-world units, such as micrometers. Knowing these specifics is key for aligning segmentation results accurately with the spatial features observed in the morphology image.\n\nwith tifffile.TiffFile(image_data_path) as tif:\n    ome_metadata = tif.ome_metadata\n    print(ome_metadata)\n\n&lt;OME xmlns=\"http://www.openmicroscopy.org/Schemas/OME/2016-06\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" Creator=\"tifffile.py 2022.10.10\" UUID=\"urn:uuid:eaf5dc46-d5c3-11ed-ad40-068afc1a6c91\" xsi:schemaLocation=\"http://www.openmicroscopy.org/Schemas/OME/2016-06 http://www.openmicroscopy.org/Schemas/OME/2016-06/ome.xsd\"&gt;\n    &lt;Plate ID=\"Plate:1\" WellOriginX=\"-0.0\" WellOriginXUnit=\"µm\" WellOriginY=\"-0.0\" WellOriginYUnit=\"µm\" /&gt;\n    &lt;Instrument ID=\"Instrument:1\"&gt;\n        &lt;Microscope Manufacturer=\"10x Genomics\" Model=\"Xenium\" /&gt;\n    &lt;/Instrument&gt;\n    &lt;Image ID=\"Image:0\" Name=\"Image0\"&gt;\n        &lt;InstrumentRef ID=\"Instrument:1\" /&gt;\n        &lt;Pixels DimensionOrder=\"XYZCT\" ID=\"Pixels:0\" SizeC=\"1\" SizeT=\"1\" SizeX=\"31348\" SizeY=\"24864\" SizeZ=\"26\" Type=\"uint16\" PhysicalSizeX=\"0.2125\" PhysicalSizeY=\"0.2125\" PhysicalSizeZ=\"3.0\"&gt;\n            &lt;Channel ID=\"Channel:0:0\" Name=\"DAPI\" SamplesPerPixel=\"1\" /&gt;\n            &lt;TiffData PlaneCount=\"26\" /&gt;\n        &lt;/Pixels&gt;\n    &lt;/Image&gt;\n&lt;/OME&gt;\n\n\nLets preview the transcripts data again:\n\ntranscriptomics_data_path = 'data/Xenium_V1_FFPE_TgCRND8_17_9_months_outs/transcripts.csv.gz'\ndata = pd.read_csv(transcriptomics_data_path, compression='gzip')\nprint(data.head())\n\n     transcript_id     cell_id  overlaps_nucleus feature_name  x_location  \\\n0  281474976710656  UNASSIGNED                 0        Sox10   164.48816   \n1  281474976710657  UNASSIGNED                 0         Ctsh   169.85483   \n2  281474976710658  UNASSIGNED                 0        Ntng1   260.06710   \n3  281474976710659  UNASSIGNED                 0        Ntng1   269.16196   \n4  281474976710660  UNASSIGNED                 0        Ntng1   272.35153   \n\n   y_location  z_location         qv fov_name  nucleus_distance  \n0   26.783148   11.713852   6.386437       A1           0.00000  \n1  652.652700   11.551014  27.915363       A1           0.00000  \n2  483.239100   12.582438  15.282572       A1         158.24005  \n3  409.500850   14.335079  29.190600       A1          84.09205  \n4  406.806150   15.083600  23.004885       A1          80.83307  \n\n\nHere, we are checking and handling the dimensionality of the morphology image to extract a usable 2D channel for segmentation and analysis. To start, print(f\"Image dimensions: {image.ndim}\") reveals the number of dimensions in the image array. Images acquired from microscopy can have multiple dimensions, often representing different z-slices, time points, or channels (e.g., specific fluorescent stains). Knowing the exact number of dimensions is essential for understanding the structure of the data and selecting the specific layer or channel needed for downstream tasks.\nWe then use conditional statements to select the appropriate 2D plane. If the image has five dimensions—typically representing time, Z (depth), channels, height, and width—we select the first time point, Z-slice, and channel to reduce it to 2D. Similarly, for four-dimensional images (likely Z, channels, height, and width), we choose the first Z-slice and channel. In the case of three-dimensional images, we assume they represent channels, height, and width, and extract the first channel. Finally, if the image is already 2D, we simply assign it to image_channel without further modification.\nThis step ensures that we have a consistent, interpretable 2D array (image_channel) for the following analysis. By isolating a single plane or channel, we simplify the data, making it easier to overlay segmentations or spatial features without the added complexity of multiple dimensions. This also ensures that our chosen channel represents the tissue morphology effectively\n\nprint(f\"Image dimensions: {image.ndim}\")\nif image.ndim == 5:\n    # Example shape: (Time, Z, Channels, Height, Width)\n    # Select the first time point, z-slice, and channel\n    image_channel = image[0, 0, 0, :, :]\nelif image.ndim == 4:\n    # Example shape: (Z, Channels, Height, Width)\n    image_channel = image[0, 0, :, :]\nelif image.ndim == 3:\n    # Example shape: (Channels, Height, Width)\n    image_channel = image[0, :, :]\nelse:\n    # Already a 2D image\n    image_channel = image\n\nImage dimensions: 3\n\n\n\nimage_channel = np.max(image, axis=0)\nimage_channel = image_channel.astype(np.uint16)\n\n\nplt.figure(figsize=(8, 8))\nplt.imshow(image_channel)\nplt.title('Selected Image for Segmentation')\nplt.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\nSince the original image is too big here we define a region of interest (ROI) within the larger image, focusing on a smaller area for more efficient and targeted analysis. This is particularly useful for high-resolution images where analyzing the entire field of view might be computationally intensive.\nWe begin by setting a scale_factor, which controls the size of the ROI as a fraction of the full image dimensions. Here, scale_factor = 0.05 means that the ROI will cover 5% of the original image’s width and height. Adjusting this factor allows flexibility in focusing on larger or smaller portions of the image, depending on the needs of the analysis.\nUsing image_channel.shape, we extract the height and width of the full image. Then, by multiplying these dimensions by scale_factor, we calculate the width and height of the ROI (roi_width and roi_height). Converting these values to integers ensures that they’re compatible with image indexing.\nFinally, we make an optional adjustment to ensure that the ROI dimensions are even numbers, which can simplify image processing tasks. We do this by reducing roi_width and roi_height by 1 if they are odd, using modulo operations. This adjustment helps avoid issues when working with certain algorithms that may require even-numbered dimensions, ensuring that the ROI dimensions are compatible with a range of image processing techniques.\n\nscale_factor = 0.05  #adjust based on the size of the img that you want to be processed\nimage_height, image_width = image_channel.shape\n\n# roi\nroi_width = int(image_width * scale_factor)\nroi_height = int(image_height * scale_factor)\nroi_width -= roi_width % 2\nroi_height -= roi_height % 2\n\n#calculate the starting and ending coordinates\nx_center = image_width // 2\ny_center = image_height // 2\n\nx_start = x_center - roi_width // 2\nx_end = x_center + roi_width // 2\ny_start = y_center - roi_height // 2\ny_end = y_center + roi_height // 2\n\nExtract the ROI from the image\n\nroi_image = image_channel[y_start:y_end, x_start:x_end]\n# dimensions\nprint(f\"ROI image shape: {roi_image.shape}\")\n\nROI image shape: (1242, 1566)\n\n\n\nplt.figure(figsize=(8, 8))\nplt.imshow(roi_image)\nplt.title('ROI Image for Segmentation')\nplt.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\nNext we map the ROI pixel coordinates back to real-world units (micrometers) and filter the spatial transcriptomics data to include only the transcripts within the ROI. This enables precise alignment of the transcript data with the selected region in the image.\nWe start by defining scaling factors for converting image pixels to micrometers. Here, x_scale and y_scale represent the conversion rate based on the pixel size provided in the image metadata: each micrometer contains approximately 4.7 pixels (1 / 0.2125). This conversion allows us to translate pixel coordinates into micrometer units, which are required for comparing and aligning data across different scales.\nUsing these scaling factors, we calculate the boundaries of the ROI in micrometers. For each dimension, x_start, x_end, y_start, and y_end (which are pixel coordinates from the original image), we divide by the scaling factor to obtain the corresponding boundaries in micrometers: x_start_um, x_end_um, y_start_um, and y_end_um. This step ensures that our ROI is defined consistently in both pixel and physical units.\nNext, we filter the transcriptomics data to include only the transcripts located within the ROI. We use conditional filtering on the x_location and y_location columns of the data DataFrame, retaining only the transcripts whose coordinates fall within the calculated micrometer boundaries. The result is stored in roi_data, which represents the subset of transcripts that reside within our chosen ROI.\nFinally, by printing len(roi_data), we get a quick count of the transcripts within the ROI.\n\n#using the scaling factors from before\nx_scale = 1 / 0.2125  # pixels per µm\ny_scale = 1 / 0.2125  # pixels per µm\n\n#roi boundaries in micrometers\nx_start_um = x_start / x_scale\nx_end_um = x_end / x_scale\ny_start_um = y_start / y_scale\ny_end_um = y_end / y_scale\n\n#filter transcripts within the ROI boundaries\nroi_data = data[\n    (data['x_location'] &gt;= x_start_um) &\n    (data['x_location'] &lt; x_end_um) &\n    (data['y_location'] &gt;= y_start_um) &\n    (data['y_location'] &lt; y_end_um)\n].copy()\nprint(f\"Number of transcripts in ROI: {len(roi_data)}\")\n\nNumber of transcripts in ROI: 47902\n\n\nNow we should subtract x_start_um from each transcript’s x_location and y_start_um from each y_location in roi_data. By doing so, we create new columns, x_location_roi and y_location_roi, that represent each transcript’s position relative to the top-left corner of the ROI rather than the full image.\n\nroi_data['x_location_roi'] = roi_data['x_location'] - x_start_um\nroi_data['y_location_roi'] = roi_data['y_location'] - y_start_um\n\nNow we finally set up the Cellpose segmentation model to identify cells within the ROI. Cellpose is a versatile deep learning-based tool commonly used for cell segmentation, especially on fluorescence and cytoplasmic images. Here, we are preparing the model for use in the analysis.\nFirst, we import the models module from the cellpose package, which provides access to pre-trained Cellpose models. Next, we initialize a model instance using models.Cellpose(). By setting gpu=False, we specify that the model will run on the CPU. This is useful if GPU resources are unavailable, though using a GPU can speed up the segmentation process if it is an option.\nWe also set model_type='cyto', indicating that the model should use Cellpose’s pre-trained “cyto” (cytoplasm) model, which is optimized for identifying cell boundaries in images with visible cell structures. This choice is typically well-suited for images showing cell cytoplasm, though Cellpose offers other model types, like “nuclei,” if our focus were solely on nuclear segmentation.\n\nfrom cellpose import models\nmodel = models.Cellpose(gpu=False, model_type='cyto')\n\n/Users/rasools/miniconda3/envs/segmentation_env/lib/python3.9/site-packages/cellpose/resnet_torch.py:280: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load(filename, map_location=torch.device(\"cpu\"))\n\n\nThen, we estimate the average cell diameter in pixels and then use Cellpose to perform cell segmentation on the ROI.\nWe start by setting cell_diameter_um to an estimated cell diameter in micrometers, which is based on biological knowledge of cell sizes in the specific tissue or sample type. Here, we use 10 micrometers as the mouse cell daimeter for mouse brains cells is estrimated 7-10 micrometers, but this value can be adjusted based on the specific dataset.\nTo convert this estimate into pixel units, we multiply cell_diameter_um by the scaling factor x_scale (pixels per micrometer), calculated previously. This results in cell_diameter_pixels, an approximation of the cell diameter in the pixel space of the image. By converting the diameter to pixels, we ensure that Cellpose can interpret the size parameter relative to the image’s resolution.\nNext, we run the Cellpose model on roi_image, the 2D image extracted from the ROI. The model’s eval() function applies the segmentation model to the image, using diameter=cell_diameter_pixels to guide the segmentation scale. The channels=[0, 0] parameter specifies that the image is grayscale; both entries as 0 indicate that there is a single channel for both input and detection purposes.\nThe eval() function returns several outputs:\n\nmasks: a labeled mask array where each detected cell has a unique identifier,\nflows: which provides information about cell boundary flows,\nstyles: representing style vectors for detected objects, and\ndiams: the diameter used in the model (helpful if it has been automatically adjusted).\n\n\ncell_diameter_um = 10  # µm\ncell_diameter_pixels = cell_diameter_um * x_scale\nprint(f\"Estimated cell diameter in pixels: {cell_diameter_pixels}\")\n#run segmentation\nmasks, flows, styles, diams = model.eval(\n    roi_image,\n    diameter=cell_diameter_pixels,\n    channels=[0, 0]\n)\n\nEstimated cell diameter in pixels: 47.05882352941177\n\n\n\nprint(f\"Number of cells detected in ROI: {masks.max()}\")\n\nNumber of cells detected in ROI: 224\n\n\nNow we convert the transcript coordinates within the ROI from micrometers to pixel indices, preparing them for alignment with the segmentation mask.\nFirst, we extract the x- and y-coordinates in micrometers from roi_data, which represents transcript locations relative to the top-left corner of the ROI. These coordinates are stored in x_coords_um and y_coords_um, making it easy to work directly with arrays of positions.\nTo map these positions into the pixel space of roi_image, we multiply each coordinate by the scaling factor (x_scale and y_scale) previously defined. This scaling factor converts micrometers into pixel units, allowing us to obtain x_indices and y_indices the pixel indices that match the resolution of the segmentation mask.\nBy converting coordinates to pixel indices, we can precisely locate each transcript in the context of the segmented cells within the ROI.\n\nx_coords_um = roi_data['x_location_roi'].values\ny_coords_um = roi_data['y_location_roi'].values\n\n#pixel indices\nx_indices = (x_coords_um * x_scale).astype(int)\ny_indices = (y_coords_um * y_scale).astype(int)\n\n\n#RRoi image dimensions\nroi_height, roi_width = roi_image.shape\n\n#indices\nx_indices = np.clip(x_indices, 0, roi_width - 1)\ny_indices = np.clip(y_indices, 0, roi_height - 1)\n\nNext we assign each transcript to a segmented cell based on its pixel coordinates, linking gene expression data to specific cells within the ROI.\n\n#cell labels for each transcript\ncell_labels = masks[y_indices, x_indices]\n#Add cell labels to the data\nroi_data['cellpose_cell_id'] = cell_labels\n\n#preview\nprint(roi_data.head())\n\n           transcript_id     cell_id  overlaps_nucleus feature_name  \\\n8282551  281599530763477  nodbomii-1                 1         Gusb   \n8282556  281599530763482  bdamcjfe-1                 0         Cst3   \n8282569  281599530763495  nodbomii-1                 0         Cst3   \n8282582  281599530763508  bdamcjfe-1                 0         Cst3   \n8282603  281599530763529  nodbomii-1                 1        Parm1   \n\n         x_location  y_location  z_location        qv fov_name  \\\n8282551   3166.3472   2527.3328   34.873024  40.00000       C6   \n8282556   3166.8430   2533.2446   34.078390  40.00000       C6   \n8282569   3167.3296   2529.3591   33.823017  40.00000       C6   \n8282582   3168.9888   2531.9070   34.126305  38.92044       C6   \n8282603   3171.1484   2524.1245   34.531853  40.00000       C6   \n\n         nucleus_distance  x_location_roi  y_location_roi  cellpose_cell_id  \n8282551          0.000000          2.0097         17.4953                15  \n8282556          0.705350          2.5055         23.4071                 0  \n8282569          0.609131          2.9921         19.5216                 0  \n8282582          0.900610          4.6513         22.0695                 0  \n8282603          0.223389          6.8109         14.2870                 0  \n\n\nKeep only transcripts assigned to a cell\n\nassigned_data = roi_data[roi_data['cellpose_cell_id'] &gt; 0].copy()\nprint(f\"Total transcripts in ROI: {len(roi_data)}\")\nprint(f\"Assigned transcripts: {len(assigned_data)}\")\n\nTotal transcripts in ROI: 47902\nAssigned transcripts: 17030\n\n\nwe visualize the results of the Cellpose segmentation overlayed on the ROI image, allowing us to inspect how well the model identified individual cells in the selected region.\n\n\nfig = plt.figure(figsize=(8, 8))\nplot.show_segmentation(fig, roi_image, masks, flows[0])\nplt.title('Cellpose Segmentation on ROI')\nplt.show()\n\n\n\n\n\n\n\n\nGroup by cell and gene to get expression counts\n\nexpression_per_cell = assigned_data.groupby(['cellpose_cell_id', 'feature_name']).size().reset_index(name='count')\nexpression_matrix = expression_per_cell.pivot(index='cellpose_cell_id', columns='feature_name', values='count').fillna(0)\nprint(expression_matrix.head())\n\nfeature_name      2010300C02Rik  Abca7  Acsbg1  Acta2  Acvrl1  Adamts2  \\\ncellpose_cell_id                                                         \n1                           0.0    0.0     1.0    0.0     2.0      0.0   \n2                           0.0    0.0     1.0    0.0     0.0      0.0   \n3                           0.0    0.0     0.0    0.0     0.0      0.0   \n4                           1.0    0.0     0.0    0.0     0.0      0.0   \n5                           1.0    1.0     0.0    0.0     0.0      0.0   \n\nfeature_name      Adamtsl1  Adgrl4  Aldh1a2  Aldh1l1  ...  Unc13c  Vat1l  \\\ncellpose_cell_id                                      ...                  \n1                      0.0     4.0      0.0      1.0  ...     0.0    0.0   \n2                      0.0     0.0      0.0      0.0  ...     0.0    0.0   \n3                      0.0     0.0      0.0      0.0  ...     0.0    0.0   \n4                      0.0     0.0      0.0      0.0  ...     0.0    1.0   \n5                      0.0     0.0      0.0      0.0  ...     0.0    1.0   \n\nfeature_name      Vcan  Vim  Vip  Vwc2l  Wfs1  Zfp366  Zfp536  Zfpm2  \ncellpose_cell_id                                                      \n1                  0.0  1.0  0.0    0.0   0.0     0.0     0.0    0.0  \n2                  0.0  0.0  0.0    0.0   0.0     0.0     0.0    0.0  \n3                  0.0  0.0  0.0    0.0   0.0     0.0     0.0    0.0  \n4                  0.0  0.0  0.0    0.0   0.0     0.0     0.0    0.0  \n5                  0.0  0.0  0.0    0.0   0.0     0.0     1.0    0.0  \n\n[5 rows x 418 columns]\n\n\nwe can plot the locations of transcripts overlaid on the ROI image, specifically highlighting those that have been assigned to segmented cells. This helps us see how transcript data aligns with the detected cell boundaries within the region.\n\nplt.figure(figsize=(8, 8))\nplt.imshow(roi_image, cmap='gray')\nplt.scatter(\n    x_indices[roi_data['cellpose_cell_id'] &gt; 0],\n    y_indices[roi_data['cellpose_cell_id'] &gt; 0],\n    c='red', s=5, label='Transcripts'\n)\nplt.title('Transcripts Mapped to Segmented Cells')\nplt.axis('off')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFinally, we can visualize the expression of a specific gene across the detected cells, providing insights into the spatial distribution of gene expression within the ROI. This visualization can reveal patterns of gene expression, such as high expression in specific cell types or regions, helping to interpret the biological significance of the data.\n\ngene_of_interest = 'Cst3'\n\nif gene_of_interest in expression_matrix.columns:\n    cell_ids = expression_matrix.index.values\n    expression_values = expression_matrix[gene_of_interest].values\n\n    # Get centroids of cells\n    from skimage.measure import regionprops\n    properties = regionprops(masks)\n    centroids = np.array([prop.centroid for prop in properties])\n    cell_labels = np.array([prop.label for prop in properties])\n\n    # Create a mapping from cell label to centroid\n    centroid_dict = {label: centroid for label, centroid in zip(cell_labels, centroids)}\n\n    # Get centroids for the cells in expression_matrix\n    cell_centroids = np.array([centroid_dict.get(cell_id, (np.nan, np.nan)) for cell_id in cell_ids])\n\n    # Plot\n    plt.figure(figsize=(8, 8))\n    plt.imshow(roi_image, cmap='gray')\n    plt.scatter(\n        cell_centroids[:, 1],  # x-coordinates\n        cell_centroids[:, 0],  # y-coordinates\n        c=expression_values,\n        cmap='viridis',\n        s=50,\n        edgecolors='k',\n        label=f'Expression of {gene_of_interest}'\n    )\n    plt.title(f'Expression of {gene_of_interest}')\n    plt.axis('off')\n    plt.colorbar(label='Expression Level')\n    plt.show()\nelse:\n    print(f\"{gene_of_interest} not found in expression matrix.\")\n\n\n\n\n\n\n\n\nnow we want to compare the cellpose segmentation with 10x segmentation, we can use the Jaccard index to quantify the similarity between the two segmentation masks. The Jaccard index, also known as the intersection-over-union (IoU), measures the overlap between two sets by dividing the size of their intersection by the size of their union. In the context of segmentation masks, the Jaccard index provides a measure of how well two masks align, with values closer to 1 indicating greater similarity.\n\ncells_data_path = 'data/Xenium_V1_FFPE_TgCRND8_17_9_months_outs/cells.csv'\ncells_data = pd.read_csv(cells_data_path)\nprint(cells_data.head())\n\n      cell_id  x_centroid  y_centroid  transcript_counts  \\\n0  aaabiggh-1  831.785336  755.803772                554   \n1  aaacfoel-1  821.733453  768.910446                291   \n2  aaaeefil-1  831.932053  780.367651                220   \n3  aaaehidd-1  853.614108  774.764157               1029   \n4  aaagcbkg-1  821.639603  799.171515                453   \n\n   control_probe_counts  control_codeword_counts  unassigned_codeword_counts  \\\n0                     0                        0                           0   \n1                     0                        0                           0   \n2                     1                        0                           0   \n3                     0                        0                           0   \n4                     0                        0                           1   \n\n   total_counts   cell_area  nucleus_area  \n0           554  509.091563     65.386250  \n1           291  275.498281     36.982969  \n2           221  261.635312     15.849844  \n3          1029  818.547344    129.056563  \n4           454  522.232031     96.002188  \n\n\n\ncell_boundaries_path = 'data/Xenium_V1_FFPE_TgCRND8_17_9_months_outs/cell_boundaries.csv.gz'  \ncell_boundaries = pd.read_csv(cell_boundaries_path)\nprint(cell_boundaries.head())\n\n      cell_id  vertex_x  vertex_y\n0  aaabiggh-1  829.6000  742.0500\n1  aaabiggh-1  816.6375  752.6750\n2  aaabiggh-1  815.3625  757.9875\n3  aaabiggh-1  822.5875  761.3875\n4  aaabiggh-1  835.9750  768.6125\n\n\nFirst we need to extract the region of intrest from the 10x segmentation mask, then we need to resize the 10x segmentation mask to the same size as the cellpose segmentation mask, then we can calculate the Jaccard index between the two masks.\n\nscale_factor = 0.05\nimage_height, image_width = image_channel.shape\nroi_width = int(image_width * scale_factor)\nroi_height = int(image_height * scale_factor)\n\nroi_width -= roi_width % 2\nroi_height -= roi_height % 2\n\nx_center = image_width // 2\ny_center = image_height // 2\n\nx_start = x_center - roi_width // 2\nx_end = x_center + roi_width // 2\ny_start = y_center - roi_height // 2\ny_end = y_center + roi_height // 2\n\n#cnvert pixel coordinates to micrometers\nx_scale = 1 / 0.2125  \ny_scale = 1 / 0.2125\n\nx_start_um = x_start / x_scale\nx_end_um = x_end / x_scale\ny_start_um = y_start / y_scale\ny_end_um = y_end / y_scale\n\nFilter cells whose centroids are within the ROI\n\ncells_in_roi = cells_data[\n    (cells_data['x_centroid'] &gt;= x_start_um) &\n    (cells_data['x_centroid'] &lt; x_end_um) &\n    (cells_data['y_centroid'] &gt;= y_start_um) &\n    (cells_data['y_centroid'] &lt; y_end_um)\n].copy()\n\nprint(f\"Number of cells in ROI from original segmentation: {len(cells_in_roi)}\")\n\nNumber of cells in ROI from original segmentation: 284\n\n\nFilter cell boundaries for cells in ROI\n\ncell_boundaries_in_roi = cell_boundaries[cell_boundaries['cell_id'].isin(cells_in_roi['cell_id'])].copy()\ncell_polygons = {}\nfor cell_id, group in cell_boundaries_in_roi.groupby('cell_id'):\n    x_coords = group['vertex_x'].values\n    y_coords = group['vertex_y'].values\n    coords = list(zip(x_coords, y_coords))\n    try:\n        polygon = Polygon(coords)\n        if not polygon.is_valid:\n            # Attempt to fix invalid polygons\n            polygon = polygon.buffer(0)\n        cell_polygons[cell_id] = polygon\n    except TopologicalError as e:\n        print(f\"Could not create polygon for cell {cell_id}: {e}\")\n\n\n# Function to transform geometries to pixel coordinates\ndef geometry_to_pixel_coords(geometry):\n    # Shift geometry to ROI coordinates (subtract ROI origin in micrometers)\n    geometry_shifted = translate(geometry, xoff=-x_start_um, yoff=-y_start_um)\n    # Scale geometry from micrometers to pixels\n    geometry_scaled = scale(geometry_shifted, xfact=x_scale, yfact=y_scale, origin=(0, 0))\n    return geometry_scaled\n\n# Apply transformation to all cell polygons\ncell_polygons_px = {cell_id: geometry_to_pixel_coords(geom) for cell_id, geom in cell_polygons.items()}\n\nMap cell_id strings to integer labels\n\ncell_id_to_label = {cell_id: idx+1 for idx, cell_id in enumerate(cell_polygons_px.keys())}\nlabel_to_cell_id = {idx+1: cell_id for idx, cell_id in enumerate(cell_polygons_px.keys())}\n\nPrepare shapes for rasterization\n\nshapes = [\n    (geom, cell_id_to_label[cell_id])\n    for cell_id, geom in cell_polygons_px.items()\n]\n\nCreate an empty mask and rasterize the shapes\n\noriginal_masks = np.zeros_like(roi_image, dtype=np.uint16)\noriginal_masks = features.rasterize(\n    shapes,\n    out_shape=original_masks.shape,\n    fill=0,\n    all_touched=True,\n    dtype=np.uint16\n)\n\nLets compare the cellpose segmentation with 10x segmentation side by side\n\nplt.figure(figsize=(16, 8))\n\n#Cellpose \nplt.subplot(1, 2, 1)\nplt.imshow(roi_image, cmap='gray')\nplt.imshow(masks, alpha=0.5, cmap='jet')\nplt.title('Cellpose Segmentation')\nplt.axis('off')\n\n#Original \nplt.subplot(1, 2, 2)\nplt.imshow(roi_image, cmap='gray')\nplt.imshow(original_masks, alpha=0.5, cmap='jet')\nplt.title('Original 10x Segmentation')\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAnd we can overlay the cellpose segmentation on the 10x segmentation to see how well they align\n\n# Overlay both masks\nplt.figure(figsize=(8, 8))\nplt.imshow(roi_image, cmap='gray')\nplt.imshow((original_masks &gt; 0).astype(int), cmap='Blues', alpha=0.5, label='Original')\nplt.imshow((masks &gt; 0).astype(int), cmap='Reds', alpha=0.5, label='Cellpose')\nplt.title('Overlay of Segmentations')\nplt.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\n\n# Convert masks to binary masks (cells vs background)\ncellpose_mask_binary = (masks &gt; 0).astype(int)\noriginal_mask_binary = (original_masks &gt; 0).astype(int)\n\n# Flatten the masks for metric computation\ncellpose_mask_flat = cellpose_mask_binary.flatten()\noriginal_mask_flat = original_mask_binary.flatten()\n\n\n\njaccard = jaccard_score(original_mask_flat, cellpose_mask_flat)\nprint(f'Jaccard Index: {jaccard:.4f}')\n\nJaccard Index: 0.1255\n\n\n\ndef dice_coefficient(y_true, y_pred):\n    intersection = np.sum(y_true * y_pred)\n    sum_union = np.sum(y_true) + np.sum(y_pred)\n    dice = 2 * intersection / sum_union\n    return dice\n\ndice = dice_coefficient(original_mask_flat, cellpose_mask_flat)\nprint(f'Dice Coefficient: {dice:.4f}')\n\nDice Coefficient: 0.2230\n\n\n\ncellpose_cell_count = masks.max()\noriginal_cell_count = original_masks.max()\n\nprint(f\"Number of cells detected by Cellpose: {cellpose_cell_count}\")\nprint(f\"Number of cells in original segmentation: {original_cell_count}\")\n\nNumber of cells detected by Cellpose: 224\nNumber of cells in original segmentation: 284\n\n\n\n# Cellpose cell areas\ncellpose_props = regionprops_table(masks, properties=['area'])\ncellpose_areas = pd.DataFrame(cellpose_props)\ncellpose_areas['method'] = 'Cellpose'\n\n# Original cell areas\noriginal_props = regionprops_table(original_masks, properties=['area'])\noriginal_areas = pd.DataFrame(original_props)\noriginal_areas['method'] = 'Original'\n\n# Combine data\nareas_df = pd.concat([cellpose_areas, original_areas], ignore_index=True)\n\ncompare cell sizes between the two segmentation methods\n\nplt.figure(figsize=(10, 6))\nsns.kdeplot(data=areas_df, x='area', hue='method', common_norm=False)\nplt.xlabel('Cell Area (pixels)')\nplt.ylabel('Density')\nplt.title('Cell Size Distribution Comparison')\nplt.show()\n\n\n\n\n\n\n\n\nand save the results to a new file\n\ntifffile.imwrite('data/Xenium_V1_FFPE_TgCRND8_17_9_months_outs/cellpose/cellpose_masks_roi.tif', masks.astype(np.uint16))\ntifffile.imwrite('data/Xenium_V1_FFPE_TgCRND8_17_9_months_outs/cellpose/original_masks_roi.tif', original_masks.astype(np.uint16))\n\n\nmetrics = pd.DataFrame({\n    'Metric': ['Jaccard Index', 'Dice Coefficient'],\n    'Value': [jaccard, dice]\n})\nmetrics.to_csv('data/Xenium_V1_FFPE_TgCRND8_17_9_months_outs/cellpose/segmentation_comparison_metrics.csv', index=False)\n\n\nareas_df.to_csv('data/Xenium_V1_FFPE_TgCRND8_17_9_months_outs/cellpose/cell_size_comparison.csv', index=False)"
  },
  {
    "objectID": "day_3/practical_4/niche_and_domain_reconstruction.html",
    "href": "day_3/practical_4/niche_and_domain_reconstruction.html",
    "title": "Niche reconstruction and spatial domain detection",
    "section": "",
    "text": "Author: Francesca Drummer\nimport squidpy as sq\nimport scanpy as sc\nWhen dealing with spatial transcriptomics datasets we might be interested in defining structures in the tissue. Some tissue structures that are interesting are: cell neighborhoods, niches, microenvironments or spatial domains. In literature these terms are sometimes used interchangably but here we will distinguish them using the Nicheformer definition."
  },
  {
    "objectID": "day_3/practical_4/niche_and_domain_reconstruction.html#dataset",
    "href": "day_3/practical_4/niche_and_domain_reconstruction.html#dataset",
    "title": "Niche reconstruction and spatial domain detection",
    "section": "Dataset",
    "text": "Dataset\nWe will use the Xenium AD dataset here.\n\nPATH = '/Users/francesca.drummer/Documents/1_Projects/jaekel/data/xenium_ad.h5ad'\n\n\n# load adata\nadata = sc.read_h5ad(PATH)\nadata\n\nAnnData object with n_obs × n_vars = 44955 × 354\n    obs: 'cell_id', 'x_centroid', 'y_centroid', 'transcript_counts', 'control_probe_counts', 'control_codeword_counts', 'unassigned_codeword_counts', 'total_counts', 'cell_area', 'nucleus_area', 'condition'\n    var: 'gene_ids', 'feature_types', 'genome'\n    obsm: 'spatial'"
  },
  {
    "objectID": "day_3/practical_4/niche_and_domain_reconstruction.html#cell-neighborhood-detection-via-graph-construction",
    "href": "day_3/practical_4/niche_and_domain_reconstruction.html#cell-neighborhood-detection-via-graph-construction",
    "title": "Niche reconstruction and spatial domain detection",
    "section": "1. Cell neighborhood detection via graph construction",
    "text": "1. Cell neighborhood detection via graph construction\nSpatial transcriptomics data can be represented as graphs with cells as nodes and edges as relations. Depending on the technology (imaging-based or sequencing-based) different assumptions can be made for the graph structure.\nHere we will explore graph construction and cell neighborhood analysis using the squidpy sq.gr module on imaging-based data.\nInformation for graph reconstruciton for sequencing-based data can be found here.\nFirst we construct a graph from the ST data based on number of neighbors to include.\n\nsq.gr.spatial_neighbors(adata, n_neighs=10, coord_type=\"generic\", key_added = 'neighs_based_spatial')\nsq.pl.spatial_scatter(\n    adata,\n    shape=None,\n    #library_key = '', TODO: Which library key indicates different FOV?\n    color=\"condition\",\n    connectivity_key=\"neighs_based_spatial_connectivities\",\n    size=10,\n)\n\nWARNING: Please specify a valid `library_id` or set it permanently in `adata.uns['spatial']`\n\n\n/Users/francesca.drummer/miniconda3/envs/nicheformer-data/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:747: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if c is not None and c in adata.obs and is_categorical_dtype(adata.obs[c]):\n/Users/francesca.drummer/miniconda3/envs/nicheformer-data/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:471: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if not is_categorical_dtype(color_source_vector):\n/Users/francesca.drummer/miniconda3/envs/nicheformer-data/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:483: FutureWarning: The default value of 'ignore' for the `na_action` parameter in pandas.Categorical.map is deprecated and will be changed to 'None' in a future version. Please set na_action to the desired value to avoid seeing this warning\n  color_vector = color_source_vector.map(color_map)\n/Users/francesca.drummer/miniconda3/envs/nicheformer-data/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:956: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap', 'norm' will be ignored\n  _cax = scatter(\n/Users/francesca.drummer/miniconda3/envs/nicheformer-data/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:649: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if is_categorical_dtype(color_source_vector):\n\n\n\n\n\n\n\n\n\n\nsq.gr.spatial_neighbors(adata, radius=0.3, coord_type=\"generic\", key_added = 'radius_based_spatial')\nsq.pl.spatial_scatter(\n    adata,\n    shape=None,\n    #library_key = '', TODO: Which library key indicates different FOV?\n    color=\"condition\",\n    connectivity_key=\"radius_based_spatial_connectivities\",\n    size=10,\n)\n\nWARNING: Please specify a valid `library_id` or set it permanently in `adata.uns['spatial']`\n\n\n/Users/francesca.drummer/miniconda3/envs/nicheformer-data/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:747: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if c is not None and c in adata.obs and is_categorical_dtype(adata.obs[c]):\n/Users/francesca.drummer/miniconda3/envs/nicheformer-data/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:471: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if not is_categorical_dtype(color_source_vector):\n/Users/francesca.drummer/miniconda3/envs/nicheformer-data/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:483: FutureWarning: The default value of 'ignore' for the `na_action` parameter in pandas.Categorical.map is deprecated and will be changed to 'None' in a future version. Please set na_action to the desired value to avoid seeing this warning\n  color_vector = color_source_vector.map(color_map)\n/Users/francesca.drummer/miniconda3/envs/nicheformer-data/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:956: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap', 'norm' will be ignored\n  _cax = scatter(\n/Users/francesca.drummer/miniconda3/envs/nicheformer-data/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:649: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if is_categorical_dtype(color_source_vector):\n\n\n\n\n\n\n\n\n\nTask 1: What is the difference between the neighborhood and radius based approach? Quantify the difference using the centrality score and neighborhood enrichment."
  },
  {
    "objectID": "day_3/practical_4/niche_and_domain_reconstruction.html#cellular-niches",
    "href": "day_3/practical_4/niche_and_domain_reconstruction.html#cellular-niches",
    "title": "Niche reconstruction and spatial domain detection",
    "section": "2. Cellular niches",
    "text": "2. Cellular niches\nIn this section, we will analyse and define cellular niches by cell type composition."
  },
  {
    "objectID": "day_3/practical_4/niche_and_domain_reconstruction.html#spatial-domain-detection-with-cellcharter",
    "href": "day_3/practical_4/niche_and_domain_reconstruction.html#spatial-domain-detection-with-cellcharter",
    "title": "Niche reconstruction and spatial domain detection",
    "section": "3. Spatial Domain detection with CellCharter",
    "text": "3. Spatial Domain detection with CellCharter"
  }
]