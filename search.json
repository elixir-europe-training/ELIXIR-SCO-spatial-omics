[
  {
    "objectID": "practicals.html",
    "href": "practicals.html",
    "title": "Practicals",
    "section": "",
    "text": "This course consists of multiple practicals. During the four days we will go through practical 0 till 6 (more info in the schedule). Each practical has a dedicated directory in the repository, and comes with:\n\nA container image: you will receive a link for each practical to your personal environment during the course.\nOne or more notebooks with the name p[practical number]_topic.ipynb. So for practical 1, we have a notebook called p1_segmentation.ipynb.\nOne or more conda environments in the image corresponding to each notebook, e.g. p1_segmentation.ipynb."
  },
  {
    "objectID": "practicals.html#introduction",
    "href": "practicals.html#introduction",
    "title": "Practicals",
    "section": "",
    "text": "This course consists of multiple practicals. During the four days we will go through practical 0 till 6 (more info in the schedule). Each practical has a dedicated directory in the repository, and comes with:\n\nA container image: you will receive a link for each practical to your personal environment during the course.\nOne or more notebooks with the name p[practical number]_topic.ipynb. So for practical 1, we have a notebook called p1_segmentation.ipynb.\nOne or more conda environments in the image corresponding to each notebook, e.g. p1_segmentation.ipynb."
  },
  {
    "objectID": "practicals.html#working-on-the-practicals",
    "href": "practicals.html#working-on-the-practicals",
    "title": "Practicals",
    "section": "Working on the practicals",
    "text": "Working on the practicals\nTo start working on the practicals, navigate to the provided spreadsheet with server login information, click on the link next to your name that links to the corresponding practical. Then, use the password associated with your name to log in.\nNow you are in your personal container image. This image has two important directories that are mounted to all container images that are avaiable to you:\n\n/home/jovyan/workdir: a directory in home for which you have read and write access. This is where you will be mainly working in.\n/data: a directory where you only have read access. From here you can read the available input data.\n\nAt the first login, open a terminal, navigate to /home/jovyan/workdir and clone the repository:\ngit clone https://github.com/elixir-europe-training/ELIXIR-SCO-spatial-omics.git\nAfter cloning you can use the navigation menu to open a notebook. With each notebook, use the associated environment (has the same name as the notebook)."
  },
  {
    "objectID": "day_3/practical_4/niche_and_domain_reconstruction.html",
    "href": "day_3/practical_4/niche_and_domain_reconstruction.html",
    "title": "Niche reconstruction and spatial domain detection",
    "section": "",
    "text": "Author: Francesca Drummer\nimport squidpy as sq\nimport scanpy as sc\nWhen dealing with spatial transcriptomics datasets we might be interested in defining structures in the tissue. Some tissue structures that are interesting are: cell neighborhoods, niches, microenvironments or spatial domains. In literature these terms are sometimes used interchangably but here we will distinguish them using the Nicheformer definition."
  },
  {
    "objectID": "day_3/practical_4/niche_and_domain_reconstruction.html#dataset",
    "href": "day_3/practical_4/niche_and_domain_reconstruction.html#dataset",
    "title": "Niche reconstruction and spatial domain detection",
    "section": "Dataset",
    "text": "Dataset\nWe will use the Xenium AD dataset here.\n\nPATH = '/Users/francesca.drummer/Documents/1_Projects/jaekel/data/xenium_ad.h5ad'\n\n\n# load adata\nadata = sc.read_h5ad(PATH)\nadata\n\nAnnData object with n_obs × n_vars = 44955 × 354\n    obs: 'cell_id', 'x_centroid', 'y_centroid', 'transcript_counts', 'control_probe_counts', 'control_codeword_counts', 'unassigned_codeword_counts', 'total_counts', 'cell_area', 'nucleus_area', 'condition'\n    var: 'gene_ids', 'feature_types', 'genome'\n    obsm: 'spatial'"
  },
  {
    "objectID": "day_3/practical_4/niche_and_domain_reconstruction.html#cell-neighborhood-detection-via-graph-construction",
    "href": "day_3/practical_4/niche_and_domain_reconstruction.html#cell-neighborhood-detection-via-graph-construction",
    "title": "Niche reconstruction and spatial domain detection",
    "section": "1. Cell neighborhood detection via graph construction",
    "text": "1. Cell neighborhood detection via graph construction\nSpatial transcriptomics data can be represented as graphs with cells as nodes and edges as relations. Depending on the technology (imaging-based or sequencing-based) different assumptions can be made for the graph structure.\nHere we will explore graph construction and cell neighborhood analysis using the squidpy sq.gr module on imaging-based data.\nInformation for graph reconstruciton for sequencing-based data can be found here.\nFirst we construct a graph from the ST data based on number of neighbors to include.\n\nsq.gr.spatial_neighbors(adata, n_neighs=10, coord_type=\"generic\", key_added = 'neighs_based_spatial')\nsq.pl.spatial_scatter(\n    adata,\n    shape=None,\n    #library_key = '', TODO: Which library key indicates different FOV?\n    color=\"condition\",\n    connectivity_key=\"neighs_based_spatial_connectivities\",\n    size=10,\n)\n\nWARNING: Please specify a valid `library_id` or set it permanently in `adata.uns['spatial']`\n\n\n/Users/francesca.drummer/miniconda3/envs/nicheformer-data/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:747: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if c is not None and c in adata.obs and is_categorical_dtype(adata.obs[c]):\n/Users/francesca.drummer/miniconda3/envs/nicheformer-data/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:471: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if not is_categorical_dtype(color_source_vector):\n/Users/francesca.drummer/miniconda3/envs/nicheformer-data/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:483: FutureWarning: The default value of 'ignore' for the `na_action` parameter in pandas.Categorical.map is deprecated and will be changed to 'None' in a future version. Please set na_action to the desired value to avoid seeing this warning\n  color_vector = color_source_vector.map(color_map)\n/Users/francesca.drummer/miniconda3/envs/nicheformer-data/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:956: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap', 'norm' will be ignored\n  _cax = scatter(\n/Users/francesca.drummer/miniconda3/envs/nicheformer-data/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:649: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if is_categorical_dtype(color_source_vector):\n\n\n\n\n\n\n\n\n\n\nsq.gr.spatial_neighbors(adata, radius=0.3, coord_type=\"generic\", key_added = 'radius_based_spatial')\nsq.pl.spatial_scatter(\n    adata,\n    shape=None,\n    #library_key = '', TODO: Which library key indicates different FOV?\n    color=\"condition\",\n    connectivity_key=\"radius_based_spatial_connectivities\",\n    size=10,\n)\n\nWARNING: Please specify a valid `library_id` or set it permanently in `adata.uns['spatial']`\n\n\n/Users/francesca.drummer/miniconda3/envs/nicheformer-data/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:747: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if c is not None and c in adata.obs and is_categorical_dtype(adata.obs[c]):\n/Users/francesca.drummer/miniconda3/envs/nicheformer-data/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:471: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if not is_categorical_dtype(color_source_vector):\n/Users/francesca.drummer/miniconda3/envs/nicheformer-data/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:483: FutureWarning: The default value of 'ignore' for the `na_action` parameter in pandas.Categorical.map is deprecated and will be changed to 'None' in a future version. Please set na_action to the desired value to avoid seeing this warning\n  color_vector = color_source_vector.map(color_map)\n/Users/francesca.drummer/miniconda3/envs/nicheformer-data/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:956: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap', 'norm' will be ignored\n  _cax = scatter(\n/Users/francesca.drummer/miniconda3/envs/nicheformer-data/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:649: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if is_categorical_dtype(color_source_vector):\n\n\n\n\n\n\n\n\n\nTask 1: What is the difference between the neighborhood and radius based approach? Quantify the difference using the centrality score and neighborhood enrichment."
  },
  {
    "objectID": "day_3/practical_4/niche_and_domain_reconstruction.html#cellular-niches",
    "href": "day_3/practical_4/niche_and_domain_reconstruction.html#cellular-niches",
    "title": "Niche reconstruction and spatial domain detection",
    "section": "2. Cellular niches",
    "text": "2. Cellular niches\nIn this section, we will analyse and define cellular niches by cell type composition."
  },
  {
    "objectID": "day_3/practical_4/niche_and_domain_reconstruction.html#spatial-domain-detection-with-cellcharter",
    "href": "day_3/practical_4/niche_and_domain_reconstruction.html#spatial-domain-detection-with-cellcharter",
    "title": "Niche reconstruction and spatial domain detection",
    "section": "3. Spatial Domain detection with CellCharter",
    "text": "3. Spatial Domain detection with CellCharter"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Spatial Omics Data Analysis",
    "section": "Overview",
    "text": "Overview\nThis course delves into the cutting-edge field of Spatial Omics, focusing on Spatially-Resolved Transcriptomics (SRT) technology which provides unprecedented insights into the spatial organization of gene expression within tissues. The rapid and recent advances in SRT technology are transforming our understanding of biological systems, and this course is designed to equip researchers with the tools to harness the power of SRT, adding significant value to biological knowledge and opening new avenues for scientific discovery.\nParticipants will explore both imaging-based and sequencing-based SRT technologies, learning to navigate the entire workflow of SRT data analysis. The course covers essential topics such as pre-processing techniques for data cleaning, normalization, and quality control, methods for identifying and characterizing spatial domains within tissues, strategies for integrating SRT data with single-cell RNA sequencing data, and statistical approaches to analyze spatial patterns and relationships. Additionally, participants will investigate interactions between cells within their spatial context. By the end of this course, participants will be equipped with the knowledge and skills to construct a complete workflow for SRT data analysis, from raw data to meaningful biological insights. The course combines lectures with practical sessions, ensuring a balanced approach to theory and hands-on experience."
  },
  {
    "objectID": "index.html#venue-and-time",
    "href": "index.html#venue-and-time",
    "title": "Spatial Omics Data Analysis",
    "section": "Venue and time",
    "text": "Venue and time\nThis course will take place at the University of Lausanne (UNIL), in the Synathlon building of the campus. More info on UNIL access, map and transport.\nThe course will start the first day at 13:00. Find a detailed schedule here.\nA lunch will be provided before the start of the course as well as at the end of the course on the last day. All participants are invited to the social dinner, organized on 21 January 2024."
  },
  {
    "objectID": "index.html#audience",
    "href": "index.html#audience",
    "title": "Spatial Omics Data Analysis",
    "section": "Audience",
    "text": "Audience\nThis 3-day course is addressed to PhD students, postdocs, and researchers who are involved (or will be in the near future) in projects including spatially-resolved transcriptomics data, and want to acquire the skills to get started with spatial data analysis."
  },
  {
    "objectID": "index.html#learning-outcomes",
    "href": "index.html#learning-outcomes",
    "title": "Spatial Omics Data Analysis",
    "section": "Learning outcomes",
    "text": "Learning outcomes\nAt the end of the course, the participants will be able to:\n\nIdentify and recall key concepts and terminology related to imaging- and sequencing-based SRT technologies.\nAssess and evaluate quality of SRT data.\nPerform standard SRT data analysis, including data cleaning, normalization, quality control.\nExamine and interpret spatial patterns and relationships within SRT data using statistical and machine learning approaches.\nConstruct a comprehensive workflow for SRT data analysis, from raw data to meaningful biological insights."
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "Spatial Omics Data Analysis",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nKnowledge / competencies\nParticipants should be proficient in Python and R, for basic data analysis.\nParticipants should be familiar with NGS technologies, have experience with analyzing (spatial/single-cell) transcriptomics data as well as basic knowledge of machine learning.\nParticipants should also have a basic understanding of working with command line tools on Unix-based systems. You can test your skills with Unix with the quiz here. If you do not feel comfortable with UNIX commands, please take our Unix fundamentals e-learning module.\n\n\nTechnical\nParticipants are required to bring your own laptop.\nWe will be mainly working on an Amazon Web Services (AWS) Elastic Cloud (EC2) server. Our Ubuntu server behaves like a ‘normal’ remote server, and can be approached through a web browser (safari, firefox, chrome etc.). All participants will be granted access to a personal workspace to be used during the course. The web interface will be approached through http (not https!), so make sure you can access http sites. You can validate it here.\nPlease perform these installations PRIOR to the course and contact us if you have any trouble."
  },
  {
    "objectID": "index.html#the-trainers",
    "href": "index.html#the-trainers",
    "title": "Spatial Omics Data Analysis",
    "section": "The trainers",
    "text": "The trainers\nThe course will feature the following lecturers and trainers:\n\nLars Borm (Katholieke Universiteit (KU) Leuven & Vlaams Instituut voor Biotechnologie (VIB), BE)\nHelena Crowell (Centro Nacional de Análisis Genómico (CNAG), ES)\nFrancesca Drummer (Helmholtz Zentrum München, DE)\nGeorge Gavrillidis (Centre for Research and Technology Hellas (CERTH), GR)\nGeert van Geest (SIB Swiss Institute of Bioinformatics, CH)\nNaveed Ishaque (Berlin Institute of Health (BIH), DE)\nAhmed Mahfouz (Leiden University Medical Center (LUMC), NL)\nMark Robinson (University of Zurich (UZH) & SIB, CH)\nYvan Saeys (University of Ghent (UGent) & Vlaams Instituut voor Biotechnologie (VIB), BE)\nRasool Saghaleyni (SciLifeLab, SE)\nAnna Schaar (Helmholtz Zentrum München, DE)\nMarco Varrone (University of Lausanne (UNIL) & SIB, CH)"
  },
  {
    "objectID": "index.html#additional-information",
    "href": "index.html#additional-information",
    "title": "Spatial Omics Data Analysis",
    "section": "Additional information",
    "text": "Additional information\nThis is an international course hosted by the SIB Swiss Institute of Bioinformatics (ELIXIR-CH) in collaboration with the ELIXIR Single-Cell Omics community, and trainers’ own institutions and affiliations to ELIXIR nodes (KU Leuven, VIB, CNAG, Helmholtz Zentrum München, CERTH, SIB, BIH, LUMC, UZH, UGent, SciLifeLab, UNIL).\nCourse organizers:\n\nAhmed Mahfouz, Leiden University Medical Center (LUMC), ELIXIR - Netherlands\nDiana Marek, SIB Training group, ELIXIR - Switzerland\nPatricia Palagi, SIB Training group, ELIXIR - Switzerland\nEija Korpelainen, CSC, ELIXIR - Finland\n\nThis course is partially funded by an ELIXIR Staff Exchange Programme.\nWe will recommend 0.75 ECTS credits for this course (given a passed assessment).\nYou are welcome to register to the SIB courses mailing list to be informed of all future courses and workshops, as well as all important deadlines using the form here.\nPlease note that participation in SIB courses is subject to our general conditions.\nCourse organizers and trainers abide by the ELIXIR Code of Conduct. Participants are also required to abide by the same code."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Time\nTopic\nTeacher\n\n\n\n\n12:00-13:00\nArrival and lunch\n\n\n\n13:00-13:15\nWelcome and course intro\nAhmed Mahfouz (LUMC, NL)\n\n\n13:15-14:00\nOverview of technologies\nLars Borm (KU Leuven, VIB, BE)\n\n\n14:00-14:45\nimaging-based spatial data analysis (preprocessing, data structures, cell segmentation, QC and normalization)\nHelena Crowell (CNAG, ES)\n\n\n14:45-15:15\nBreak\n\n\n\n15:15-16:00\nPractical 0: Data formats (SpatialData, AnnData,…)\nGeorge Gavrilidis\n\n\n16:00-17:00\nPractical 1a: imaging-based data QC and normalization\nRasool Saghaleyni"
  },
  {
    "objectID": "schedule.html#day-1",
    "href": "schedule.html#day-1",
    "title": "Schedule",
    "section": "",
    "text": "Time\nTopic\nTeacher\n\n\n\n\n12:00-13:00\nArrival and lunch\n\n\n\n13:00-13:15\nWelcome and course intro\nAhmed Mahfouz (LUMC, NL)\n\n\n13:15-14:00\nOverview of technologies\nLars Borm (KU Leuven, VIB, BE)\n\n\n14:00-14:45\nimaging-based spatial data analysis (preprocessing, data structures, cell segmentation, QC and normalization)\nHelena Crowell (CNAG, ES)\n\n\n14:45-15:15\nBreak\n\n\n\n15:15-16:00\nPractical 0: Data formats (SpatialData, AnnData,…)\nGeorge Gavrilidis\n\n\n16:00-17:00\nPractical 1a: imaging-based data QC and normalization\nRasool Saghaleyni"
  },
  {
    "objectID": "schedule.html#day-2",
    "href": "schedule.html#day-2",
    "title": "Schedule",
    "section": "Day 2",
    "text": "Day 2\n\n\n\n\n\n\n\n\nTime\nTopic\nTeacher\n\n\n\n\n09:00-09:45\nimaging-based spatial data analysis (segmentation-free analysis)\nNaveed Ishaque (BIH, DE)\n\n\n09:45-10:45\nPractical 1b: imaging-based data segmentation-free analysis + Practical 1c:segmentation (optional)\nRasool Saghaleyni\n\n\n10:45-11:15\nBreak\n\n\n\n11:15-12:00\nsequence-based data analysis (preprocessing, data structures, QC and normalization)\nAhmed Mahfouz (LUMC, NL)\n\n\n12:00-13:30\nLunch\n\n\n\n13:30-14:30\nPractical 2: sequence-based data analysis\nGeorge Gavrilidis\n\n\n14:30-15:15\nIntegration with scRNA-seq/deconvolution/annotation/imputation\nAhmed Mahfouz (LUMC, NL)\n\n\n15:15-15:45\nBreak\n\n\n\n15:45-16:45\nPractical 3: integration with scRNA-seq\nGeert van Geest"
  },
  {
    "objectID": "schedule.html#day-3",
    "href": "schedule.html#day-3",
    "title": "Schedule",
    "section": "Day 3",
    "text": "Day 3\n\n\n\n\n\n\n\n\nTime\nTopic\nTeacher\n\n\n\n\n09:00-09:45\nGraph representations/Niche reconstruction\nAnna Schaar (Helmholtz Munich, DE)\n\n\n09:45-10:30\nSpatial domain identification/spatial annotation\nMarco Varrone (UNIL, CH)\n\n\n10:30-11:00\nBreak\n\n\n\n11:00-12:30\nPractical 4: Niche reconstruction and domain identification\nFrancesca Drummer/Marco Varrone\n\n\n12:30-14:00\nLunch\n\n\n\n14:00-14:45\nSpatial statistics\nMark Robinson (Uni Zurich, CH)\n\n\n14:45-15:45\nPractical 5: spatial stats\nMark Robinson\n\n\n15:45-16:15\nBreak\n\n\n\n16:15-17:00\nGuest lecture:\nMaria Brbic (EPFL)"
  },
  {
    "objectID": "schedule.html#day-4",
    "href": "schedule.html#day-4",
    "title": "Schedule",
    "section": "Day 4",
    "text": "Day 4\n\n\n\n\n\n\n\n\nTime\nTopic\nTeaching\n\n\n\n\n09:00-09:45\ncell-cell communication (CCC)\nYvan Saeys (U Ghent, VIB, BE)\n\n\n09:45-10:45\nPractical 6: CCC\nFrancesca Drummer\n\n\n10:45-11:15\nBreak\n\n\n\n11:15-11:45\nFree practical time (finish stuff) / work on assignment\n\n\n\n11:45-12:00\nWrap-up (how)\n\n\n\n12:00-13:00\nLunch and departure"
  },
  {
    "objectID": "day_1/practical_1/workdir/practical_1_QC&Normalization.html",
    "href": "day_1/practical_1/workdir/practical_1_QC&Normalization.html",
    "title": "ELIXIR Spatial Transcriptomics Course",
    "section": "",
    "text": "Date: 2025-01-21\nAuthor(s): Rasool Saghaleyni, Åsa Björklund\nAuthor(s) email: rasool.saghaleyni@scilifelab.se, asa.bjorklund@scilifelab.se\n⚠️ Note: The proper environment for this notebook is imaging_based_data_analysis_env. It can be activated by selecting the kernel in the Jupyter notebook."
  },
  {
    "objectID": "day_1/practical_1/workdir/practical_1_QC&Normalization.html#loading-packages",
    "href": "day_1/practical_1/workdir/practical_1_QC&Normalization.html#loading-packages",
    "title": "ELIXIR Spatial Transcriptomics Course",
    "section": "Loading packages",
    "text": "Loading packages\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\nimport seaborn as sns\nimport scanpy as sc\nimport squidpy as sq\nimport scipy.sparse as sp\nfrom scipy.stats import gaussian_kde\nfrom scipy.signal import find_peaks, argrelextrema\nfrom scipy.sparse import issparse, csr_matrix\nfrom diptest import diptest\nimport statsmodels.api as sm\nfrom shapely.geometry import Point, Polygon, MultiPoint\nfrom scipy.spatial import ConvexHull\nimport sys\nsys.path.append('./custom')\nimport tenx_method_nb_helper_functions as hf"
  },
  {
    "objectID": "day_1/practical_1/workdir/practical_1_QC&Normalization.html#dataset-description-and-the-design-of-the-experiment",
    "href": "day_1/practical_1/workdir/practical_1_QC&Normalization.html#dataset-description-and-the-design-of-the-experiment",
    "title": "ELIXIR Spatial Transcriptomics Course",
    "section": "Dataset description and the design of the experiment",
    "text": "Dataset description and the design of the experiment\nBefore starting the analysis, please make that you know about the biological background, experimental design and the data structure for the datset that we will do the analysis on it. Here you can find good information about this: https://pages.10xgenomics.com/rs/446-PBO-704/images/10x_LIT000210_App-Note_Xenium-In-Situ_Letter_Digital.pdf"
  },
  {
    "objectID": "day_1/practical_1/workdir/practical_1_QC&Normalization.html#loading-data-and-primary-inspections",
    "href": "day_1/practical_1/workdir/practical_1_QC&Normalization.html#loading-data-and-primary-inspections",
    "title": "ELIXIR Spatial Transcriptomics Course",
    "section": "Loading data and primary inspections",
    "text": "Loading data and primary inspections\nMaking adata object considering the transcripts that should be used for the analysis. Running analysis on the transcripts that are only in the nucleus.\nData was downloaded from 10x at https://cf.10xgenomics.com/samples/xenium/1.4.0/Xenium_V1_FFPE_TgCRND8_17_9_months/Xenium_V1_FFPE_TgCRND8_17_9_months_outs.zip and unzipped in folder data/.\n\nsample_path = \"../data/Xenium_V1_FFPE_TgCRND8_17_9_months_outs\"\n# sample_path = \"/data/raw_data/Xenium_V1_FFPE_TgCRND8_17_9_months_outs\"\ntranscripts_csv_path = os.path.join(sample_path, \"transcripts.csv.gz\")\ntranscripts_df = pd.read_csv(transcripts_csv_path, compression='gzip')\nnucleus_boundaries_gz_path = os.path.join(sample_path, \"nucleus_boundaries.csv.gz\")\nnucleus_df = pd.read_csv(nucleus_boundaries_gz_path, compression='gzip')\nif not os.path.exists(os.path.join(sample_path, \"cells.csv\")):\n    hf.decompress_file(os.path.join(sample_path, \"cells.csv.gz\"))\n\n\nMaking the adata object\n\nadata = hf.create_adata(sample_path, nucleus_genes_only = False)\nadata\n\nAnnData object with n_obs × n_vars = 62268 × 347\n    obs: 'cell_id', 'x_centroid', 'y_centroid', 'transcript_counts', 'control_probe_counts', 'control_codeword_counts', 'unassigned_codeword_counts', 'total_counts', 'cell_area', 'nucleus_area'\n    var: 'gene_ids', 'feature_types', 'genome'\n    obsm: 'spatial'\n\n\nThe AnnData object, adata, contains a structured dataset with cells as observations (n_obs = 62268) and genes as variables (n_vars = 347). Here’s a breakdown of the main components within adata:\n\nadata.obs\n\n\n\n\n\n\n\n\ncell_id\nx_centroid\ny_centroid\ntranscript_counts\ncontrol_probe_counts\ncontrol_codeword_counts\nunassigned_codeword_counts\ntotal_counts\ncell_area\nnucleus_area\n\n\n\n\naaabiggh-1\naaabiggh-1\n831.785336\n755.803772\n554\n0\n0\n0\n554\n509.091563\n65.386250\n\n\naaacfoel-1\naaacfoel-1\n821.733453\n768.910446\n291\n0\n0\n0\n291\n275.498281\n36.982969\n\n\naaaeefil-1\naaaeefil-1\n831.932053\n780.367651\n220\n1\n0\n0\n221\n261.635312\n15.849844\n\n\naaaehidd-1\naaaehidd-1\n853.614108\n774.764157\n1029\n0\n0\n0\n1029\n818.547344\n129.056563\n\n\naaagcbkg-1\naaagcbkg-1\n821.639603\n799.171515\n453\n0\n0\n1\n454\n522.232031\n96.002188\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\noindmjog-1\noindmjog-1\n5068.380664\n4446.804883\n35\n0\n0\n0\n35\n229.709844\n15.985312\n\n\noinecaba-1\noinecaba-1\n5072.841504\n4459.385132\n124\n0\n0\n0\n124\n359.353438\n18.423750\n\n\noinehfmf-1\noinehfmf-1\n5251.196240\n4366.193091\n15\n0\n0\n0\n15\n686.329844\n24.745625\n\n\noinemiil-1\noinemiil-1\n5248.493506\n4382.190356\n22\n0\n0\n0\n22\n333.478906\n20.681562\n\n\noingfoec-1\noingfoec-1\n5272.023315\n4387.369629\n18\n0\n0\n0\n18\n750.948438\n9.798906\n\n\n\n\n62268 rows × 10 columns\n\n\n\nobs (Observations): This table contains metadata about each cell, where each row corresponds to a cell, and each column holds information about a specific attribute:\n\ncell_id: Unique identifier for each cell.\nx_centroid and y_centroid: Coordinates of each cell’s center in the spatial layout, indicating where each cell is located within the tissue.\ntranscript_counts: Total transcript counts for each cell, showing the overall gene expression level.\ncontrol_probe_counts and control_codeword_counts: Counts related to control probes and codewords, which are often used for quality control in spatial transcriptomics.\nunassigned_codeword_counts and deprecated_codeword_counts: Counts of unassigned or deprecated codewords, indicating low-confidence or outdated identifiers.\ntotal_counts: Total counts across all measured attributes, representing the cell’s total signal.\ncell_area and nucleus_area: Physical measurements of the cell and its nucleus area, in pixels or micrometers.\n\n\nadata.var\n\n\n\n\n\n\n\n\ngene_ids\nfeature_types\ngenome\n\n\n\n\n2010300C02Rik\nENSMUSG00000026090\nGene Expression\nUnknown\n\n\nAbca7\nENSMUSG00000035722\nGene Expression\nUnknown\n\n\nAcsbg1\nENSMUSG00000032281\nGene Expression\nUnknown\n\n\nActa2\nENSMUSG00000035783\nGene Expression\nUnknown\n\n\nAcvrl1\nENSMUSG00000000530\nGene Expression\nUnknown\n\n\n...\n...\n...\n...\n\n\nVwc2l\nENSMUSG00000045648\nGene Expression\nUnknown\n\n\nWfs1\nENSMUSG00000039474\nGene Expression\nUnknown\n\n\nZfp366\nENSMUSG00000050919\nGene Expression\nUnknown\n\n\nZfp536\nENSMUSG00000043456\nGene Expression\nUnknown\n\n\nZfpm2\nENSMUSG00000022306\nGene Expression\nUnknown\n\n\n\n\n347 rows × 3 columns\n\n\n\nvar (Variables): This table contains metadata about each gene, where each row is a gene and each column is an attribute:\n\ngene_ids: Unique identifiers for each gene, often in Ensembl or another standardized format.\nfeature_types: Type of feature associated with each gene, such as “gene” or “transcript.”\ngenome: Information about the genome source of each gene, like “human” or “mouse.”\n\nobsm (Multi-dimensional Observations): This slot contains multi-dimensional data related to cells. Here, spatial stores spatial coordinates for each cell, allowing visualization and spatial analysis of cells in their tissue context.\n\nadata.obs['total_counts'] = adata.X.sum(axis=1)\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['total_counts'], kde='True', bins=50)\nplt.xlabel(\"Total Transcript Counts per Cell\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Total Transcript Counts per Cell\")\nplt.show()\n\n\n\n\n\n\n\n\nWe calculate the total transcript counts for each cell by summing gene expression values across all genes and the number of genes detected in each cell. The resulting distributions gives us an overview of the data quality and cellular diversity in terms of RNA content.\nThese provide a measure of each cell’s transcriptional activity or RNA content. High total counts typically indicate cells with higher transcriptional activity, while very low total counts may suggest low-quality cells or empty spots with minimal RNA. Examining this distribution helps us assess data quality and identify potential outliers:\n\nCells with Very Low Counts: These may represent low-quality cells or background noise, which could be filtered out in subsequent steps to improve analysis accuracy.\nCells with Very High Counts: High total counts may indicate cell types with naturally high transcriptional activity or potential doublets (two cells counted as one).\n\nThis plot provides a quick check of the dataset’s quality and helps inform any initial filtering steps. A typical goal is to ensure the data has a reasonable distribution of RNA counts per cell, without excessive noise or artifacts that might skew downstream analysis.\n\nadata.obs['n_genes'] = (adata.X &gt; 0).sum(axis=1)\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['n_genes'], kde=True, bins=50)\nplt.xlabel(\"Number of Genes Detected per Cell\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Genes Detected per Cell\")\nplt.show()\n\n\n\n\n\n\n\n\nNow lets find genes with the highest expression across the whole dataset. We calculate the mean expression level of each gene across all cells and identify the top 10 most highly expressed genes, then plot them to understand which genes dominate the transcriptional landscape. This helps us quickly identify genes with the highest abundance, which are often either essential housekeeping genes or specific markers that define particular cell types. Examining the top expressed genes serves both technical and biological purposes: it allows us to check for any potential technical artifacts (e.g., genes with unusually high background expression) and offers biological insight by highlighting key genes likely involved in core cellular functions or distinguishing cell types.\n\n#calculate mean expression for each gene\nmean_expression = adata.X.mean(axis=0).A1\ntop_genes_idx = mean_expression.argsort()[::-1][:10]\ntop_genes = adata.var_names[top_genes_idx]\ntop_expression = mean_expression[top_genes_idx]\nplt.figure(figsize=(10, 5))\nsns.barplot(x=top_genes, y=top_expression)\nplt.xlabel(\"Genes\")\nplt.ylabel(\"Mean Expression\")\nplt.title(\"Top 10 Most Expressed Genes\")\nplt.xticks(rotation=45)\nplt.show()\n\n\n\n\n\n\n\n\nWe can also look into the distributions of cell and nucleus areas to assess segmentation quality and examine cell size diversity across the dataset. These distributions provide an overview of the range of cell and nucleus sizes, helping to identify segmentation artifacts or inconsistencies, such as unusually small areas (which may indicate partial cells or segmentation errors) or large areas (potentially indicating doublets or merged cells).\n\n#distribution of cell and nucleus areas\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['cell_area'], kde=True, bins=50)\nplt.xlabel(\"Cell Area\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Cell Areas\")\nplt.show()\n\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['nucleus_area'], kde=True, bins=50)\nplt.xlabel(\"Nucleus Area\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Nucleus Areas\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCell Area vs Nucleus Area\n\nplt.figure(figsize=(8, 6))\nplt.scatter(adata.obs['cell_area'], adata.obs['nucleus_area'], alpha=0.5)\nplt.xlabel(\"Cell Area\")\nplt.ylabel(\"Nucleus Area\")\nplt.title(\"Cell Area vs Nucleus Area\")\nplt.show()\n\n\n\n\n\n\n\n\nCalculate cell-to-nucleus area ratio and plot it. This ratio provides a measure of the relative size of the nucleus compared to the whole cell, which can be informative for understanding cell morphology and the distribution of nuclear material within cells. A high ratio may indicate cells with large nuclei relative to their overall size, which could be relevant for cell type classification or biological interpretation. Examining this ratio helps identify potential outliers or unusual cell morphologies that may require further investigation or filtering.\n\nadata.obs['area_ratio'] = adata.obs['nucleus_area'] / adata.obs['cell_area']\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['area_ratio'], kde=True, bins=50)\nplt.xlabel(\"Nucleus-to-Cell Area Ratio\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Nucleus-to-Cell Area Ratios\")\nplt.show()\n\n\n\n\n\n\n\n\nScatter plot of Cell Area vs Total Counts\n\nplt.figure(figsize=(8, 6))\nplt.scatter(adata.obs['cell_area'], adata.obs['total_counts'], alpha=0.5)\nplt.xlabel(\"Cell Area\")\nplt.ylabel(\"Total Transcript Counts\")\nplt.title(\"Cell Area vs Total Transcript Counts\")\nplt.show()\n\n\n\n\n\n\n\n\nSpatial plot of cell and nucleus areas.\n\n#cell area\nsc.pl.spatial(adata, color='cell_area', spot_size=10, title=\"Spatial Distribution of Cell Area\")\n\n#nucleus area\nsc.pl.spatial(adata, color='nucleus_area', spot_size=10, title=\"Spatial Distribution of Nucleus Area\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLooking to spatial distibution of one of the genes. For example the gene “MALL”\n\nsc.pl.spatial(adata, color=['Cst3'], spot_size=10, title=\"Cst3 Gene Expression\")\n\n\n\n\n\n\n\n\n\n#filter cells with nucleus area &lt; 5\ninitial_cells_count = adata.n_obs\nadata = adata[adata.obs['nucleus_area'] &gt;= 5].copy()\nfiltered_cells_count = adata.n_obs\nprint(f\"Filtered out {initial_cells_count - filtered_cells_count} cells with nucleus_area &lt; 5. Remaining cells: {filtered_cells_count}\")\n\nFiltered out 314 cells with nucleus_area &lt; 5. Remaining cells: 61954\n\n\nPlot distribution of total transcript counts per cell and distribution of Nucleus area after filtering\n\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['total_counts'], kde=True, bins=50)\nplt.xlabel(\"Total Transcript Counts per Cell\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Total Transcript Counts per Cell After Filtering\")\nplt.show()\n\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['nucleus_area'], kde=True, bins=50)\nplt.xlabel(\"Nucleus Area\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Nucleus Area After Filtering\")\nplt.show()"
  },
  {
    "objectID": "day_1/practical_1/workdir/practical_1_QC&Normalization.html#control-probes-and-decoding-metrics.",
    "href": "day_1/practical_1/workdir/practical_1_QC&Normalization.html#control-probes-and-decoding-metrics.",
    "title": "ELIXIR Spatial Transcriptomics Course",
    "section": "Control probes and decoding metrics.",
    "text": "Control probes and decoding metrics.\nwe can also look into the control probe counts and their spatial distribution to assess background noise and technical quality in the dataset. First, we plot the distribution of control probe counts across cells to understand how frequently control probes are detected. This distribution provides insights into potential technical noise or background signals, as higher-than-expected control counts may suggest artifacts or contamination. Next, we create a spatial plot of control probe counts, which allows us to see if any regions in the tissue exhibit unexpectedly high control counts, possibly indicating localized technical issues.\n\n#plot distribution of control probe counts\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['control_probe_counts'], kde=True, bins=50)\nplt.xlabel(\"Control Probe Counts\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Control Probe Counts\")\nplt.show()\n\n#spatial plot of control probe counts\nsc.pl.spatial(adata, color='control_probe_counts', spot_size=10, title=\"Spatial Distribution of Control Probe Counts\", cmap = 'viridis_r')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsc.pl.spatial(adata, color='control_codeword_counts', spot_size=15, title=\"Spatial Distribution of Control codeword Counts\", cmap='viridis_r')\nsc.pl.spatial(adata, color='unassigned_codeword_counts', spot_size=15, title=\"Spatial Distribution of Unassigned codeword Counts\", cmap='viridis_r')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprint(pd.crosstab(adata.obs['control_probe_counts']&gt;0, adata.obs['control_codeword_counts']&gt;0))\n# not always in the same cells!\n\nprint(pd.crosstab(adata.obs['control_codeword_counts']&gt;0, adata.obs['unassigned_codeword_counts']&gt;0))\n\ncontrol_codeword_counts  False  True \ncontrol_probe_counts                 \nFalse                    60073    614\nTrue                      1253     14\nunassigned_codeword_counts  False  True \ncontrol_codeword_counts                 \nFalse                       57963   3363\nTrue                          576     52\n\n\nHow does the control probes etc correlate to other quality measures?\n\nadata.obs['ctrl_probe'] = (adata.obs['control_probe_counts']&gt;0).astype(\"category\")\nadata.obs['ctrl_code'] = (adata.obs['control_codeword_counts']&gt;0).astype(\"category\")\nadata.obs['unass_code'] = (adata.obs['unassigned_codeword_counts']&gt;0).astype(\"category\")\n\nsc.pl.violin(adata, ['cell_area','nucleus_area','total_counts','n_genes'], groupby='ctrl_probe')\nsc.pl.violin(adata, ['cell_area','nucleus_area','total_counts','n_genes'], groupby='ctrl_code')\nsc.pl.violin(adata, ['cell_area','nucleus_area','total_counts','n_genes'], groupby='unass_code')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJust seems to be larger cells with larger number of counts and genes."
  },
  {
    "objectID": "day_1/practical_1/workdir/practical_1_QC&Normalization.html#explore-filtering-criteria",
    "href": "day_1/practical_1/workdir/practical_1_QC&Normalization.html#explore-filtering-criteria",
    "title": "ELIXIR Spatial Transcriptomics Course",
    "section": "Explore filtering criteria",
    "text": "Explore filtering criteria\n\nsc.pl.spatial(adata, color=['cell_area','nucleus_area'], spot_size=15, color_map = \"viridis_r\")\nsc.pl.spatial(adata, color=['total_counts','n_genes'], spot_size=15,  color_map = \"viridis_r\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAll top region of the section is messed up, low counts and low number of features. Needs to be reomoved? Napari?\nAlso, bunch of “cells” outside of the tissue.\n\nsns.histplot(adata.obs['total_counts'], kde=True, bins=100)\n\nadata.obs['min10'] = adata.obs['total_counts'] &lt; 10\nprint(adata.obs['min10'].value_counts())\nadata.obs['min30'] = adata.obs['total_counts'] &lt; 30\nprint(adata.obs['min30'].value_counts())\nadata.obs['max600'] = adata.obs['total_counts'] &gt; 600\nprint(adata.obs['max600'].value_counts())\n\nsc.pl.spatial(adata, color=['min10','min30','max600'], spot_size=15, palette = [\"lightgray\",\"blue\"])\n\nmin10\nFalse    59765\nTrue      2189\nName: count, dtype: int64\nmin30\nFalse    58588\nTrue      3366\nName: count, dtype: int64\nmax600\nFalse    61629\nTrue       325\nName: count, dtype: int64\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsns.histplot(adata.obs['n_genes'], kde=True, bins=100)\n\n\nadata.obs['Gmin5'] = adata.obs['n_genes'] &lt; 5\nprint(adata.obs['Gmin5'].value_counts())\nadata.obs['Gmax150'] = adata.obs['n_genes'] &gt; 150\nprint(adata.obs['Gmax150'].value_counts())\n\nsc.pl.spatial(adata, color=['Gmin5','Gmax150'], spot_size=15, palette = [\"lightgray\",\"blue\"])\n\nGmin5\nFalse    60082\nTrue      1872\nName: count, dtype: int64\nGmax150\nFalse    61924\nTrue        30\nName: count, dtype: int64\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsns.histplot(adata.obs['cell_area'], kde=True, bins=100)\n\nadata.obs['Amin10'] = adata.obs['cell_area'] &lt; 10\nprint(adata.obs['Amin10'].value_counts())\nadata.obs['Amin20'] = adata.obs['cell_area'] &lt; 20\nprint(adata.obs['Amin20'].value_counts())\nadata.obs['Amax1000'] = adata.obs['cell_area'] &gt; 1000\nprint(adata.obs['Amax1000'].value_counts())\n\nsc.pl.spatial(adata, color=['Amin10','Amin20','Amax1000'], spot_size=15, palette = [\"lightgray\",\"blue\"])\n\nAmin10\nFalse    61946\nTrue         8\nName: count, dtype: int64\nAmin20\nFalse    61761\nTrue       193\nName: count, dtype: int64\nAmax1000\nFalse    61709\nTrue       245\nName: count, dtype: int64\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsns.histplot(adata.obs['nucleus_area'], kde=True, bins=100)\n\nadata.obs['Nmin10'] = adata.obs['nucleus_area'] &lt; 10\nprint(adata.obs['Nmin10'].value_counts())\nadata.obs['Nmin7'] = adata.obs['nucleus_area'] &lt; 7\nprint(adata.obs['Nmin7'].value_counts())\nadata.obs['Nmin6'] = adata.obs['nucleus_area'] &lt; 6\nprint(adata.obs['Nmin6'].value_counts())\nadata.obs['Nmax125'] = adata.obs['nucleus_area'] &gt; 125\nprint(adata.obs['Nmax125'].value_counts())\n\nsc.pl.spatial(adata, color=['Nmin10','Nmin6','Nmin7','Nmax125'], spot_size=15, palette = [\"lightgray\",\"blue\"])\n\nNmin10\nFalse    57829\nTrue      4125\nName: count, dtype: int64\nNmin7\nFalse    60315\nTrue      1639\nName: count, dtype: int64\nNmin6\nFalse    61184\nTrue       770\nName: count, dtype: int64\nNmax125\nFalse    61702\nTrue       252\nName: count, dtype: int64\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nadata.obs.sort_values(by=\"nucleus_area\").head(20)\n\n\n\n\n\n\n\n\ncell_id\nx_centroid\ny_centroid\ntranscript_counts\ncontrol_probe_counts\ncontrol_codeword_counts\nunassigned_codeword_counts\ntotal_counts\ncell_area\nnucleus_area\n...\nmax600\nGmin5\nGmax150\nAmin10\nAmin20\nAmax1000\nNmin10\nNmin7\nNmin6\nNmax125\n\n\n\n\nhkcipmfi-1\nhkcipmfi-1\n1896.213452\n3830.822583\n87\n0\n0\n0\n87.0\n81.461875\n5.012344\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\nhdjcjgek-1\nhdjcjgek-1\n3327.305493\n1251.938251\n18\n0\n0\n0\n18.0\n36.982969\n5.012344\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\nhdhkdpgn-1\nhdhkdpgn-1\n3440.780078\n1249.603552\n73\n0\n0\n0\n73.0\n167.845781\n5.012344\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\nkjbhfghi-1\nkjbhfghi-1\n4029.808911\n4098.354688\n18\n0\n0\n0\n18.0\n77.668750\n5.012344\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\nkjbilgog-1\nkjbilgog-1\n4026.586133\n4134.333179\n77\n0\n0\n0\n77.0\n223.026719\n5.012344\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\nimkjpnnj-1\nimkjpnnj-1\n1149.841339\n651.571744\n90\n0\n0\n0\n90.0\n65.973281\n5.012344\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\ndicdnime-1\ndicdnime-1\n2213.888708\n785.633875\n335\n0\n0\n0\n335.0\n687.232969\n5.012344\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\nbohkadnc-1\nbohkadnc-1\n4163.014038\n1619.668774\n59\n0\n0\n0\n59.0\n214.221250\n5.012344\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\nlaldefaj-1\nlaldefaj-1\n5488.850513\n2387.367151\n77\n0\n0\n0\n77.0\n180.895938\n5.012344\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\nmadmmblf-1\nmadmmblf-1\n2708.154578\n797.708554\n69\n0\n0\n0\n69.0\n115.690313\n5.012344\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\noaggdhce-1\noaggdhce-1\n2642.590234\n2067.187549\n53\n0\n0\n0\n53.0\n69.134219\n5.012344\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\nmbegkkhi-1\nmbegkkhi-1\n2826.654041\n317.760287\n15\n0\n0\n0\n15.0\n11.469687\n5.012344\n...\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\nmjkfcnjk-1\nmjkfcnjk-1\n5086.753198\n2939.776050\n82\n0\n0\n0\n82.0\n248.720625\n5.012344\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\ncjkdglik-1\ncjkdglik-1\n4837.046606\n2266.345081\n161\n0\n0\n1\n161.0\n457.613437\n5.012344\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\ngobpaadh-1\ngobpaadh-1\n1828.043079\n2896.392017\n161\n0\n0\n0\n161.0\n209.163750\n5.012344\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\nkedbcdbd-1\nkedbcdbd-1\n957.122827\n1123.840387\n73\n0\n0\n0\n73.0\n93.247656\n5.012344\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\nkkamiafh-1\nkkamiafh-1\n3918.152612\n3481.532764\n77\n0\n0\n0\n77.0\n140.300469\n5.012344\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\nfeoednoe-1\nfeoednoe-1\n4181.003491\n3960.628540\n26\n0\n0\n0\n26.0\n21.900781\n5.012344\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\ncjhlfijo-1\ncjhlfijo-1\n4890.426025\n2503.740576\n32\n0\n0\n0\n32.0\n53.239219\n5.012344\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\nnbcppddc-1\nnbcppddc-1\n3231.211084\n1264.438501\n6\n0\n0\n0\n6.0\n20.862188\n5.012344\n...\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\n\n\n20 rows × 27 columns\n\n\n\nMany cells with exact same nucleus area - at 5.012344, Clearly varying cell area for same cells.\n\nplt.scatter(adata.obs['cell_area'], adata.obs['nucleus_area'], c=adata.obs['total_counts'],alpha=0.5, cmap='viridis_r')\n\n\n\n\n\n\n\n\n\nplt.scatter(adata.obs['cell_area'], adata.obs['total_counts'], c=adata.obs['n_genes'],alpha=0.5, cmap='viridis_r')\n\n\n\n\n\n\n\n\n\nplt.scatter(adata.obs['total_counts'], adata.obs['n_genes'], c=adata.obs['cell_area'],alpha=0.5, cmap='viridis_r')\n\n\n\n\n\n\n\n\nLook at gene detection\n\nadata.var['n_cell'] = adata.X.getnnz(axis=0)\nadata.var['n_count'] = adata.X.sum(axis=0).A1\n\nsns.histplot(adata.var['n_cell'], kde=True, bins=100)\nsns.histplot(adata.var['n_count'], kde=True, bins=100)\n\n\n\n\n\n\n\n\n\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\nsns.histplot(adata.var['n_cell'], kde=True, bins=100, ax = axs[0,0])\nsns.histplot(adata.var['n_count'], kde=True, bins=100, ax = axs[0,1])\nplt.scatter(adata.var['n_count'], adata.var['n_cell'], alpha=0.5)\n\n\n\n\n\n\n\n\nMost genes are detected in around 5K of the 61K cells. A few are in pretty much every cell. Lowest number is 112 cells.\nThe few genes with extremely high counts will effect normalization a great deal.\n\nadata.var['n_cell'].min()\n\n112\n\n\n\nsc.pl.highest_expr_genes(adata)\n\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:234: UserWarning: Some cells have zero counts\n  warn(UserWarning(\"Some cells have zero counts\"))"
  },
  {
    "objectID": "day_1/practical_1/workdir/practical_1_QC&Normalization.html#filtering-normalizing-and-cleaning-data",
    "href": "day_1/practical_1/workdir/practical_1_QC&Normalization.html#filtering-normalizing-and-cleaning-data",
    "title": "ELIXIR Spatial Transcriptomics Course",
    "section": "Filtering, Normalizing and Cleaning data",
    "text": "Filtering, Normalizing and Cleaning data\nRun filtering with:\nNuclei size &lt; 7\nArea &lt; 20, &gt;1000\nTotal counts &lt; 30, &gt; 600\nNumber of genes &lt;4, &gt; 150\nFilter out the cells that have nuclei smaller than 7 microns.\nWhat do you think could be a good cutoff for filtering out lowly expressed genes and cells with low transcript count? Lets removes low-quality cells and genes from the dataset, which helps reduce noise and computational load in downstream analyses. This filtering step ensures that the dataset is focused on cells and genes with a minimum level of expression, which are more likely to be biologically relevant.\n\n# Cell and gene filtering\ninitial_cells_count = adata.n_obs\ninitial_genes_count = adata.n_vars\n\nadata_full = adata.copy()\n\nsc.pp.filter_cells(adata, min_counts=30, inplace=True)\nsc.pp.filter_cells(adata, max_counts=600, inplace=True)\nsc.pp.filter_cells(adata, min_genes=5, inplace=True)\nsc.pp.filter_cells(adata, max_genes=150, inplace=True)\n# sc.pp.filter_genes(adata, min_cells=5, inplace=True) - no genes have less than 5 cells.\n\nadata = adata[adata.obs['cell_area']&gt;20,:]\nadata = adata[adata.obs['cell_area']&lt;1000,:]\nadata = adata[adata.obs['nucleus_area']&gt;7,:]\nfiltered_cells_count = adata.n_obs\nfiltered_genes_count = adata.n_vars\nprint(f\"Filtered {initial_cells_count - filtered_cells_count} (out of intial {initial_cells_count} cells)\")\nprint(f\"Filtered {initial_genes_count - filtered_genes_count} (out of intial {initial_genes_count} genes)\")\n\nFiltered 5055 (out of intial 61954 cells)\nFiltered 0 (out of intial 347 genes)\n\n\n\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['total_counts'], kde=True, bins=50)\nplt.xlabel(\"Total Transcript Counts per Cell\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Total Transcript Counts per Cell After Filtering\")\nplt.show()\n\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['nucleus_area'], kde=True, bins=50)\nplt.xlabel(\"Nucleus Area\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Nucleus Area After Filtering\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.scatter(adata.obs['cell_area'], adata.obs['total_counts'], c=adata.obs['n_genes'],alpha=0.5, cmap='viridis_r')\n\n\n\n\n\n\n\n\n\nsc.pl.highest_expr_genes(adata)\n\n# now no gene is 100% of the expression for a cell, but still have genes that make up around 40%\n\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:207: UserWarning: Received a view of an AnnData. Making a copy.\n  view_to_actual(adata)\n\n\n\n\n\n\n\n\n\n\n# Check again n_cell vs total counts after filtering genes, no gene should now be 100%\nadata.var['n_cell2'] = adata.X.getnnz(axis=0)\nadata.var['n_count2'] = adata.X.sum(axis=0).A1\n\n\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\nsns.histplot(adata.var['n_cell2'], kde=True, bins=100, ax = axs[0,0])\nsns.histplot(adata.var['n_count2'], kde=True, bins=100, ax = axs[0,1])\nplt.scatter(adata.var['n_count2'], adata.var['n_cell2'], alpha=0.5)\n\n\n\n\n\n\n\n\n\nadata_full.obs['kept'] = adata_full.obs_names.isin(adata.obs_names)\nsc.pl.spatial(adata_full, color=['kept'], spot_size=15, palette = [\"lightgray\",\"blue\"])\nsc.pl.spatial(adata_full, color=['kept'], spot_size=15, palette = [\"blue\",\"lightgray\"])"
  },
  {
    "objectID": "day_1/practical_1/workdir/practical_1_QC&Normalization.html#normaliation-and-scaling",
    "href": "day_1/practical_1/workdir/practical_1_QC&Normalization.html#normaliation-and-scaling",
    "title": "ELIXIR Spatial Transcriptomics Course",
    "section": "Normaliation and scaling",
    "text": "Normaliation and scaling\nNormalization adjusts for cell-specific technical differences, and log transformation makes the data easier to analyze by reducing the effects of extreme values. This normalization and transformation make the dataset more appropriate for dimensionality reduction, clustering, and other analyses.\n\nUsing raw counts\nTest running pca and umap without normalization.\n\nsc.pp.pca(adata)\nsc.pp.neighbors(adata)\nsc.tl.leiden(adata)\nsc.tl.umap(adata)\nsc.pl.umap(adata, color='leiden', title='UMAP raw counts')\n\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n/var/folders/8l/yj6nz8296zd7wwj0xy6pw3880000gn/T/ipykernel_80568/183271786.py:3: FutureWarning: In the future, the default backend for leiden will be igraph instead of leidenalg.\n\n To achieve the future defaults please pass: flavor=\"igraph\" and n_iterations=2.  directed must also be False to work with igraph's implementation.\n  sc.tl.leiden(adata)\n\n\n\n\n\n\n\n\n\n\nadata.obsm['X_umap_counts'] = adata.obsm['X_umap']\nadata.obs['leiden_counts'] = adata.obs['leiden']\n\n\n\nLognorm\n\nadata.layers['raw'] = adata.X.copy()\nsc.pp.normalize_total(adata, target_sum=1e4)\nsc.pp.log1p(adata)\n\nComparing the effect of normalization\n\noriginal_counts = adata.layers['raw'].sum(axis=1)\nnormalized_counts = adata.X.sum(axis=1)\n#plt distributions\nplt.figure(figsize=(10, 5))\nsns.histplot(original_counts.A1, color=\"blue\", label=\"Before Normalization\", kde=True) \nsns.histplot(normalized_counts.A1, color=\"orange\", label=\"After Normalization\", kde=True)\nplt.xlabel(\"Total Expression per Cell\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Effect of Normalization on Expression Distribution\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nHow the normalization and scaling of the data affects the distribution of gene expression values in the dataset. We can have a look at the distribution of gene expression values before and after normalization and scaling for Cst3 gene.\n\ngene_name = \"Cst3\"\nif gene_name in adata.var_names:\n    #extract Cst3 expression values before normalization\n    original_mall_expression = adata[:, gene_name].layers['raw'].toarray().flatten()\n    #and after normalization\n    normalized_mall_expression = adata[:, gene_name].X.toarray().flatten()\n    #plt distributions\n    plt.figure(figsize=(10, 5))\n    sns.histplot(original_mall_expression, color=\"blue\", label=\"Before Normalization\", kde=True, bins=50)\n    sns.histplot(normalized_mall_expression, color=\"orange\", label=\"After Normalization\", kde=True, bins=50)\n    plt.xlabel(f\"{gene_name} Expression\")\n    plt.ylabel(\"Number of Cells\")\n    plt.title(f\"Effect of Normalization and Scaling on {gene_name} Expression\")\n    plt.legend()\n    plt.show()\n\n\n\n\n\n\n\n\n\n# a more intermediate expression gene.\n\ngene_name = \"Sorl1\"\nif gene_name in adata.var_names:\n    original_mall_expression = adata[:, gene_name].layers['raw'].toarray().flatten()\n    normalized_mall_expression = adata[:, gene_name].X.toarray().flatten()\n    plt.figure(figsize=(10, 5))\n    sns.histplot(original_mall_expression, color=\"blue\", label=\"Before Normalization\", kde=True, bins=50)\n    sns.histplot(normalized_mall_expression, color=\"orange\", label=\"After Normalization\", kde=True, bins=50)\n    plt.xlabel(f\"{gene_name} Expression\")\n    plt.ylabel(\"Number of Cells\")\n    plt.title(f\"Effect of Normalization and Scaling on {gene_name} Expression\")\n    plt.legend()\n    plt.show()\n\n\n\n\n\n\n\n\n\n# a lowly expression gene.\n\ngene_name = \"Th\"\nif gene_name in adata.var_names:\n    original_mall_expression = adata[:, gene_name].layers['raw'].toarray().flatten()\n    normalized_mall_expression = adata[:, gene_name].X.toarray().flatten()\n    plt.figure(figsize=(10, 5))\n    sns.histplot(original_mall_expression, color=\"blue\", label=\"Before Normalization\",  bins=50)\n    sns.histplot(normalized_mall_expression, color=\"orange\", label=\"After Normalization\", bins=50)\n    plt.xlabel(f\"{gene_name} Expression\")\n    plt.ylabel(\"Number of Cells\")\n    plt.title(f\"Effect of Normalization and Scaling on {gene_name} Expression\")\n    plt.legend()\n    plt.show()\n\n\n\n\n\n\n\n\n\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\n\naxs[0,0].scatter(adata.obs['total_counts'], adata.X.getcol(adata.var.index.tolist().index('Cst3')).toarray(), c=adata.obs['n_genes'],alpha=0.5, cmap='viridis_r')\naxs[0,0].set_title(\"Cst3 vs Total counts\")\n\naxs[0,1].scatter(adata.obs['total_counts'], adata.X.getcol(adata.var.index.tolist().index('Cd69')).toarray(), c=adata.obs['n_genes'],alpha=0.5, cmap='viridis_r')\naxs[0,1].set_title(\"Cd69 vs Total counts\")\n\naxs[1,0].scatter(adata.obs['total_counts'], adata.X.getcol(adata.var.index.tolist().index('Sorl1')).toarray(), c=adata.obs['n_genes'],alpha=0.5, cmap='viridis_r')\naxs[1,0].set_title(\"Sorl1 vs Total counts\")\n\n#adata.var.index.tolist().index('Cst3')\n\nText(0.5, 1.0, 'Sorl1 vs Total counts')\n\n\n\n\n\n\n\n\n\n\nsc.pl.highest_expr_genes(adata)\n\n\n\n\n\n\n\n\n\nsc.pp.pca(adata)\nsc.pp.neighbors(adata)\nsc.tl.leiden(adata)\nsc.tl.umap(adata)\nsc.pl.umap(adata, color='leiden', title='UMAP lognorm')\n\n\n\n\n\n\n\n\n\nadata.obsm['X_umap_lognorm'] = adata.obsm['X_umap']\nadata.obs['leiden_lognorm'] = adata.obs['leiden']\n\n# save the lognorm as its own layer\nadata.layers['lognorm'] = adata.X.copy()\n\n\n\nScaling\nShould the data be scaled before running PCA? Get more distinct clusters, but is it closer to biological truth?\n\nsc.pp.scale(adata, max_value=10)\n\n\nsc.pp.pca(adata)\nsc.pp.neighbors(adata)\nsc.tl.leiden(adata)\nsc.tl.umap(adata)\nsc.pl.umap(adata, color='leiden', title='UMAP Scaled')\n\n\n\n\n\n\n\n\n\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\n\naxs[0,0].scatter(adata.obs['total_counts'], adata.X[:,adata.var.index.tolist().index('Cst3')], c=adata.obs['n_genes'],alpha=0.5, cmap='viridis_r')\naxs[0,0].set_title(\"Cst3 vs Total counts\")\n\naxs[0,1].scatter(adata.obs['total_counts'], adata.X[:,adata.var.index.tolist().index('Cd69')], c=adata.obs['n_genes'],alpha=0.5, cmap='viridis_r')\naxs[0,1].set_title(\"Cd69 vs Total counts\")\n\naxs[1,0].scatter(adata.obs['total_counts'], adata.X[:,adata.var.index.tolist().index('Sorl1')], c=adata.obs['n_genes'],alpha=0.5, cmap='viridis_r')\naxs[1,0].set_title(\"Sorl1 vs Total counts\")\n\nText(0.5, 1.0, 'Sorl1 vs Total counts')\n\n\n\n\n\n\n\n\n\n\nadata.obsm['X_umap_scaled'] = adata.obsm['X_umap']\nadata.obs['leiden_scaled'] = adata.obs['leiden']\n\n# save the lognorm as its own layer\nadata.layers['scaled'] = adata.X.copy()\n\n\n\nPearson residuals normalization\nAs suggested in the Lause et al 2021 https://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-02451-7\n\n# revert back to counts\nadata.X = adata.layers['raw'].copy()\nsc.experimental.pp.normalize_pearson_residuals(adata)\n#Now the X matrix is an array instead.\n\n\nsc.pp.pca(adata)\nsc.pp.neighbors(adata)\nsc.tl.leiden(adata)\nsc.tl.umap(adata)\nsc.pl.umap(adata, color='leiden', title='UMAP pearson R')\n\n\n\n\n\n\n\n\n\nadata.obsm['X_umap_pearson'] = adata.obsm['X_umap']\nadata.obs['leiden_pearson'] = adata.obs['leiden']\n\nadata.layers['pearson'] = adata.X.copy()\n\nSelect one high, one low and one intermediate expression gene and plot expression distributions.\n\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\n\naxs[0,0].scatter(adata.obs['total_counts'], adata.X[:,adata.var.index.tolist().index('Cst3')], c=adata.obs['n_genes'],alpha=0.5, cmap='viridis_r')\naxs[0,0].set_title(\"Cst3 vs Total counts\")\n\naxs[0,1].scatter(adata.obs['total_counts'], adata.X[:,adata.var.index.tolist().index('Cd69')], c=adata.obs['n_genes'],alpha=0.5, cmap='viridis_r')\naxs[0,1].set_title(\"Cd69 vs Total counts\")\n\naxs[1,0].scatter(adata.obs['total_counts'], adata.X[:,adata.var.index.tolist().index('Sorl1')], c=adata.obs['n_genes'],alpha=0.5, cmap='viridis_r')\naxs[1,0].set_title(\"Sorl1 vs Total counts\")\n\nText(0.5, 1.0, 'Sorl1 vs Total counts')\n\n\n\n\n\n\n\n\n\n\nsc.pl.highest_expr_genes(adata)\n\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:234: UserWarning: Some cells have zero counts\n  warn(UserWarning(\"Some cells have zero counts\"))\n\n\n\n\n\n\n\n\n\n\n\nCell size normalization\n\nX = adata.layers['raw'].copy()\nXnorm = np.divide(X.todense().T, adata.obs['cell_area'].values).T * 1000\n# need to add a scaling factor?\nXnorm = np.log1p(Xnorm)\n\nfrom scipy import sparse\n\nadata.X = sparse.csr_matrix(Xnorm.copy())\n\n\nsc.pp.pca(adata)\nsc.pp.neighbors(adata)\nsc.tl.leiden(adata)\nsc.tl.umap(adata)\nsc.pl.umap(adata, color='leiden', title='UMAP size norm')\n\n\n\n\n\n\n\n\n\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\n\naxs[0,0].scatter(adata.obs['total_counts'], adata.X.getcol(adata.var.index.tolist().index('Cst3')).toarray(), c=adata.obs['n_genes'],alpha=0.5, cmap='viridis_r')\naxs[0,0].set_title(\"Cst3 vs Total counts\")\n\naxs[0,1].scatter(adata.obs['total_counts'], adata.X.getcol(adata.var.index.tolist().index('Cd69')).toarray(), c=adata.obs['n_genes'],alpha=0.5, cmap='viridis_r')\naxs[0,1].set_title(\"Cd69 vs Total counts\")\n\naxs[1,0].scatter(adata.obs['total_counts'], adata.X.getcol(adata.var.index.tolist().index('Sorl1')).toarray(), c=adata.obs['n_genes'],alpha=0.5, cmap='viridis_r')\naxs[1,0].set_title(\"Sorl1 vs Total counts\")\n\nText(0.5, 1.0, 'Sorl1 vs Total counts')\n\n\n\n\n\n\n\n\n\n\nadata.obsm['X_umap_size'] = adata.obsm['X_umap']\nadata.obs['leiden_size'] = adata.obs['leiden']\n\nadata.layers['size'] = adata.X.copy()\n\n\n# all with clustering from lognorm coloring.\n\nfig, axs = plt.subplots(2, 3, figsize=(10,8),constrained_layout=True)\nsc.pl.embedding(adata, color='leiden_lognorm', basis='umap_counts', title='umap counts', ax=axs[0,0], show=False, legend_loc='on data')\nsc.pl.embedding(adata, color='leiden_lognorm', basis='umap_lognorm', title='umap lognorm', ax=axs[0,1], show=False, legend_loc='on data') \nsc.pl.embedding(adata, color='leiden_lognorm', basis='umap_scaled', title='umap scaled', ax=axs[0,2], show=False, legend_loc='on data')\nsc.pl.embedding(adata, color='leiden_lognorm', basis='umap_pearson', title='umap pearson', ax=axs[1,0], show=False, legend_loc='on data')\nsc.pl.embedding(adata, color='leiden_lognorm', basis='umap_size', title='umap size norm', ax=axs[1,1], show=False, legend_loc='on data')\nsc.pl.embedding(adata, color='leiden_pearson', basis='umap_pearson', title='umap pearson, cl pearson', ax=axs[1,2], show=False, legend_loc='on data')\n\n\n\n\n\n\n\n\n\nlognorm clusters 0,1,5,16 now 0,4,20 with pearson.\nCortical layers are 9,3,10,22,8 in lognorm, 12,8,9,17,16,27,30,25 in pearson\nNew pearson clusters 28, 19, 29, 26, 25,30, (pretty much all abouve 25)\n\n# plot all with same colors to make more comparable.\n\nsc.pl.spatial(adata, color='leiden_lognorm', spot_size=15, title=\"Lognorm\", palette = adata.uns['leiden_pearson_colors'])\nsc.pl.spatial(adata, color='leiden_scaled', spot_size=15, title=\"Scaled\", palette = adata.uns['leiden_pearson_colors'])\nsc.pl.spatial(adata, color='leiden_pearson', spot_size=15, title=\"Pearson\")\nsc.pl.spatial(adata, color='leiden_size', spot_size=15, title=\"Size\", palette = adata.uns['leiden_pearson_colors'])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBetter separation of cortical layers with Size or Pearson normalization.\n\n# examine specific clusters that differen between lognorm and pearson\n\nclustersL = adata.obs['leiden_lognorm'].cat.categories.tolist()\nclustersP = adata.obs['leiden_pearson'].cat.categories.tolist()\n\n#lognorm clusters 0,15,16 now 0,4,20 with pearson.\n#New pearson clusters  28, 19, 29, 26, 25,30, (pretty much all abouve 25)\n\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\nsc.pl.spatial(adata[adata.obs['leiden_lognorm'].isin(np.array(clustersL)[[0,15,16]]),:], color='leiden_lognorm', spot_size=15, ax = axs[0,0], show=False, palette = adata.uns['leiden_pearson_colors'])\nsc.pl.spatial(adata[adata.obs['leiden_pearson'].isin(np.array(clustersP)[[0,4,20]]),:], color='leiden_pearson', spot_size=15, ax = axs[0,1], show=False)\n\nsc.pl.spatial(adata[adata.obs['leiden_pearson'].isin(clustersP[25:29]),:], color='leiden_pearson', spot_size=15, ax = axs[1,0], show=False)\nsc.pl.spatial(adata[adata.obs['leiden_pearson'].isin(clustersP[29:33]),:], color='leiden_pearson', spot_size=15, ax = axs[1,1], show=False)\n\n\n\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/scanpy/plotting/_utils.py:487: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n  adata.uns[value_to_plot + \"_colors\"] = colors_list\n\n\n\n\n\n\n\n\n\n\n#Cortical layers are 9,3,10,22,8 in lognorm, 12,8,9,17,16,27,30,25 in pearson\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\nsc.pl.spatial(adata[adata.obs['leiden_lognorm'].isin(np.array(clustersL)[[9,3]]),:], color='leiden_lognorm', spot_size=15, ax = axs[0,0], show=False, palette = adata.uns['leiden_pearson_colors'])\nsc.pl.spatial(adata[adata.obs['leiden_lognorm'].isin(np.array(clustersL)[[10,22,8]]),:], color='leiden_lognorm', spot_size=15, ax = axs[0,1], show=False, palette = adata.uns['leiden_pearson_colors'])\n\nsc.pl.spatial(adata[adata.obs['leiden_pearson'].isin(np.array(clustersP)[[12,8,9,17]]),:], color='leiden_pearson', spot_size=15, ax = axs[1,0], show=False)\nsc.pl.spatial(adata[adata.obs['leiden_pearson'].isin(np.array(clustersP)[[16,27,30,25]]),:], color='leiden_pearson', spot_size=15, ax = axs[1,1], show=False)\n\n# cl 22 is a low quality cluster with lognorm\n\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/scanpy/plotting/_utils.py:487: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n  adata.uns[value_to_plot + \"_colors\"] = colors_list\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/scanpy/plotting/_utils.py:487: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n  adata.uns[value_to_plot + \"_colors\"] = colors_list\n\n\n\n\n\n\n\n\n\n\nsc.pl.violin(adata, 'total_counts', groupby='leiden_lognorm')\nsc.pl.violin(adata, 'total_counts', groupby='leiden_scaled')\nsc.pl.violin(adata, 'total_counts', groupby='leiden_pearson')\nsc.pl.violin(adata, 'total_counts', groupby='leiden_size')"
  },
  {
    "objectID": "day_1/practical_1/workdir/practical_1_QC&Normalization.html#dimensionality-reduction",
    "href": "day_1/practical_1/workdir/practical_1_QC&Normalization.html#dimensionality-reduction",
    "title": "ELIXIR Spatial Transcriptomics Course",
    "section": "Dimensionality reduction",
    "text": "Dimensionality reduction\nWe use dimensionality reduction, clustering, and visualization techniques to analyze the structure of our dataset, group similar cells, and visualize their relationships. First, we apply Principal Component Analysis (PCA) to reduce the high-dimensional gene expression data into a smaller set of principal components, retaining the main patterns of variation while reducing noise. Then, we create a neighbors graph, which identifies connections between cells based on their similarity in the reduced PCA space, capturing local relationships essential for clustering. Using the Leiden clustering algorithm, we group cells into clusters based on these connections, allowing us to identify groups of similar cells that may represent distinct cell types or states. We then apply UMAP (Uniform Manifold Approximation and Projection), a technique that reduces the data to two dimensions for visualization, preserving both local and global structures in the data. Finally, we generate a UMAP plot with cells colored by their assigned clusters, providing an overview of the dataset’s structure and making it easy to spot distinct cell populations or clusters. This visualization gives us an interpretable view of the relationships within our data, helping us understand its organization before further analysis.\n\n# run for now with scaled.\n\nadata.X = adata.layers['scaled'].copy()\n\n\nsc.pp.pca(adata)\nsc.pp.neighbors(adata)\nsc.tl.leiden(adata)\nsc.tl.umap(adata)\n\n\nsc.pl.umap(adata, color='leiden', title='UMAP before filtering suspected false positives', legend_loc='on data')\n#help(sc.pl.umap)\n\n\n\n\n\n\n\n\n\nsc.pl.spatial(adata, color='leiden', spot_size=15, title=\"Clusters\")\n\n\n\n\n\n\n\n\nWe can plot clusters spatially to see if they are localized to specific regions of the tissue, which may indicate spatially distinct cell types or states. This spatial information can provide insights into the organization of cells within the tissue and help identify spatially related cell populations or structures.\n\nclusters = adata.obs['leiden'].cat.categories.tolist()\n\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\nsc.pl.spatial(adata[adata.obs['leiden'].isin(clusters[0:3]),:], color='leiden', spot_size=15, ax = axs[0,0], show=False)\nsc.pl.spatial(adata[adata.obs['leiden'].isin(clusters[3:6]),:], color='leiden', spot_size=15, ax = axs[0,1], show=False)\nsc.pl.spatial(adata[adata.obs['leiden'].isin(clusters[6:9]),:], color='leiden', spot_size=15, ax = axs[1,0], show=False)\nsc.pl.spatial(adata[adata.obs['leiden'].isin(clusters[9:12]),:], color='leiden', spot_size=15, ax = axs[1,1], show=False)\n\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/scanpy/plotting/_utils.py:487: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n  adata.uns[value_to_plot + \"_colors\"] = colors_list\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/scanpy/plotting/_utils.py:487: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n  adata.uns[value_to_plot + \"_colors\"] = colors_list\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/scanpy/plotting/_utils.py:487: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n  adata.uns[value_to_plot + \"_colors\"] = colors_list\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/scanpy/plotting/_utils.py:487: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n  adata.uns[value_to_plot + \"_colors\"] = colors_list\n\n\n\n\n\n\n\n\n\n\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\nsc.pl.spatial(adata[adata.obs['leiden'].isin(clusters[12:15]),:], color='leiden', spot_size=15, ax = axs[0,0], show=False)\nsc.pl.spatial(adata[adata.obs['leiden'].isin(clusters[15:18]),:], color='leiden', spot_size=15, ax = axs[0,1], show=False)\nsc.pl.spatial(adata[adata.obs['leiden'].isin(clusters[18:21]),:], color='leiden', spot_size=15, ax = axs[1,0], show=False)\nsc.pl.spatial(adata[adata.obs['leiden'].isin(clusters[21:24]),:], color='leiden', spot_size=15, ax = axs[1,1], show=False)\n\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/scanpy/plotting/_utils.py:487: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n  adata.uns[value_to_plot + \"_colors\"] = colors_list\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/scanpy/plotting/_utils.py:487: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n  adata.uns[value_to_plot + \"_colors\"] = colors_list\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/scanpy/plotting/_utils.py:487: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n  adata.uns[value_to_plot + \"_colors\"] = colors_list\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/scanpy/plotting/_utils.py:487: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n  adata.uns[value_to_plot + \"_colors\"] = colors_list\n\n\n\n\n\n\n\n\n\n\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\nsc.pl.spatial(adata[adata.obs['leiden'].isin(clusters[24:27]),:], color='leiden', spot_size=15, ax = axs[0,0], show=False)\nsc.pl.spatial(adata[adata.obs['leiden'].isin(clusters[27:30]),:], color='leiden', spot_size=15, ax = axs[0,1], show=False)\nsc.pl.spatial(adata[adata.obs['leiden'].isin(clusters[30:33]),:], color='leiden', spot_size=15, ax = axs[1,0], show=False)\n\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/scanpy/plotting/_utils.py:487: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n  adata.uns[value_to_plot + \"_colors\"] = colors_list\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/scanpy/plotting/_utils.py:487: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n  adata.uns[value_to_plot + \"_colors\"] = colors_list\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/scanpy/plotting/_utils.py:487: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n  adata.uns[value_to_plot + \"_colors\"] = colors_list\n\n\n\n\n\n\n\n\n\nUsing vioilin plots to see how the clusters are distributed in terms of gene expression (number of genes and the total counts) and cell size (cell and nucleus area). This helps us understand the characteristics of each cluster in terms of gene expression levels, cell size, and other features, providing insights into the biological properties of each cluster.\n\nsc.pl.violin(adata, [\"total_counts\",\"n_genes\"], groupby='leiden')\nsc.pl.violin(adata, [\"nucleus_area\",\"cell_area\"], groupby='leiden')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExplore QC a bit more\n\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\nsc.pl.umap(adata, color='total_counts', show=False, ax = axs[0,0])\nsc.pl.umap(adata, color='n_genes', show=False, ax = axs[0,1])\nsc.pl.umap(adata, color='nucleus_area', show=False, ax = axs[1,0])\nsc.pl.umap(adata, color='cell_area', show=False, ax = axs[1,1])"
  },
  {
    "objectID": "day_1/practical_1/workdir/practical_1_QC&Normalization.html#systematic-filtering-of-suspected-false-positives",
    "href": "day_1/practical_1/workdir/practical_1_QC&Normalization.html#systematic-filtering-of-suspected-false-positives",
    "title": "ELIXIR Spatial Transcriptomics Course",
    "section": "Systematic Filtering of Suspected False Positives",
    "text": "Systematic Filtering of Suspected False Positives\nIn Xenium data, some genes may appear to be “expressed” across large areas or in many cells due to background noise or technical artifacts, rather than true biological expression. To address this, we are implementing a gene-specific filtering approach to identify and remove suspected false positives systematically. By filtering out these spurious signals, we can focus our analysis on more reliable gene expression patterns, improving the quality of downstream analyses.\n\n1- Calculate the Mean Expression per Gene per Cluster\nIn the first step, we calculate the mean expression of each gene within each cluster. Clustering organizes cells into groups that likely share biological characteristics, and taking the average expression of each gene within clusters provides a baseline for typical expression levels. This allows us to identify clusters where a gene has unusually low expression, which might indicate noise rather than true expression.\n\nmean_expression = adata.to_df().groupby(adata.obs['leiden']).mean()\n\n/var/folders/8l/yj6nz8296zd7wwj0xy6pw3880000gn/T/ipykernel_80568/2069805196.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  mean_expression = adata.to_df().groupby(adata.obs['leiden']).mean()\n\n\n\n\n2- Determine the Maximum Expression Level of Each Gene Across Clusters\nThen, we find the maximum expression level for each gene across all clusters. This maximum value serves as a reference point for each gene’s typical expression level in the dataset. The highest expression level of each gene is assumed to represent meaningful expression, while lower values may be more likely to represent noise or background.\n\nmax_expression_levels = mean_expression.max(axis=0)\n\n\n\n3- Calculate Spurious Expression Threshold for Each Gene\nWe define a threshold, here set at 5%, which will be used to identify potential false positives. This threshold means that if a gene’s expression in a given cluster is below 5% of its highest expression level across all clusters, we will consider it to be a likely false positive. This step allows us to systematically identify clusters where the gene’s expression is likely due to background noise rather than true biological signal. Then, we calculate a spurious expression threshold for each gene, which is 5% of its maximum expression level. This threshold provides a cut-off below which we consider expression values to be suspected false positives. By applying this threshold, we can filter out clusters where a gene’s expression level is unlikely to be biologically meaningful.\n\nthreshold = 0.05\nspurious_expression_threshold = max_expression_levels * threshold\n\n\n# plot distribution for first few genes.\nfor gene in adata.var_names[:10]: \n    cut = spurious_expression_threshold[gene]\n    fig, axs = plt.subplots(1, 2, figsize=(8,4),constrained_layout=True)\n    sc.pl.violin(adata, gene, groupby='leiden', use_raw=False, ax=axs[0], show=False, ylabel = str(cut))\n    sns.barplot(mean_expression[gene], ax=axs[1])\n    plt.axhline(y=cut, color='black')\n    print(gene, \":\",cut)\n\n2010300C02Rik : 0.08079957\nAbca7 : 0.042234458\nAcsbg1 : 0.058632173\nActa2 : 0.06602961\nAcvrl1 : 0.098840825\nAdamts2 : 0.06141582\nAdamtsl1 : 0.08577509\nAdgrl4 : 0.1225271\nAldh1a2 : 0.16123967\nAldh1l1 : 0.04846475\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4- Identify Suspected False Positives for Each Cluster and Gene\nNext we creat a dictionary, suspected_false_positives, to store suspected false positive genes for each cluster. For each cluster, it checks each gene’s mean expression level within that cluster. If the gene’s mean expression is below the spurious expression threshold (5% of its maximum expression), the gene is flagged as a suspected false positive in that cluster.\n\nsuspected_false_positives = {}\nfor cluster in mean_expression.index:\n    suspected_genes = []\n    for gene in adata.var_names:\n        if mean_expression.at[cluster, gene] &lt; spurious_expression_threshold[gene]:\n            suspected_genes.append(gene)\n    suspected_false_positives[cluster] = suspected_genes\n\nNow we can see a quick summary of the suspected false positives across clusters\n\n#Showing first 10 genes for brevity\nfor cluster, genes in suspected_false_positives.items():\n    print(f\"Cluster {cluster} has {len(genes)} suspected false positive genes: {genes[:10]}\")\n\ncluster_counts = {cluster: len(genes) for cluster, genes in suspected_false_positives.items()}\nclusters = list(cluster_counts.keys())\ncounts = list(cluster_counts.values())\nplt.figure(figsize=(12, 6))\nsns.barplot(x=clusters, y=counts, palette='viridis')\nplt.title('Count of Suspected False Positive Genes per Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Count of Suspected False Positive Genes')\nplt.xticks(rotation=45)\nplt.show()\n\nCluster 0 has 315 suspected false positive genes: ['2010300C02Rik', 'Abca7', 'Acsbg1', 'Acta2', 'Acvrl1', 'Adamts2', 'Adgrl4', 'Aldh1a2', 'Aldh1l1', 'Angpt1']\nCluster 1 has 289 suspected false positive genes: ['2010300C02Rik', 'Abca7', 'Acta2', 'Acvrl1', 'Adamts2', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Ano1', 'Apod']\nCluster 2 has 218 suspected false positive genes: ['2010300C02Rik', 'Abca7', 'Acsbg1', 'Acta2', 'Acvrl1', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Aldh1l1', 'Angpt1']\nCluster 3 has 278 suspected false positive genes: ['2010300C02Rik', 'Abca7', 'Acsbg1', 'Acta2', 'Acvrl1', 'Adamts2', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Aldh1l1']\nCluster 4 has 296 suspected false positive genes: ['2010300C02Rik', 'Abca7', 'Acta2', 'Adamts2', 'Adamtsl1', 'Aldh1a2', 'Aldh1l1', 'Angpt1', 'Ano1', 'Apod']\nCluster 5 has 258 suspected false positive genes: ['2010300C02Rik', 'Abca7', 'Acsbg1', 'Adamtsl1', 'Aldh1l1', 'Aqp4', 'Arc', 'Arhgap12', 'Arhgap25', 'Arhgap6']\nCluster 6 has 239 suspected false positive genes: ['2010300C02Rik', 'Acta2', 'Acvrl1', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Aldh1l1', 'Ano1', 'Apod', 'Apoe']\nCluster 7 has 260 suspected false positive genes: ['Acsbg1', 'Acta2', 'Acvrl1', 'Adamts2', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Angpt1', 'Ano1', 'Apod']\nCluster 8 has 236 suspected false positive genes: ['Acta2', 'Acvrl1', 'Adamts2', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Angpt1', 'Ano1', 'Apod', 'Apoe']\nCluster 9 has 288 suspected false positive genes: ['2010300C02Rik', 'Abca7', 'Acta2', 'Acvrl1', 'Adamts2', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Ano1', 'Apod']\nCluster 10 has 237 suspected false positive genes: ['Acsbg1', 'Acta2', 'Acvrl1', 'Adamts2', 'Adgrl4', 'Aldh1a2', 'Aldh1l1', 'Angpt1', 'Ano1', 'Apod']\nCluster 11 has 221 suspected false positive genes: ['Acsbg1', 'Acta2', 'Acvrl1', 'Adamts2', 'Adgrl4', 'Aldh1a2', 'Aldh1l1', 'Ano1', 'Apod', 'Apoe']\nCluster 12 has 282 suspected false positive genes: ['2010300C02Rik', 'Abca7', 'Acta2', 'Acvrl1', 'Adgrl4', 'Aldh1a2', 'Aldh1l1', 'Angpt1', 'Ano1', 'Aqp4']\nCluster 13 has 273 suspected false positive genes: ['Abca7', 'Acsbg1', 'Acta2', 'Acvrl1', 'Adamts2', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Aldh1l1', 'Ano1']\nCluster 14 has 261 suspected false positive genes: ['Abca7', 'Acsbg1', 'Acta2', 'Acvrl1', 'Adamts2', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Aldh1l1', 'Angpt1']\nCluster 15 has 276 suspected false positive genes: ['2010300C02Rik', 'Abca7', 'Acsbg1', 'Acta2', 'Acvrl1', 'Adamts2', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Aldh1l1']\nCluster 16 has 210 suspected false positive genes: ['Acsbg1', 'Acvrl1', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Ano1', 'Apod', 'Apoe', 'Aqp4', 'Arhgap12']\nCluster 17 has 280 suspected false positive genes: ['2010300C02Rik', 'Abca7', 'Acsbg1', 'Acta2', 'Acvrl1', 'Adamts2', 'Adgrl4', 'Aldh1a2', 'Aldh1l1', 'Angpt1']\nCluster 18 has 224 suspected false positive genes: ['2010300C02Rik', 'Acsbg1', 'Acta2', 'Acvrl1', 'Adamts2', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Aldh1l1', 'Angpt1']\nCluster 19 has 269 suspected false positive genes: ['Abca7', 'Acsbg1', 'Acta2', 'Acvrl1', 'Adamts2', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Aldh1l1', 'Angpt1']\nCluster 20 has 283 suspected false positive genes: ['2010300C02Rik', 'Abca7', 'Acsbg1', 'Acvrl1', 'Adamts2', 'Adgrl4', 'Aldh1a2', 'Aldh1l1', 'Angpt1', 'Ano1']\nCluster 21 has 283 suspected false positive genes: ['2010300C02Rik', 'Acsbg1', 'Adamts2', 'Adamtsl1', 'Aldh1a2', 'Aldh1l1', 'Angpt1', 'Apod', 'Aqp4', 'Arc']\nCluster 22 has 222 suspected false positive genes: ['Acta2', 'Acvrl1', 'Adamts2', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Aldh1l1', 'Ano1', 'Apod', 'Apoe']\nCluster 23 has 211 suspected false positive genes: ['Abca7', 'Acsbg1', 'Acvrl1', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Aldh1l1', 'Ano1', 'Apod', 'Apoe']\nCluster 24 has 221 suspected false positive genes: ['2010300C02Rik', 'Acta2', 'Acvrl1', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Aldh1l1', 'Ano1', 'Apod', 'Aqp4']\nCluster 25 has 253 suspected false positive genes: ['Acsbg1', 'Acvrl1', 'Adamts2', 'Adgrl4', 'Aldh1a2', 'Aldh1l1', 'Ano1', 'Apod', 'Apoe', 'Aqp4']\nCluster 26 has 207 suspected false positive genes: ['Acvrl1', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Angpt1', 'Ano1', 'Apod', 'Apoe', 'Aqp4', 'Arhgap25']\nCluster 27 has 238 suspected false positive genes: ['2010300C02Rik', 'Acsbg1', 'Acta2', 'Acvrl1', 'Adamts2', 'Adamtsl1', 'Adgrl4', 'Aldh1l1', 'Angpt1', 'Ano1']\nCluster 28 has 275 suspected false positive genes: ['2010300C02Rik', 'Acsbg1', 'Acta2', 'Acvrl1', 'Adamts2', 'Adgrl4', 'Aldh1a2', 'Aldh1l1', 'Angpt1', 'Ano1']\nCluster 29 has 287 suspected false positive genes: ['2010300C02Rik', 'Acsbg1', 'Acta2', 'Acvrl1', 'Adamts2', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Aldh1l1', 'Apod']\nCluster 30 has 256 suspected false positive genes: ['2010300C02Rik', 'Acsbg1', 'Acta2', 'Acvrl1', 'Adamtsl1', 'Adgrl4', 'Aldh1a2', 'Aldh1l1', 'Angpt1', 'Ano1']\nCluster 31 has 307 suspected false positive genes: ['2010300C02Rik', 'Abca7', 'Acsbg1', 'Acta2', 'Acvrl1', 'Adamts2', 'Adgrl4', 'Aldh1a2', 'Aldh1l1', 'Angpt1']\n\n\n/var/folders/8l/yj6nz8296zd7wwj0xy6pw3880000gn/T/ipykernel_80568/225620550.py:9: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x=clusters, y=counts, palette='viridis')\n\n\n\n\n\n\n\n\n\nClusters 8,14,20,21 have very small cell areas. 8 also small nucleus area, small number of genes and counts. Clusters 14,20,21 has the highest number of FP genes.\nDue to low numbers mainly?\nClusters in tissue:\n\n#sc.pl.spatial(adata, color='n_genes')\nsc.pl.spatial(adata, color=['cell_area','nucleus_area'], spot_size=15, title=\"Cell Area\", color_map = \"viridis_r\")\nsc.pl.spatial(adata, color=['total_counts','n_genes'], spot_size=15, title=\"Cell Area\", color_map = \"viridis_r\")\n\nsc.pl.spatial(adata, color='leiden', spot_size=15, title=\"Clusters\")\n\nWARNING: The title list is shorter than the number of panels. Using 'color' value instead for some plots.\n\n\n\n\n\n\n\n\n\nWARNING: The title list is shorter than the number of panels. Using 'color' value instead for some plots.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nall_suspected_fp_genes = set()\nfor genes in suspected_false_positives.values():\n    all_suspected_fp_genes.update(genes)\nall_suspected_fp_genes_list = sorted(all_suspected_fp_genes)\nclusters = list(suspected_false_positives.keys())\nheatmap_data = pd.DataFrame(0, index=list(all_suspected_fp_genes_list), columns=clusters)\n\nfor cluster, genes in suspected_false_positives.items():\n    heatmap_data.loc[genes, cluster] = 1\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(heatmap_data, cmap=\"viridis\", cbar_kws={'label': 'Presence of Suspected False Positives'})\nplt.title(\"Heatmap of Suspected False Positive Genes Across Clusters\")\nplt.xlabel(\"Cluster\")\nplt.ylabel(\"Gene\")\nplt.show()\n\n\n\n\n\n\n\n\n\nbackground_noise_counts = {gene: 0 for gene in adata.var_names}\nfor gene in adata.var_names:\n    for cluster in mean_expression.index:\n        if mean_expression.at[cluster, gene] &lt; spurious_expression_threshold[gene]:\n            background_noise_counts[gene] += 1\n\n# Find the gene with the highest background noise\nhighest_noise_gene = max(background_noise_counts, key=background_noise_counts.get)\nhighest_noise_count = background_noise_counts[highest_noise_gene]\n\nprint(f\"The gene with the highest background noise is '{highest_noise_gene}', detected below the threshold in {highest_noise_count} clusters.\")\n\nThe gene with the highest background noise is 'C1qa', detected below the threshold in 31 clusters.\n\n\n\n\n5- Adjusting gene expression values across the dataset (background noise reduction)\nNow, we aim to reduce background noise by adjusting gene expression levels across all cells based on suspected false positives. Specifically, if a gene has low expression (below the spurious expression threshold) in any cluster, we take the highest of those low expression levels and subtract it from all cells for that gene. This method removes unspecific, potentially spurious expression, which can help improve cluster separation and make biologically relevant expression patterns clearer.\n\nadata_app_1 = adata.copy()\n\nmax_filtered_expression = {}\nadata_df = adata_app_1.to_df()\n\nfor gene in adata_app_1.var_names:\n    below_threshold_values = []\n    for cluster in mean_expression.index:\n        expression_level = mean_expression.at[cluster, gene]\n        if expression_level &lt; spurious_expression_threshold[gene]:\n            below_threshold_values.append(expression_level)\n            \n    if below_threshold_values:\n        max_filtered_expression[gene] = max(below_threshold_values)\n    else:\n        max_filtered_expression[gene] = 0  \n        #no values below threshold = no subtraction needed\n\n#subtract the maximum filtered expression value from all cells for each gene\nfor gene in adata_app_1.var_names:\n    max_expr = max_filtered_expression[gene]\n    if max_expr &gt; 0:\n        adata_df[gene] -= max_expr\n        #ensure that no negative values are introduced\n        adata_df[gene] = np.maximum(adata_df[gene], 0)\n\n#update AnnData object with adjusted gene expressions\nadata_app_1 = sc.AnnData(X=adata_df.values, obs=adata_app_1.obs, var=adata_app_1.var, obsm=adata_app_1.obsm)\nsc.pp.pca(adata_app_1)\nsc.pp.neighbors(adata_app_1)\nsc.tl.leiden(adata_app_1)\nsc.tl.umap(adata_app_1)\n\n\n\nadata_app_1.obs[\"old_clust\"] = adata.obs['leiden']\nadata.obs[\"new_clust\"] = adata_app_1.obs['leiden']\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\nsc.pl.umap(adata_app_1, color='leiden', title='UMAP after filtering, clusters after filtering', ax=axs[0,0], show=False)\nsc.pl.umap(adata_app_1, color='old_clust', title='UMAP after filtering, clusters before filtering', ax=axs[0,1], show=False)\nsc.pl.umap(adata, color='new_clust', title='UMAP before filtering, clusters after filtering', ax=axs[1,0], show=False)\nsc.pl.umap(adata, color='leiden', title='UMAP before filtering, clusters before filtering', ax=axs[1,1], show=False)\n\n\n\n\n\n\n\n\n\nMainly cluster 11 clearly moves from middle part to top left.\n\nnormalized_counts1 = adata.X.sum(axis=1)\nnormalized_counts2 = adata_app_1.X.sum(axis=1)\n\nplt.figure(figsize=(8, 6))\nplt.scatter(np.array(normalized_counts1), normalized_counts2, alpha=0.5)\nplt.xlabel(\"Sum expression before filtering\")\nplt.ylabel(\"Sum expression after filtering\")\nplt.title(\"Expression sum after filtering\")\nplt.show()\n\n\n\n\n\n\n\n\n\ngene_of_interest = \"Vip\"\nsc.pl.spatial(adata, color=[gene_of_interest], spot_size=15, title=f'{gene_of_interest} Expression Before Adjustment', color_map='viridis_r')\nsc.pl.spatial(adata_app_1, color=[gene_of_interest], spot_size=15, title=f'{gene_of_interest} Expression After Adjustment', color_map = 'viridis_r')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\noriginal_expression = adata.to_df()[gene_of_interest]\nadjusted_expression = adata_app_1.to_df()[gene_of_interest]\n\nplt.figure(figsize=(10, 5))\nsns.kdeplot(original_expression, label=\"Original\", color=\"blue\")\nsns.kdeplot(adjusted_expression, label=\"Adjusted\", color=\"orange\")\nplt.xlabel(f'Expression of {gene_of_interest}')\nplt.ylabel('Density')\nplt.title(f'Expression Distribution of {gene_of_interest} Before and After Adjustment')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Calculate mean expression per gene\nmean_expression_original = adata.to_df().mean(axis=0)\nmean_expression_adjusted = adata_app_1.to_df().mean(axis=0)\n\n# Plot a scatter plot comparing mean expression before and after adjustment\nplt.figure(figsize=(8, 8))\nplt.scatter(mean_expression_original, mean_expression_adjusted, alpha=0.5)\nplt.plot([0, max(mean_expression_original)], [0, max(mean_expression_adjusted)], color=\"red\", linestyle=\"--\")\nplt.xlabel('Mean Expression (Original)')\nplt.ylabel('Mean Expression (Adjusted)')\nplt.title('Mean Gene Expression Before and After Adjustment')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSecond approach\nCheck the histogram of the gene expression for every gene and if it has a multimodal expression distribution to set based on that histogram a thereshold below which we consider the expression to be background. And we could remove from all cells the expression below that therahold. First making helper functions performing dip test and plotting the histogram of the gene expression. I’ve used dip test to check if the distribution is multimodal or not. If the p-value is smaller than 0.05 we consider the distribution to be multimodal. A question here would be that should we only consider non-zero expression values for this analysis or should we consider all expression values? If consider all values we might get a multimodal distribution all for genes, however if we only consider non-zero values we might miss some genes that are suspected to have multimodal distribution. What do you think?\n\ngenes_to_analyze = adata.var_names[0:len(adata.var_names)]\nthresholds = {}\nfor gene in genes_to_analyze:\n    threshold = hf.analyze_gene_expressions(adata, gene, bandwidth=0.05, plot=False, filter_zeros=False)\n    if threshold is not None:\n        thresholds[gene] = threshold\n\nSort genes by threshold values in descending order and display the top genes with the highest thresholds\n\nsorted_thresholds = sorted(thresholds.items(), key=lambda x: x[1], reverse=True)\nprint(\"Top genes with the highest thresholds:\")\nfor gene, threshold_value in sorted_thresholds[:10]:\n    print(f\"{gene}: {threshold_value}\")\n\nTop genes with the highest thresholds:\nC3: 9.797229191085119\nCrh: 9.30170339008083\nTgm1: 9.151178239165127\nPtx3: 9.081075215714053\nTh: 7.629701487384401\nCxcl10: 7.478884432901133\nPln: 7.468555342402305\nItgax: 7.4166006570284795\nIl1a: 7.1395792748119025\nChodl: 7.0284665207992925\n\n\n\ngene_of_interest = \"Calb1\"\nhf.analyze_gene_expressions(adata, gene_of_interest, bandwidth=0.05, plot=True, filter_zeros=False)\n\n\n\n\n\n\n\n\nCalb1 has a Multimodal modality (p-value=0.00)\nBackground threshold for Calb1 is 1.498\n\n\n1.498341975269375\n\n\n\nadata.X = adata.layers['lognorm'].copy()\ngene_of_interest = \"Calb1\"\nhf.analyze_gene_expressions(adata, gene_of_interest, bandwidth=0.05, plot=True, filter_zeros=False)\n\n\n\n\n\n\n\n\nCalb1 has a Multimodal modality (p-value=0.00)\nBackground threshold for Calb1 is 5.090\n\n\n5.089991098886973\n\n\n\nadata.X = adata.layers['scaled'].copy()\ngene_of_interest = \"Calb1\"\nhf.analyze_gene_expressions(adata, gene_of_interest, bandwidth=0.05, plot=True, filter_zeros=False)\n\n\n\n\n\n\n\n\nCalb1 has a Multimodal modality (p-value=0.00)\nBackground threshold for Calb1 is 1.498\n\n\n1.498341975269375\n\n\n\nadata.X = adata.layers['pearson'].copy()\ngene_of_interest = \"Calb1\"\nhf.analyze_gene_expressions(adata, gene_of_interest, bandwidth=0.05, plot=True, filter_zeros=False)\n\n\n\n\n\n\n\n\nCalb1 has a Unimodal modality (p-value=0.19)\n\n\n\nadata.X = adata.layers['size'].copy()\ngene_of_interest = \"Calb1\"\nhf.analyze_gene_expressions(adata, gene_of_interest, bandwidth=0.05, plot=True, filter_zeros=False)\n\n\n\n\n\n\n\n\nCalb1 has a Multimodal modality (p-value=0.00)\nBackground threshold for Calb1 is 0.391\n\n\n0.39147009018736884\n\n\nNow we can do the subtraction of genes with a background expression from their original values in each cell.\n\n# 1. Reverse the log1p transformation on adata.X\nadata_app_2 = adata.copy()\nif sp.issparse(adata_app_2.X):\n    adata_app_2.X = sp.csr_matrix(np.expm1(adata_app_2.X.toarray()))\nelse:\n    adata_app_2.X = np.expm1(adata_app_2.X)\n\n# 2. Reverse the log1p transformation on thresholds\nthresholds = {gene: np.expm1(thresh) for gene, thresh in thresholds.items()}\n\n# 3. Perform the subtraction and ensure non-negative values\nfor gene, threshold in thresholds.items():\n    if gene in adata_app_2.var_names:  # Ensure the gene exists in adata\n        gene_index = adata_app_2.var_names.get_loc(gene)\n        \n        # Extract the column as a dense numpy array\n        gene_data = adata_app_2[:, gene].X\n        if sp.issparse(gene_data):\n            gene_data = gene_data.toarray().flatten()\n\n        # Perform the subtraction and ensure non-negative values\n        updated_gene_data = np.maximum(gene_data - threshold, 0)\n\n        # Update the AnnData object\n        if sp.issparse(adata_app_2.X):\n            adata_app_2[:, gene_index].X = sp.csr_matrix(updated_gene_data[:, np.newaxis])\n        else:\n            adata_app_2[:, gene_index].X = updated_gene_data[:, np.newaxis]\n\n# 4. Reapply the log1p transformation\nsc.pp.log1p(adata_app_2)\n\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/scipy/sparse/_index.py:142: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n  self._set_arrayXarray_sparse(i, j, x)\n\n\nWARNING: adata.X seems to be already log-transformed.\n\n\n\ngene_of_interest = \"Calb1\"\n\nsc.pl.spatial(adata, color=[gene_of_interest], spot_size=10, title=f'{gene_of_interest} Expression Before Adjustment', color_map = 'viridis_r')\nsc.pl.spatial(adata_app_2, color=[gene_of_interest], spot_size=10, title=f'{gene_of_interest} Expression After Adjustment', color_map = 'viridis_r')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\noriginal_expression = adata.to_df()[gene_of_interest]\nadjusted_expression = adata_app_2.to_df()[gene_of_interest]\n\n# Plot expression distributions\nplt.figure(figsize=(10, 5))\nsns.kdeplot(original_expression, label=\"Original\", color=\"blue\")\nsns.kdeplot(adjusted_expression, label=\"Adjusted\", color=\"orange\")\nplt.xlabel(f'Expression of {gene_of_interest}')\nplt.ylabel('Density')\nplt.title(f'Expression Distribution of {gene_of_interest} Before and After Adjustment')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Principal component analysis for dimension reduction\nsc.pp.pca(adata_app_2)\nsc.pp.neighbors(adata_app_2)\nsc.tl.leiden(adata_app_2)\nsc.tl.umap(adata_app_2)\nsc.pl.umap(adata_app_2, color='leiden', title='UMAP after filtering suspected false positives (approach 2)')"
  },
  {
    "objectID": "day_1/practical_1/data/READM.html",
    "href": "day_1/practical_1/data/READM.html",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "",
    "text": "Download and extract the data from the following link:\nhttps://cf.10xgenomics.com/samples/xenium/1.4.0/Xenium_V1_FFPE_TgCRND8_17_9_months/Xenium_V1_FFPE_TgCRND8_17_9_months_outs.zip"
  },
  {
    "objectID": "day_1/practical_1/workdir/Practical_1_segmentation.html",
    "href": "day_1/practical_1/workdir/Practical_1_segmentation.html",
    "title": "ELIXIR Spatial Transcriptomics Course",
    "section": "",
    "text": "Practical 1c: Segmentation of spatial transcriptomics data using cellpose\nDate: 2025-01-22\nAuthor(s): Rasool Saghaleyni\nAuthor(s) email: rasool.saghaleyni@scilifelab.se\n⚠️ Note: The proper environment for this notebook is segmentation_env. It can be activated by selecting the kernel in the Jupyter notebook.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom cellpose import models, io, plot\nfrom tifffile import imread\nimport os\nimport tifffile\nfrom cellpose import plot\nimport shapely.geometry as geometry\nfrom shapely.geometry import Polygon\nfrom shapely.affinity import translate, scale\nfrom shapely.errors import TopologicalError\nfrom rasterio import features\nfrom sklearn.metrics import jaccard_score\nfrom skimage.measure import regionprops_table\n\n\n# Set up plotting aesthetics\nsns.set(style='whitegrid')\n%matplotlib inline\n\nLoading and inspecting the morphology image is a foundational step in the analysis. Understanding the image’s dimensions helps guide downstream processing, including selecting channels or slices for segmentation and defining an ROI if needed.\n\nimage_data_path = '../data/Xenium_V1_FFPE_TgCRND8_17_9_months_outs/morphology.ome.tif'\nimage = tifffile.imread(image_data_path)\nprint(f\"Image shape: {image.shape}\")\n\nImage shape: (26, 24864, 31348)\n\n\nwe retrieve and inspect the metadata embedded within the morphology image file. Opening the file with tifffile.TiffFile allows us to access not only the pixel data but also any associated metadata stored in OME (Open Microscopy Environment) format. By using a context manager (with statement), we ensure that the file is properly handled, meaning it will close automatically once we’re done, helping to avoid potential file-handling errors.\nThe OME metadata contains crucial information about the image acquisition settings. Extracting it with ome_metadata = tif.ome_metadata provides us with details about the microscope settings, pixel size, and other experimental parameters. This metadata appears in XML format, which is printed for review. Examining this data is essential to understand the spatial resolution of the image, enabling us to relate image coordinates to real-world units, such as micrometers. Knowing these specifics is key for aligning segmentation results accurately with the spatial features observed in the morphology image.\n\nwith tifffile.TiffFile(image_data_path) as tif:\n    ome_metadata = tif.ome_metadata\n    print(ome_metadata)\n\n&lt;OME xmlns=\"http://www.openmicroscopy.org/Schemas/OME/2016-06\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" Creator=\"tifffile.py 2022.10.10\" UUID=\"urn:uuid:eaf5dc46-d5c3-11ed-ad40-068afc1a6c91\" xsi:schemaLocation=\"http://www.openmicroscopy.org/Schemas/OME/2016-06 http://www.openmicroscopy.org/Schemas/OME/2016-06/ome.xsd\"&gt;\n    &lt;Plate ID=\"Plate:1\" WellOriginX=\"-0.0\" WellOriginXUnit=\"µm\" WellOriginY=\"-0.0\" WellOriginYUnit=\"µm\" /&gt;\n    &lt;Instrument ID=\"Instrument:1\"&gt;\n        &lt;Microscope Manufacturer=\"10x Genomics\" Model=\"Xenium\" /&gt;\n    &lt;/Instrument&gt;\n    &lt;Image ID=\"Image:0\" Name=\"Image0\"&gt;\n        &lt;InstrumentRef ID=\"Instrument:1\" /&gt;\n        &lt;Pixels DimensionOrder=\"XYZCT\" ID=\"Pixels:0\" SizeC=\"1\" SizeT=\"1\" SizeX=\"31348\" SizeY=\"24864\" SizeZ=\"26\" Type=\"uint16\" PhysicalSizeX=\"0.2125\" PhysicalSizeY=\"0.2125\" PhysicalSizeZ=\"3.0\"&gt;\n            &lt;Channel ID=\"Channel:0:0\" Name=\"DAPI\" SamplesPerPixel=\"1\" /&gt;\n            &lt;TiffData PlaneCount=\"26\" /&gt;\n        &lt;/Pixels&gt;\n    &lt;/Image&gt;\n&lt;/OME&gt;\n\n\nLets preview the transcripts data again:\n\ntranscriptomics_data_path = '../data/Xenium_V1_FFPE_TgCRND8_17_9_months_outs/transcripts.csv.gz'\ndata = pd.read_csv(transcriptomics_data_path, compression='gzip')\nprint(data.head())\n\n     transcript_id     cell_id  overlaps_nucleus feature_name  x_location  \\\n0  281474976710656  UNASSIGNED                 0        Sox10   164.48816   \n1  281474976710657  UNASSIGNED                 0         Ctsh   169.85483   \n2  281474976710658  UNASSIGNED                 0        Ntng1   260.06710   \n3  281474976710659  UNASSIGNED                 0        Ntng1   269.16196   \n4  281474976710660  UNASSIGNED                 0        Ntng1   272.35153   \n\n   y_location  z_location         qv fov_name  nucleus_distance  \n0   26.783148   11.713852   6.386437       A1           0.00000  \n1  652.652700   11.551014  27.915363       A1           0.00000  \n2  483.239100   12.582438  15.282572       A1         158.24005  \n3  409.500850   14.335079  29.190600       A1          84.09205  \n4  406.806150   15.083600  23.004885       A1          80.83307  \n\n\nHere, we are checking and handling the dimensionality of the morphology image to extract a usable 2D channel for segmentation and analysis. To start, print(f\"Image dimensions: {image.ndim}\") reveals the number of dimensions in the image array. Images acquired from microscopy can have multiple dimensions, often representing different z-slices, time points, or channels (e.g., specific fluorescent stains). Knowing the exact number of dimensions is essential for understanding the structure of the data and selecting the specific layer or channel needed for downstream tasks.\nWe then use conditional statements to select the appropriate 2D plane. If the image has five dimensions—typically representing time, Z (depth), channels, height, and width—we select the first time point, Z-slice, and channel to reduce it to 2D. Similarly, for four-dimensional images (likely Z, channels, height, and width), we choose the first Z-slice and channel. In the case of three-dimensional images, we assume they represent channels, height, and width, and extract the first channel. Finally, if the image is already 2D, we simply assign it to image_channel without further modification.\nThis step ensures that we have a consistent, interpretable 2D array (image_channel) for the following analysis. By isolating a single plane or channel, we simplify the data, making it easier to overlay segmentations or spatial features without the added complexity of multiple dimensions. This also ensures that our chosen channel represents the tissue morphology effectively\n\nprint(f\"Image dimensions: {image.ndim}\")\nif image.ndim == 5:\n    # Example shape: (Time, Z, Channels, Height, Width)\n    # Select the first time point, z-slice, and channel\n    image_channel = image[0, 0, 0, :, :]\nelif image.ndim == 4:\n    # Example shape: (Z, Channels, Height, Width)\n    image_channel = image[0, 0, :, :]\nelif image.ndim == 3:\n    # Example shape: (Channels, Height, Width)\n    image_channel = image[0, :, :]\nelse:\n    # Already a 2D image\n    image_channel = image\n\nImage dimensions: 3\n\n\n\nimage_channel = np.max(image, axis=0)\nimage_channel = image_channel.astype(np.uint16)\n\n\nplt.figure(figsize=(8, 8))\nplt.imshow(image_channel)\nplt.title('Selected Image for Segmentation')\nplt.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\nSince the original image is too big here we define a region of interest (ROI) within the larger image, focusing on a smaller area for more efficient and targeted analysis. This is particularly useful for high-resolution images where analyzing the entire field of view might be computationally intensive.\nWe begin by setting a scale_factor, which controls the size of the ROI as a fraction of the full image dimensions. Here, scale_factor = 0.05 means that the ROI will cover 5% of the original image’s width and height. Adjusting this factor allows flexibility in focusing on larger or smaller portions of the image, depending on the needs of the analysis.\nUsing image_channel.shape, we extract the height and width of the full image. Then, by multiplying these dimensions by scale_factor, we calculate the width and height of the ROI (roi_width and roi_height). Converting these values to integers ensures that they’re compatible with image indexing.\nFinally, we make an optional adjustment to ensure that the ROI dimensions are even numbers, which can simplify image processing tasks. We do this by reducing roi_width and roi_height by 1 if they are odd, using modulo operations. This adjustment helps avoid issues when working with certain algorithms that may require even-numbered dimensions, ensuring that the ROI dimensions are compatible with a range of image processing techniques.\n\nscale_factor = 0.05\nimage_height, image_width = image_channel.shape\n\n# roi\nroi_width = int(image_width * scale_factor)\nroi_height = int(image_height * scale_factor)\nroi_width -= roi_width % 2\nroi_height -= roi_height % 2\n\n#calculate the starting and ending coordinates\nx_center = image_width // 2\ny_center = image_height // 2\n\nx_start = x_center - roi_width // 2\nx_end = x_center + roi_width // 2\ny_start = y_center - roi_height // 2\ny_end = y_center + roi_height // 2\n\nExtract the ROI from the image\n\nroi_image = image_channel[y_start:y_end, x_start:x_end]\n# dimensions\nprint(f\"ROI image shape: {roi_image.shape}\")\n\nROI image shape: (1242, 1566)\n\n\n\nplt.figure(figsize=(8, 8))\nplt.imshow(roi_image)\nplt.title('ROI Image for Segmentation')\nplt.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\nNext we map the ROI pixel coordinates back to real-world units (micrometers) and filter the spatial transcriptomics data to include only the transcripts within the ROI. This enables precise alignment of the transcript data with the selected region in the image.\nWe start by defining scaling factors for converting image pixels to micrometers. Here, x_scale and y_scale represent the conversion rate based on the pixel size provided in the image metadata: each micrometer contains approximately 4.7 pixels (1 / 0.2125). This conversion allows us to translate pixel coordinates into micrometer units, which are required for comparing and aligning data across different scales.\nUsing these scaling factors, we calculate the boundaries of the ROI in micrometers. For each dimension, x_start, x_end, y_start, and y_end (which are pixel coordinates from the original image), we divide by the scaling factor to obtain the corresponding boundaries in micrometers: x_start_um, x_end_um, y_start_um, and y_end_um. This step ensures that our ROI is defined consistently in both pixel and physical units.\nNext, we filter the transcriptomics data to include only the transcripts located within the ROI. We use conditional filtering on the x_location and y_location columns of the data DataFrame, retaining only the transcripts whose coordinates fall within the calculated micrometer boundaries. The result is stored in roi_data, which represents the subset of transcripts that reside within our chosen ROI.\nFinally, by printing len(roi_data), we get a quick count of the transcripts within the ROI.\n\n#using the scaling factors from before\nx_scale = 1 / 0.2125  # pixels per µm\ny_scale = 1 / 0.2125  # pixels per µm\n\n#roi boundaries in micrometers\nx_start_um = x_start / x_scale\nx_end_um = x_end / x_scale\ny_start_um = y_start / y_scale\ny_end_um = y_end / y_scale\n\n#filter transcripts within the ROI boundaries\nroi_data = data[\n    (data['x_location'] &gt;= x_start_um) &\n    (data['x_location'] &lt; x_end_um) &\n    (data['y_location'] &gt;= y_start_um) &\n    (data['y_location'] &lt; y_end_um)\n].copy()\nprint(f\"Number of transcripts in ROI: {len(roi_data)}\")\n\nNumber of transcripts in ROI: 47902\n\n\nNow we should subtract x_start_um from each transcript’s x_location and y_start_um from each y_location in roi_data. By doing so, we create new columns, x_location_roi and y_location_roi, that represent each transcript’s position relative to the top-left corner of the ROI rather than the full image.\n\nroi_data['x_location_roi'] = roi_data['x_location'] - x_start_um\nroi_data['y_location_roi'] = roi_data['y_location'] - y_start_um\n\nNow we finally set up the Cellpose segmentation model to identify cells within the ROI. Cellpose is a versatile deep learning-based tool commonly used for cell segmentation, especially on fluorescence and cytoplasmic images. Here, we are preparing the model for use in the analysis.\nFirst, we import the models module from the cellpose package, which provides access to pre-trained Cellpose models. Next, we initialize a model instance using models.Cellpose(). By setting gpu=False, we specify that the model will run on the CPU. This is useful if GPU resources are unavailable, though using a GPU can speed up the segmentation process if it is an option.\nWe also set model_type='cyto', indicating that the model should use Cellpose’s pre-trained “cyto” (cytoplasm) model, which is optimized for identifying cell boundaries in images with visible cell structures. This choice is typically well-suited for images showing cell cytoplasm, though Cellpose offers other model types, like “nuclei,” if our focus were solely on nuclear segmentation.\n\nfrom cellpose import models\nmodel = models.Cellpose(gpu=False, model_type='cyto')\n\n/Users/rasools/miniconda3/envs/segmentation_env/lib/python3.9/site-packages/cellpose/resnet_torch.py:280: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load(filename, map_location=torch.device(\"cpu\"))\n\n\nThen, we estimate the average cell diameter in pixels and then use Cellpose to perform cell segmentation on the ROI.\nWe start by setting cell_diameter_um to an estimated cell diameter in micrometers, which is based on biological knowledge of cell sizes in the specific tissue or sample type. Here, we use 10 micrometers as the mouse cell daimeter for mouse brains cells is estrimated 7-10 micrometers, but this value can be adjusted based on the specific dataset.\nTo convert this estimate into pixel units, we multiply cell_diameter_um by the scaling factor x_scale (pixels per micrometer), calculated previously. This results in cell_diameter_pixels, an approximation of the cell diameter in the pixel space of the image. By converting the diameter to pixels, we ensure that Cellpose can interpret the size parameter relative to the image’s resolution.\nNext, we run the Cellpose model on roi_image, the 2D image extracted from the ROI. The model’s eval() function applies the segmentation model to the image, using diameter=cell_diameter_pixels to guide the segmentation scale. The channels=[0, 0] parameter specifies that the image is grayscale; both entries as 0 indicate that there is a single channel for both input and detection purposes.\nThe eval() function returns several outputs:\n\nmasks: a labeled mask array where each detected cell has a unique identifier,\nflows: which provides information about cell boundary flows,\nstyles: representing style vectors for detected objects, and\ndiams: the diameter used in the model (helpful if it has been automatically adjusted).\n\n\ncell_diameter_um = 10  # µm\ncell_diameter_pixels = cell_diameter_um * x_scale\nprint(f\"Estimated cell diameter in pixels: {cell_diameter_pixels}\")\n#run segmentation\nmasks, flows, styles, diams = model.eval(\n    roi_image,\n    diameter=cell_diameter_pixels,\n    channels=[0, 0]\n)\n\nEstimated cell diameter in pixels: 47.05882352941177\n\n\n\nprint(f\"Number of cells detected in ROI: {masks.max()}\")\n\nNumber of cells detected in ROI: 224\n\n\nNow we convert the transcript coordinates within the ROI from micrometers to pixel indices, preparing them for alignment with the segmentation mask.\nFirst, we extract the x- and y-coordinates in micrometers from roi_data, which represents transcript locations relative to the top-left corner of the ROI. These coordinates are stored in x_coords_um and y_coords_um, making it easy to work directly with arrays of positions.\nTo map these positions into the pixel space of roi_image, we multiply each coordinate by the scaling factor (x_scale and y_scale) previously defined. This scaling factor converts micrometers into pixel units, allowing us to obtain x_indices and y_indices the pixel indices that match the resolution of the segmentation mask.\nBy converting coordinates to pixel indices, we can precisely locate each transcript in the context of the segmented cells within the ROI.\n\nx_coords_um = roi_data['x_location_roi'].values\ny_coords_um = roi_data['y_location_roi'].values\n\n#pixel indices\nx_indices = (x_coords_um * x_scale).astype(int)\ny_indices = (y_coords_um * y_scale).astype(int)\n\n\n#Roi image dimensions\nroi_height, roi_width = roi_image.shape\n\n#indices\nx_indices = np.clip(x_indices, 0, roi_width - 1)\ny_indices = np.clip(y_indices, 0, roi_height - 1)\n\nNext we assign each transcript to a segmented cell based on its pixel coordinates, linking gene expression data to specific cells within the ROI.\n\n#cell labels for each transcript\ncell_labels = masks[y_indices, x_indices]\n#Add cell labels to the data\nroi_data['cellpose_cell_id'] = cell_labels\n\n#preview\nprint(roi_data.head())\n\n           transcript_id     cell_id  overlaps_nucleus feature_name  \\\n8282551  281599530763477  nodbomii-1                 1         Gusb   \n8282556  281599530763482  bdamcjfe-1                 0         Cst3   \n8282569  281599530763495  nodbomii-1                 0         Cst3   \n8282582  281599530763508  bdamcjfe-1                 0         Cst3   \n8282603  281599530763529  nodbomii-1                 1        Parm1   \n\n         x_location  y_location  z_location        qv fov_name  \\\n8282551   3166.3472   2527.3328   34.873024  40.00000       C6   \n8282556   3166.8430   2533.2446   34.078390  40.00000       C6   \n8282569   3167.3296   2529.3591   33.823017  40.00000       C6   \n8282582   3168.9888   2531.9070   34.126305  38.92044       C6   \n8282603   3171.1484   2524.1245   34.531853  40.00000       C6   \n\n         nucleus_distance  x_location_roi  y_location_roi  cellpose_cell_id  \n8282551          0.000000          2.0097         17.4953                15  \n8282556          0.705350          2.5055         23.4071                 0  \n8282569          0.609131          2.9921         19.5216                 0  \n8282582          0.900610          4.6513         22.0695                 0  \n8282603          0.223389          6.8109         14.2870                 0  \n\n\nKeep only transcripts assigned to a cell\n\nassigned_data = roi_data[roi_data['cellpose_cell_id'] &gt; 0].copy()\nprint(f\"Total transcripts in ROI: {len(roi_data)}\")\nprint(f\"Assigned transcripts: {len(assigned_data)}\")\n\nTotal transcripts in ROI: 47902\nAssigned transcripts: 17030\n\n\nwe visualize the results of the Cellpose segmentation overlayed on the ROI image, allowing us to inspect how well the model identified individual cells in the selected region.\n\nfig = plt.figure(figsize=(8, 8))\nplot.show_segmentation(fig, roi_image, masks, flows[0])\nplt.title('Cellpose Segmentation on ROI')\nplt.show()\n\n\n\n\n\n\n\n\nGroup by cell and gene to get expression counts\n\nexpression_per_cell = assigned_data.groupby(['cellpose_cell_id', 'feature_name']).size().reset_index(name='count')\nexpression_matrix = expression_per_cell.pivot(index='cellpose_cell_id', columns='feature_name', values='count').fillna(0)\nprint(expression_matrix.head())\n\nfeature_name      2010300C02Rik  Abca7  Acsbg1  Acta2  Acvrl1  Adamts2  \\\ncellpose_cell_id                                                         \n1                           0.0    0.0     1.0    0.0     2.0      0.0   \n2                           0.0    0.0     1.0    0.0     0.0      0.0   \n3                           0.0    0.0     0.0    0.0     0.0      0.0   \n4                           1.0    0.0     0.0    0.0     0.0      0.0   \n5                           1.0    1.0     0.0    0.0     0.0      0.0   \n\nfeature_name      Adamtsl1  Adgrl4  Aldh1a2  Aldh1l1  ...  Unc13c  Vat1l  \\\ncellpose_cell_id                                      ...                  \n1                      0.0     4.0      0.0      1.0  ...     0.0    0.0   \n2                      0.0     0.0      0.0      0.0  ...     0.0    0.0   \n3                      0.0     0.0      0.0      0.0  ...     0.0    0.0   \n4                      0.0     0.0      0.0      0.0  ...     0.0    1.0   \n5                      0.0     0.0      0.0      0.0  ...     0.0    1.0   \n\nfeature_name      Vcan  Vim  Vip  Vwc2l  Wfs1  Zfp366  Zfp536  Zfpm2  \ncellpose_cell_id                                                      \n1                  0.0  1.0  0.0    0.0   0.0     0.0     0.0    0.0  \n2                  0.0  0.0  0.0    0.0   0.0     0.0     0.0    0.0  \n3                  0.0  0.0  0.0    0.0   0.0     0.0     0.0    0.0  \n4                  0.0  0.0  0.0    0.0   0.0     0.0     0.0    0.0  \n5                  0.0  0.0  0.0    0.0   0.0     0.0     1.0    0.0  \n\n[5 rows x 418 columns]\n\n\nwe can plot the locations of transcripts overlaid on the ROI image, specifically highlighting those that have been assigned to segmented cells. This helps us see how transcript data aligns with the detected cell boundaries within the region.\n\nplt.figure(figsize=(8, 8))\nplt.imshow(roi_image, cmap='gray')\nplt.scatter(\n    x_indices[roi_data['cellpose_cell_id'] &gt; 0],\n    y_indices[roi_data['cellpose_cell_id'] &gt; 0],\n    c='red', s=5, label='Transcripts'\n)\nplt.title('Transcripts Mapped to Segmented Cells')\nplt.axis('off')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFinally, we can visualize the expression of a specific gene across the detected cells, providing insights into the spatial distribution of gene expression within the ROI. This visualization can reveal patterns of gene expression, such as high expression in specific cell types or regions, helping to interpret the biological significance of the data.\n\ngene_of_interest = 'Cst3'\n\nif gene_of_interest in expression_matrix.columns:\n    cell_ids = expression_matrix.index.values\n    expression_values = expression_matrix[gene_of_interest].values\n\n    #get centroids of cells\n    from skimage.measure import regionprops\n    properties = regionprops(masks)\n    centroids = np.array([prop.centroid for prop in properties])\n    cell_labels = np.array([prop.label for prop in properties])\n\n    #create a mapping from cell label to centroid\n    centroid_dict = {label: centroid for label, centroid in zip(cell_labels, centroids)}\n\n    #get centroids for the cells in expression_matrix\n    cell_centroids = np.array([centroid_dict.get(cell_id, (np.nan, np.nan)) for cell_id in cell_ids])\n\n    plt.figure(figsize=(8, 8))\n    plt.imshow(roi_image, cmap='gray')\n    plt.scatter(\n        cell_centroids[:, 1],  # x-coordinates\n        cell_centroids[:, 0],  # y-coordinates\n        c=expression_values,\n        cmap='viridis',\n        s=50,\n        edgecolors='k',\n        label=f'Expression of {gene_of_interest}'\n    )\n    plt.title(f'Expression of {gene_of_interest}')\n    plt.axis('off')\n    plt.colorbar(label='Expression Level')\n    plt.show()\nelse:\n    print(f\"{gene_of_interest} not found in expression matrix.\")\n\n\n\n\n\n\n\n\nnow we want to compare the cellpose segmentation with 10x segmentation, we can use the Jaccard index to quantify the similarity between the two segmentation masks. The Jaccard index, also known as the intersection-over-union (IoU), measures the overlap between two sets by dividing the size of their intersection by the size of their union. In the context of segmentation masks, the Jaccard index provides a measure of how well two masks align, with values closer to 1 indicating greater similarity.\n\ncells_data_path = '../data/Xenium_V1_FFPE_TgCRND8_17_9_months_outs/cells.csv'\ncells_data = pd.read_csv(cells_data_path)\nprint(cells_data.head())\n\n      cell_id  x_centroid  y_centroid  transcript_counts  \\\n0  aaabiggh-1  831.785336  755.803772                554   \n1  aaacfoel-1  821.733453  768.910446                291   \n2  aaaeefil-1  831.932053  780.367651                220   \n3  aaaehidd-1  853.614108  774.764157               1029   \n4  aaagcbkg-1  821.639603  799.171515                453   \n\n   control_probe_counts  control_codeword_counts  unassigned_codeword_counts  \\\n0                     0                        0                           0   \n1                     0                        0                           0   \n2                     1                        0                           0   \n3                     0                        0                           0   \n4                     0                        0                           1   \n\n   total_counts   cell_area  nucleus_area  \n0           554  509.091563     65.386250  \n1           291  275.498281     36.982969  \n2           221  261.635312     15.849844  \n3          1029  818.547344    129.056563  \n4           454  522.232031     96.002188  \n\n\n\ncell_boundaries_path = '../data/Xenium_V1_FFPE_TgCRND8_17_9_months_outs/cell_boundaries.csv.gz'  \ncell_boundaries = pd.read_csv(cell_boundaries_path)\nprint(cell_boundaries.head())\n\n      cell_id  vertex_x  vertex_y\n0  aaabiggh-1  829.6000  742.0500\n1  aaabiggh-1  816.6375  752.6750\n2  aaabiggh-1  815.3625  757.9875\n3  aaabiggh-1  822.5875  761.3875\n4  aaabiggh-1  835.9750  768.6125\n\n\nFirst we need to extract the region of intrest from the 10x segmentation mask, then we need to resize the 10x segmentation mask to the same size as the cellpose segmentation mask, then we can calculate the Jaccard index between the two masks.\n\nscale_factor = 0.05\nimage_height, image_width = image_channel.shape\nroi_width = int(image_width * scale_factor)\nroi_height = int(image_height * scale_factor)\n\nroi_width -= roi_width % 2\nroi_height -= roi_height % 2\n\nx_center = image_width // 2\ny_center = image_height // 2\n\nx_start = x_center - roi_width // 2\nx_end = x_center + roi_width // 2\ny_start = y_center - roi_height // 2\ny_end = y_center + roi_height // 2\n\n#cnvert pixel coordinates to micrometers\nx_scale = 1 / 0.2125  \ny_scale = 1 / 0.2125\n\nx_start_um = x_start / x_scale\nx_end_um = x_end / x_scale\ny_start_um = y_start / y_scale\ny_end_um = y_end / y_scale\n\nFilter cells whose centroids are within the ROI\n\ncells_in_roi = cells_data[\n    (cells_data['x_centroid'] &gt;= x_start_um) &\n    (cells_data['x_centroid'] &lt; x_end_um) &\n    (cells_data['y_centroid'] &gt;= y_start_um) &\n    (cells_data['y_centroid'] &lt; y_end_um)\n].copy()\n\nprint(f\"Number of cells in ROI from original segmentation: {len(cells_in_roi)}\")\n\nNumber of cells in ROI from original segmentation: 284\n\n\nFilter cell boundaries for cells in ROI\n\ncell_boundaries_in_roi = cell_boundaries[cell_boundaries['cell_id'].isin(cells_in_roi['cell_id'])].copy()\ncell_polygons = {}\nfor cell_id, group in cell_boundaries_in_roi.groupby('cell_id'):\n    x_coords = group['vertex_x'].values\n    y_coords = group['vertex_y'].values\n    coords = list(zip(x_coords, y_coords))\n    try:\n        polygon = Polygon(coords)\n        if not polygon.is_valid:\n            # Attempt to fix invalid polygons\n            polygon = polygon.buffer(0)\n        cell_polygons[cell_id] = polygon\n    except TopologicalError as e:\n        print(f\"Could not create polygon for cell {cell_id}: {e}\")\n\n\n# lets make a function to transform geometries to pixel coordinates\ndef geometry_to_pixel_coords(geometry):\n    #shift geometry to ROI coordinates (subtract ROI origin in micrometers)\n    geometry_shifted = translate(geometry, xoff=-x_start_um, yoff=-y_start_um)\n    #scale geometry from micrometers to pixels\n    geometry_scaled = scale(geometry_shifted, xfact=x_scale, yfact=y_scale, origin=(0, 0))\n    return geometry_scaled\n\n# now appply transformation to all cell polygons\ncell_polygons_px = {cell_id: geometry_to_pixel_coords(geom) for cell_id, geom in cell_polygons.items()}\n\nMap cell_id strings to integer labels\n\ncell_id_to_label = {cell_id: idx+1 for idx, cell_id in enumerate(cell_polygons_px.keys())}\nlabel_to_cell_id = {idx+1: cell_id for idx, cell_id in enumerate(cell_polygons_px.keys())}\n\nPrepare shapes for rasterization\n\nshapes = [\n    (geom, cell_id_to_label[cell_id])\n    for cell_id, geom in cell_polygons_px.items()\n]\n\nCreate an empty mask and rasterize the shapes\n\noriginal_masks = np.zeros_like(roi_image, dtype=np.uint16)\noriginal_masks = features.rasterize(\n    shapes,\n    out_shape=original_masks.shape,\n    fill=0,\n    all_touched=True,\n    dtype=np.uint16\n)\n\nLets compare the cellpose segmentation with 10x segmentation side by side\n\nplt.figure(figsize=(16, 8))\n\n#Cellpose \nplt.subplot(1, 2, 1)\nplt.imshow(roi_image, cmap='gray')\nplt.imshow(masks, alpha=0.5, cmap='jet')\nplt.title('Cellpose Segmentation')\nplt.axis('off')\n\n#Original \nplt.subplot(1, 2, 2)\nplt.imshow(roi_image, cmap='gray')\nplt.imshow(original_masks, alpha=0.5, cmap='jet')\nplt.title('Original 10x Segmentation')\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAnd we can overlay the cellpose segmentation on the 10x segmentation to see how well they align\n\n# now we overlay both masks\nplt.figure(figsize=(8, 8))\nplt.imshow(roi_image, cmap='gray')\nplt.imshow((original_masks &gt; 0).astype(int), cmap='Blues', alpha=0.5, label='Original')\nplt.imshow((masks &gt; 0).astype(int), cmap='Reds', alpha=0.5, label='Cellpose')\nplt.title('Overlay of Segmentations')\nplt.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\n\n#convert masks to binary masks (cells vs background)\ncellpose_mask_binary = (masks &gt; 0).astype(int)\noriginal_mask_binary = (original_masks &gt; 0).astype(int)\n\n#flatten the masks for metric computation\ncellpose_mask_flat = cellpose_mask_binary.flatten()\noriginal_mask_flat = original_mask_binary.flatten()\n\n\n\njaccard = jaccard_score(original_mask_flat, cellpose_mask_flat)\nprint(f'Jaccard Index: {jaccard:.4f}')\n\nJaccard Index: 0.1255\n\n\n\ndef dice_coefficient(y_true, y_pred):\n    intersection = np.sum(y_true * y_pred)\n    sum_union = np.sum(y_true) + np.sum(y_pred)\n    dice = 2 * intersection / sum_union\n    return dice\n\ndice = dice_coefficient(original_mask_flat, cellpose_mask_flat)\nprint(f'Dice Coefficient: {dice:.4f}')\n\nDice Coefficient: 0.2230\n\n\n\ncellpose_cell_count = masks.max()\noriginal_cell_count = original_masks.max()\n\nprint(f\"Number of cells detected by Cellpose: {cellpose_cell_count}\")\nprint(f\"Number of cells in original segmentation: {original_cell_count}\")\n\nNumber of cells detected by Cellpose: 224\nNumber of cells in original segmentation: 284\n\n\n\n#cellpose cell areas\ncellpose_props = regionprops_table(masks, properties=['area'])\ncellpose_areas = pd.DataFrame(cellpose_props)\ncellpose_areas['method'] = 'Cellpose'\n\n#original cell areas\noriginal_props = regionprops_table(original_masks, properties=['area'])\noriginal_areas = pd.DataFrame(original_props)\noriginal_areas['method'] = 'Original'\n\n#combine data\nareas_df = pd.concat([cellpose_areas, original_areas], ignore_index=True)\n\ncompare cell sizes between the two segmentation methods\n\nplt.figure(figsize=(10, 6))\nsns.kdeplot(data=areas_df, x='area', hue='method', common_norm=False)\nplt.xlabel('Cell Area (pixels)')\nplt.ylabel('Density')\nplt.title('Cell Size Distribution Comparison')\nplt.show()\n\n\n\n\n\n\n\n\nand save the results to a new file\n\ntifffile.imwrite('../data/Xenium_V1_FFPE_TgCRND8_17_9_months_outs/cellpose/cellpose_masks_roi.tif', masks.astype(np.uint16))\ntifffile.imwrite('../data/Xenium_V1_FFPE_TgCRND8_17_9_months_outs/cellpose/original_masks_roi.tif', original_masks.astype(np.uint16))\n\n\nmetrics = pd.DataFrame({\n    'Metric': ['Jaccard Index', 'Dice Coefficient'],\n    'Value': [jaccard, dice]\n})\nmetrics.to_csv('../data/Xenium_V1_FFPE_TgCRND8_17_9_months_outs/cellpose/segmentation_comparison_metrics.csv', index=False)\n\n\nareas_df.to_csv('../data/Xenium_V1_FFPE_TgCRND8_17_9_months_outs/cellpose/cell_size_comparison.csv', index=False)"
  },
  {
    "objectID": "day_1/practical_1/workdir/Practical_1_sainsc_seg_free.html",
    "href": "day_1/practical_1/workdir/Practical_1_sainsc_seg_free.html",
    "title": "ELIXIR Spatial Transcriptomics Course",
    "section": "",
    "text": "Date: 2025-01-22\nAuthor(s): Niklas Müller-Bötticher, Rasool Saghaleyni\nAuthor(s) email: niklas.mueller-boetticher@bih-charite.de, rasool.saghaleyni@scilifelab.\n⚠️ Note: The proper environment for this notebook is sib_sainsc_env. It can be activated by selecting the kernel in the Jupyter notebook."
  },
  {
    "objectID": "day_1/practical_1/workdir/Practical_1_sainsc_seg_free.html#imports",
    "href": "day_1/practical_1/workdir/Practical_1_sainsc_seg_free.html#imports",
    "title": "ELIXIR Spatial Transcriptomics Course",
    "section": "Imports",
    "text": "Imports\nFirst we are going to load all necessary packages for the analysis.\nWe will use sainsc for the main analysis and scanpy to cluster the cell-types in our unsupervised analysis.\n\n# Don't try this at home!\n# Usually you do want to notice if warnings come up!\nimport warnings\n\nfrom tqdm import TqdmWarning\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=TqdmWarning)\n\n\nfrom pathlib import Path\n\nimport pandas as pd\nimport scanpy as sc\nfrom sainsc.io import read_Xenium\nfrom sainsc.utils import celltype_signatures\n\nFirst we define the paths to our directory where we keep the Xenium sample that we want to analyze.\n\n# TODO: adjust to the correct path\ndata_path = Path(\"data\")\n\nsample_path = data_path / \"Xenium_V1_FFPE_TgCRND8_17_9_months\"\n\nBefore we start it is good to get a brief overview of the two main Classes in sainsc.\n\nGridCounts: This class holds the data as a dictionary of sparse matrices of the same shape. You rarely will need to interact with it directly unless you want to, filter the genes or crop/mask the sample. It mostly behaves like a Python dictionary but is implemented in Rust. Therefore, iterating over the count matrices of each gene might be slow as the data needs to be transformed every time.\nLazyKDE: This is the class that you mostly will interact with. It contains a GridCounts instance in its counts attribute and otherwise exposes almost all methods necessary to perform the analysis.\n\nWe will use the transcripts.csv.gz (or transcripts.parquet) to load the locations of all identified transcripts. The control probes from the Xenium study will be automatically filtered out.\nWe can furthermore specify the size of the bins we will asign the transcripts into (by default this is set to 0.5 um) and the number of threads we want to use to process the data.\nThere are options to directly load data from common file formats/technologies such as Stereo-seq, Xenium, and Vizgen. If none of the options fit for your use case you can have a look at LazyKDE.from_dataframe or GridCounts.from_dataframe methods.\n\nbrain = read_Xenium(sample_path / \"transcripts.csv.gz\", n_threads=8)\n\nbrain\n\nLazyKDE (8 threads)\n    genes: 347\n    shape: (13311, 10545)\n    resolution: 500.0 nm / px\n\n\nThe LazyKDE object will give us some useful information when we print it; including the number of genes, the size of the sample in pixels and the resolution.\nNext we can get a quick overview of our sample by calculating the total mRNA and plotting it. If we can squint our eyes, we can notice some technical artifacts; the mRNA seems to be lower at certain locations that seem to form a grid, likely along the stitching borders.\n\nbrain.calculate_total_mRNA()\n_ = brain.plot_genecount(im_kwargs={\"vmax\": 2})\n\n\n\n\n\n\n\n\nWe can crop our sample to remove some “dead” space to further speed up processing or to “zoom” into a smaller region of interest (ROI).\nAlternatively, we could also use the GridCounts.filter_mask method to use an arbitrary binary mask to determine the ROI. All the transcripts outside our ROI will then be dropped. This allows us to filter the ROI to any shape desired.\n\nbrain.counts.crop((500, None), (None, 10_000))\n\nbrain.calculate_total_mRNA()\n_ = brain.plot_genecount(im_kwargs={\"vmax\": 2})\n\n\n\n\n\n\n\n\nIt is always a good idea to also check the distribution of transcripts detected per gene.\n\n_ = brain.plot_genecount_histogram()\n\n\n\n\n\n\n\n\nThe kernel defines on how we will smooth the gene expression. The go-to choice is to use a gaussian kernel, however any square numpy.ndarray can be used.\nThe size of the kernel can either be defined in pixels or in µm (if the resolution is set).\nThe required kernel size may depend on the technology. Here, we will use 2.5 µm.\n\nbrain.gaussian_kernel(2.5, unit=\"um\")\n\nNow we can first smooth the total mRNA and visualize it.\n\nbrain.calculate_total_mRNA_KDE()\n_ = brain.plot_KDE()\n\n\n\n\n\n\n\n\nThe distribtuion of the smoothed gene expression can be used to determine a threshold to use for filtering out background noise. Here, a value of ~ 0.02 seems to be a good first choice.\n\n_ = brain.plot_KDE_histogram(bins=200)\n\n\n\n\n\n\n\n\n\n_ = brain.plot_KDE_histogram(bins=100, range=(0, 0.1))\n\n\n\n\n\n\n\n\nEven though in the images above it looked like the background was empty, adjusting the color scale will quickly prove us that this is not the case.\nHere, masking the ROI could be used to completely remove those counts. Filtering the background, on the other side, will only affect the visualization but not the processing.\n\n_ = brain.plot_KDE(im_kwargs={\"vmax\": 0.02})\n\n\n\n\n\n\n\n\nNow we can filter the background. Note, that later we can further refine this and define background filter on the total mRNA KDE per cell type.\n\nbrain.filter_background(0.02)"
  },
  {
    "objectID": "day_1/practical_1/workdir/Practical_1_sainsc_seg_free.html#unsupervised-analysis",
    "href": "day_1/practical_1/workdir/Practical_1_sainsc_seg_free.html#unsupervised-analysis",
    "title": "ELIXIR Spatial Transcriptomics Course",
    "section": "Unsupervised analysis",
    "text": "Unsupervised analysis\nTo generate the cell-type map we will need a set of gene expression signatures. These can either be derived from previous studies e.g. scRNAseq or we can identify them de novo from the sample we are analysing.\nThe de novo approach works by finding the local maxima of the gene expression and treating these as proxies for cells. We can then use standard single-cell/spatial workflows to process and cluster the cells. The cell-types indentified in the clustering can then be used to calculate the gene expression signatures.\nThe first step is to identify the local maxiam, we set a minimum distance to avoid sampling too many close-by spots.\n\nbrain.find_local_maxima(5)\nbrain\n\nLazyKDE (8 threads)\n    genes: 347\n    shape: (12811, 10000)\n    resolution: 500.0 nm / px\n    kernel: (21, 21)\n    background: set\n    local maxima: 84858\n\n\n\nFind cell-type signatures\nNext we can load the local maxima into and AnnData object and then proceed to identify clusters.\n\nlocal_max = brain.load_local_maxima()\nlocal_max\n\nAnnData object with n_obs × n_vars = 84858 × 347\n    obs: 'total_mRNA_KDE'\n    obsm: 'spatial'\n\n\n\n# for reproducibility\nrandom_state = 42\n\n\nsc.pp.normalize_total(local_max)\n\n\nlocal_max.layers[\"counts\"] = local_max.X.copy()\n\n\nsc.pp.log1p(local_max)\nsc.pp.pca(local_max, random_state=random_state)\nsc.pp.neighbors(local_max, random_state=random_state)\nsc.tl.umap(local_max, random_state=random_state)\n\n\nsc.tl.leiden(local_max, resolution=2, random_state=random_state)\n\nsc.pl.umap(local_max, color=\"leiden\")\n\n\n\n\n\n\n\n\nAfter we have identified our cell-types/clusters we can easily calculate the gene expression signatures.\nNote, the gene expression signatures should be strictly positive i.e. they should not be calculated from data that has been standardized or similar.\n\nsignatures = celltype_signatures(local_max, celltype_col=\"leiden\")\n\n\n\nGenerate cell-type map\nTo generate the cell-type map we just need to pass the signature DataFrame to the assign_celltype method.\nIf the gene expression varies across multiple orders of magnitude across genes it might be useful to use log-transformation after calculating the KDE. In this case the gene expression signatures should be calculated from log-transformed data, as well.\n\nbrain.assign_celltype(signatures, log=True)\n\n\n# maintain the same coloring as in UMAP\ncmap = {\n    cluster: color\n    for cluster, color in zip(\n        local_max.obs[\"leiden\"].cat.categories, local_max.uns[\"leiden_colors\"]\n    )\n}\n\nWe can now visualize our cell-type map.\n\n_ = brain.plot_celltype_map(cmap=cmap)\n\n\n\n\n\n\n\n\nThe assignment score can be helpful to identify regions with low confidence in the cell-type assignment. This is especially useful when using pre-existing cell-type signatures as it might highlight regions where we couldn’t map any cell-type with high confidence and therefore might indicate that cell-types are missing in the reference.\n\n_ = brain.plot_assignment_score(remove_background=True)\n\n\n\n\n\n\n\n\n\nkde_per_celltype = pd.DataFrame(\n    {\n        \"kde\": brain.total_mRNA_KDE.flatten(),\n        \"celltype\": pd.Categorical.from_codes(\n            brain.celltype_map.flatten(), categories=brain.celltypes\n        ),\n    }\n).dropna()\n\ncelltype_threshold = (\n    kde_per_celltype.groupby(\"celltype\", observed=True).quantile(0.5)[\"kde\"] / 2\n).to_dict()\n\nmin_t = 0.02\n\ncelltype_threshold = {\n    ct: (t if t &gt; min_t else min_t) for ct, t in celltype_threshold.items()\n}\n\nbrain.filter_background(celltype_threshold)\n\n\n_ = brain.plot_celltype_map(cmap=cmap)\n\n\n\n\n\n\n\n\nWe can zoom-in by defining the ROI that we want to plot.\n\nroi = ((1_000, 4_500), (4_000, 6_000))\n\n_ = brain.plot_celltype_map(cmap=cmap, crop=roi, scalebar_kwargs={\"box_alpha\": 0.7})\n\n\n\n\n\n\n\n\nWe can also highlight only one/few cell-types by removing the rest from the colormap.\n\ncmap2 = {\"0\": \"yellow\"}\n\n_ = brain.plot_celltype_map(cmap=cmap2, crop=roi, scalebar_kwargs={\"box_alpha\": 0.7})\n\n\n\n\n\n\n\n\nVisualizing the gene expression can help rationalizing the assigned cell-types.\n\n_ = brain.plot_KDE(gene=signatures[\"0\"].idxmax(), crop=roi)\n\n\n\n\n\n\n\n\n\n_ = brain.plot_KDE(gene=signatures[\"18\"].idxmax(), crop=roi)"
  },
  {
    "objectID": "day_1/practical_1/workdir/Practical_1_sainsc_seg_free.html#bonus-task-supervised-analysis",
    "href": "day_1/practical_1/workdir/Practical_1_sainsc_seg_free.html#bonus-task-supervised-analysis",
    "title": "ELIXIR Spatial Transcriptomics Course",
    "section": "Bonus task: Supervised analysis",
    "text": "Bonus task: Supervised analysis\nTry using sainsc for a supervised analysis leveraging the cell-type signatures obtained from your previous segmentation-based analysis workflow."
  },
  {
    "objectID": "day_2/practical_3/workdir/spatial_course_SOL_CH.html",
    "href": "day_2/practical_3/workdir/spatial_course_SOL_CH.html",
    "title": "Computational analysis of spatial transcriptomics data",
    "section": "",
    "text": "1. Spatial data download and format\n2. Spatial imputation with SpaGE and Tangram\n3. Cell deconvolution with Cell2location\n4. Access image in AnnData object"
  },
  {
    "objectID": "day_2/practical_3/workdir/spatial_course_SOL_CH.html#brainomics-2.0---day-3",
    "href": "day_2/practical_3/workdir/spatial_course_SOL_CH.html#brainomics-2.0---day-3",
    "title": "Computational analysis of spatial transcriptomics data",
    "section": "",
    "text": "1. Spatial data download and format\n2. Spatial imputation with SpaGE and Tangram\n3. Cell deconvolution with Cell2location\n4. Access image in AnnData object"
  },
  {
    "objectID": "presentations.html",
    "href": "presentations.html",
    "title": "Presentations",
    "section": "",
    "text": "All slides used in this course can be found here."
  },
  {
    "objectID": "day_4/practical_6/workdir/practical_6_ccc.html",
    "href": "day_4/practical_6/workdir/practical_6_ccc.html",
    "title": "Practical 6: Cell-Cell Communication",
    "section": "",
    "text": "Author: Francesca Drummer\nIn this notebook we will cover different methods to revocer cell-cell communication (CCC) in spatial transcriptomics.\nTo reduce the environment dependencies we will use the LIANA+ implementation of the methods. Please notice that the original tools might offer more functionalities. For that reason we will always link to the original publication and GitHub repository.\nimport squidpy as sq\nimport scanpy as sc\n\nfrom pathlib import Path\nimport numpy as np\n\nfrom scipy.sparse import issparse, csr_matrix\n\nfrom liana.method import singlecellsignalr, connectome, cellphonedb, natmi, logfc, cellchat, geometric_mean"
  },
  {
    "objectID": "day_4/practical_6/workdir/practical_6_ccc.html#download-data",
    "href": "day_4/practical_6/workdir/practical_6_ccc.html#download-data",
    "title": "Practical 6: Cell-Cell Communication",
    "section": "0. Download data",
    "text": "0. Download data\n\nPATH = \"/home/icb/francesca.drummer/1-Projects/\"\n\n\n# load adata\nadata = sc.read_h5ad(Path(PATH, 'xenium_mouse_ad_annotated_rotated.h5ad'))\nadata\n\nAnnData object with n_obs × n_vars = 350209 × 347\n    obs: 'cell_id', 'transcript_counts', 'control_probe_counts', 'control_codeword_counts', 'unassigned_codeword_counts', 'total_counts', 'cell_area', 'nucleus_area', 'region', 'cell_labels', 'condition', 'time', 'batch_key', 'leiden_res0_25', 'leiden_res0_5', 'leiden_res1', 'cell_types', 'sample'\n    var: 'gene_ids', 'feature_types', 'genome'\n    uns: 'cell_types_colors', 'dea_leiden_res0_25', 'dendrogram_leiden_res0_25', 'leiden', 'leiden_res0_25_colors', 'leiden_res0_5_colors', 'leiden_res1_colors', 'neighbors', 'umap'\n    obsm: 'X_pca', 'X_umap', 'spatial'\n    obsp: 'connectivities', 'distances'\n\n\n\nprint(adata.X[:2,:2])\n\n  (1, 0)    1.0\n\n\n\nadata.layers['counts'] = adata.X\n\n\n# Normalization to the median\nsc.pp.normalize_total(adata)\n\n# Freeman-Tukey square root transform\nassert issparse(adata.X)\nsqrt_X = adata.X.sqrt()\n# Create a new sparse matrix for X + 1\nX_plus_1 = adata.X + csr_matrix(np.ones(adata.X.shape))\n# Calculate the square root of (X + 1)\nsqrt_X_plus_1 = X_plus_1.sqrt()\nadata.layers['median_ft'] = sqrt_X + sqrt_X_plus_1"
  },
  {
    "objectID": "day_4/practical_6/workdir/practical_6_ccc.html#introduction-to-liana",
    "href": "day_4/practical_6/workdir/practical_6_ccc.html#introduction-to-liana",
    "title": "Practical 6: Cell-Cell Communication",
    "section": "0. Introduction to LIANA+",
    "text": "0. Introduction to LIANA+\nLIANA+ is a toolbox in Python for various dissociated, multimodal and spatially informed cell-cell communication tools [Dimitrov et al., 2024].\nFirst we install the package and observe which methods are implemented in LIANA+. Each method relies on different assumptions and returns a different ligand-receptor score. Usually, one score for the strength of the interaction (magnitude) and a score reflecting the specifivity of a interaction to a pair of cell identities.\n\nimport liana as li\n\nli.mt.show_methods()\n\n\n\n\n\n\n\n\nMethod Name\nMagnitude Score\nSpecificity Score\nReference\n\n\n\n\n0\nCellPhoneDB\nlr_means\ncellphone_pvals\nEfremova, M., Vento-Tormo, M., Teichmann, S.A....\n\n\n0\nConnectome\nexpr_prod\nscaled_weight\nRaredon, M.S.B., Yang, J., Garritano, J., Wang...\n\n\n0\nlog2FC\nNone\nlr_logfc\nDimitrov, D., Türei, D., Garrido-Rodriguez, M....\n\n\n0\nNATMI\nexpr_prod\nspec_weight\nHou, R., Denisenko, E., Ong, H.T., Ramilowski,...\n\n\n0\nSingleCellSignalR\nlrscore\nNone\nCabello-Aguilar, S., Alame, M., Kon-Sun-Tack, ...\n\n\n0\nRank_Aggregate\nmagnitude_rank\nspecificity_rank\nDimitrov, D., Türei, D., Garrido-Rodriguez, M....\n\n\n0\nGeometric Mean\nlr_gmeans\ngmean_pvals\nCellPhoneDBv2's permutation approach applied t...\n\n\n0\nscSeqComm\ninter_score\nNone\nBaruzzo, G., Cesaro, G., Di Camillo, B. 2022. ...\n\n\n0\nCellChat\nlr_probs\ncellchat_pvals\nJin, S., Guerrero-Juarez, C.F., Zhang, L., Cha...\n\n\n\n\n\n\n\nMost CCC tools identify LR interaction. For this they rely on a extracting LR pairs from databases. There are diverse databases but LIANA+ has a consensus database that uses LR that are overlapping across databases.\nFirst, we need to ensure that there are LR-pairs present in the data to be detected for communication.\n\nprint(li.resource.show_resources())\nresource_name = \"mouseconsensus\"  # Replace with the desired resource name if needed\nlr_pairs = li.resource.select_resource(resource_name)\nlr_pairs\n\n['baccin2019', 'cellcall', 'cellchatdb', 'cellinker', 'cellphonedb', 'celltalkdb', 'connectomedb2020', 'consensus', 'embrace', 'guide2pharma', 'hpmr', 'icellnet', 'italk', 'kirouac2010', 'lrdb', 'mouseconsensus', 'ramilowski2015']\n\n\n\n\n\n\n\n\n\nligand\nreceptor\n\n\n\n\n31371\nDll1\nNotch1\n\n\n31372\nDll1\nNotch2\n\n\n31373\nDll1\nNotch4\n\n\n31374\nDll1\nNotch3\n\n\n31375\nNrg2\nErbb2_Erbb3\n\n\n...\n...\n...\n\n\n35355\nSerpina1a\nLrp1\n\n\n35356\nSerpina1b\nLrp1\n\n\n35357\nSerpina1c\nLrp1\n\n\n35358\nSerpina1d\nLrp1\n\n\n35359\nSerpina1e\nLrp1\n\n\n\n\n3989 rows × 2 columns\n\n\n\n\ndef lr_pairs_in_adata(adata):\n    genes_in_dataset = set(adata.var_names)  # Replace `adata.var_names` with your dataset's gene names if different\n    \n    # Filter the ligand-receptor pairs for those present in your dataset\n    filtered_lr_pairs = lr_pairs[\n        lr_pairs['ligand'].isin(genes_in_dataset) & lr_pairs['receptor'].isin(genes_in_dataset)\n    ]\n    \n    # Count the number of ligand-receptor pairs present in your dataset\n    num_lr_pairs = len(filtered_lr_pairs)\n    \n    # Display the count\n    print(f\"Number of ligand-receptor pairs present in the dataset: {num_lr_pairs}\")\n\n\nlr_pairs_in_adata(adata)\n\nNumber of ligand-receptor pairs present in the dataset: 16\n\n\nIn the following chapter, we will work with the CellPhoneDB method from LIANA+."
  },
  {
    "objectID": "day_4/practical_6/workdir/practical_6_ccc.html#cellphonedb-non-spatial-ccc",
    "href": "day_4/practical_6/workdir/practical_6_ccc.html#cellphonedb-non-spatial-ccc",
    "title": "Practical 6: Cell-Cell Communication",
    "section": "1. CellPhoneDB: non-spatial CCC",
    "text": "1. CellPhoneDB: non-spatial CCC\nWe will cover two possible appraoches to integrate spatial information into non-spatially aware CCC tools, as shown by li.mt.show_methods().\n\nSelect spatially variable genes as input.\nInput all genes into the\n\n\nSpatially-variable gene selection\nWe use Moran’s I score as a measure of spatial autocorrelation to identify spatially variable genes.\nFor more information see: Chapter 29: Spatially variable genes from single-cell best practices.\n\nsub_adata = adata[(adata.obs['time'] == '5_7') & (adata.obs['condition'] == 'TgCRND8')]\nsub_adata\n\nView of AnnData object with n_obs × n_vars = 58681 × 347\n    obs: 'cell_id', 'transcript_counts', 'control_probe_counts', 'control_codeword_counts', 'unassigned_codeword_counts', 'total_counts', 'cell_area', 'nucleus_area', 'region', 'cell_labels', 'condition', 'time', 'batch_key', 'leiden_res0_25', 'leiden_res0_5', 'leiden_res1', 'cell_types', 'sample'\n    var: 'gene_ids', 'feature_types', 'genome'\n    uns: 'cell_types_colors', 'dea_leiden_res0_25', 'dendrogram_leiden_res0_25', 'leiden', 'leiden_res0_25_colors', 'leiden_res0_5_colors', 'leiden_res1_colors', 'neighbors', 'umap'\n    obsm: 'X_pca', 'X_umap', 'spatial'\n    layers: 'counts', 'median_ft'\n    obsp: 'connectivities', 'distances'\n\n\n\nprint(sub_adata.X[:5,:5])\n\n  (0, 2)    4.50828742980957\n  (1, 0)    2.081632614135742\n  (1, 2)    2.081632614135742\n  (2, 2)    2.6322579383850098\n  (4, 0)    1.2289156913757324\n  (4, 2)    2.457831382751465\n\n\n\nsq.gr.spatial_neighbors(sub_adata, n_neighs=30, coord_type=\"generic\", key_added = 'neighs_based_spatial')\nsq.gr.spatial_autocorr(sub_adata, connectivity_key = \"neighs_based_spatial_connectivities\", mode=\"moran\", n_perms=50, genes=sub_adata.var_names)\n\n/home/icb/francesca.drummer/miniconda3/envs/ccc_liana/lib/python3.9/site-packages/squidpy/gr/_utils.py:194: ImplicitModificationWarning: Setting element `.obsp['neighs_based_spatial_connectivities']` of view, initializing view as actual.\n100%|██████████| 50/50 [00:48&lt;00:00,  1.03/s]\n\n\n\nsub_adata.uns[\"moranI\"].head()\n\n\n\n\n\n\n\n\nI\npval_norm\nvar_norm\npval_z_sim\npval_sim\nvar_sim\npval_norm_fdr_bh\npval_z_sim_fdr_bh\npval_sim_fdr_bh\n\n\n\n\nNwd2\n0.637334\n0.0\n0.000001\n0.0\n0.019608\n0.000014\n0.0\n0.0\n0.019665\n\n\nPpp1r1b\n0.602092\n0.0\n0.000001\n0.0\n0.019608\n0.000014\n0.0\n0.0\n0.019665\n\n\nMbp\n0.592759\n0.0\n0.000001\n0.0\n0.019608\n0.000012\n0.0\n0.0\n0.019665\n\n\nSlc17a7\n0.575611\n0.0\n0.000001\n0.0\n0.019608\n0.000012\n0.0\n0.0\n0.019665\n\n\nNeurod6\n0.573918\n0.0\n0.000001\n0.0\n0.019608\n0.000012\n0.0\n0.0\n0.019665\n\n\n\n\n\n\n\nSubset data to only spatially variable genes and check that there are still LR pairs present.\n\nsub_adata_svg = sub_adata[:, sub_adata.uns[\"moranI\"]['I'] &gt; 0.2]\nsub_adata_svg\n\nView of AnnData object with n_obs × n_vars = 58681 × 115\n    obs: 'cell_id', 'transcript_counts', 'control_probe_counts', 'control_codeword_counts', 'unassigned_codeword_counts', 'total_counts', 'cell_area', 'nucleus_area', 'region', 'cell_labels', 'condition', 'time', 'batch_key', 'leiden_res0_25', 'leiden_res0_5', 'leiden_res1', 'cell_types', 'sample'\n    var: 'gene_ids', 'feature_types', 'genome'\n    uns: 'cell_types_colors', 'dea_leiden_res0_25', 'dendrogram_leiden_res0_25', 'leiden', 'leiden_res0_25_colors', 'leiden_res0_5_colors', 'leiden_res1_colors', 'neighbors', 'umap', 'neighs_based_spatial_neighbors', 'moranI'\n    obsm: 'X_pca', 'X_umap', 'spatial'\n    layers: 'counts', 'median_ft'\n    obsp: 'connectivities', 'distances', 'neighs_based_spatial_connectivities', 'neighs_based_spatial_distances'\n\n\n\nlr_pairs_in_adata(sub_adata_svg)\n\nNumber of ligand-receptor pairs present in the dataset: 5\n\n\n\nsq.pl.spatial_scatter(sub_adata, \n                      color=[\"Ppp1r1b\", \"Neurod6\"],\n                     shape=None)\n\nWARNING: Please specify a valid `library_id` or set it permanently in `adata.uns['spatial']`\n\n\n\n\n\n\n\n\n\n\nCellPhoneDB\n\ncellphonedb(sub_adata_svg,\n            groupby='cell_types',\n            # NOTE by default the resource uses HUMAN gene symbols\n            resource_name='mouseconsensus',\n            expr_prop=0.1,\n            verbose=True, \n            use_raw = False,\n            layer = 'counts',\n            key_added='cpdb_res')\n\nUsing resource `mouseconsensus`.\nUsing the `counts` layer!\n/home/icb/francesca.drummer/miniconda3/envs/ccc_liana/lib/python3.9/site-packages/anndata/_core/anndata.py:522: FutureWarning: The dtype argument is deprecated and will be removed in late 2024.\n39 samples of mat are empty, they will be removed.\n/home/icb/francesca.drummer/miniconda3/envs/ccc_liana/lib/python3.9/site-packages/liana/method/_pipe_utils/_pre.py:153: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n0.98 of entities in the resource are missing from the data.\n\n\nGenerating ligand-receptor stats for 58681 samples and 6 features\n\n\n100%|██████████| 1000/1000 [00:04&lt;00:00, 207.76it/s]\n/home/icb/francesca.drummer/miniconda3/envs/ccc_liana/lib/python3.9/site-packages/liana/method/sc/_Method.py:266: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n\n\n\nsub_adata_svg.uns['cpdb_res'].head()\n\n\n\n\n\n\n\n\nligand\nligand_complex\nligand_means\nligand_props\nreceptor\nreceptor_complex\nreceptor_means\nreceptor_props\nsource\ntarget\nlr_means\ncellphone_pvals\n\n\n\n\n3\nC1qa\nC1qa\n3.718225\n0.903226\nCd93\nCd93\n0.207941\n0.12677\nMicroglia\nAstrocytes\n1.963083\n0.000\n\n\n0\nC1qa\nC1qa\n0.311218\n0.202483\nCd93\nCd93\n0.207941\n0.12677\nAstrocytes\nAstrocytes\n0.259579\n0.000\n\n\n5\nC1qa\nC1qa\n0.194758\n0.112398\nCd93\nCd93\n0.207941\n0.12677\nOligodendrocytes\nAstrocytes\n0.201350\n0.645\n\n\n4\nC1qa\nC1qa\n0.183544\n0.124688\nCd93\nCd93\n0.207941\n0.12677\nOPC\nAstrocytes\n0.195742\n0.657\n\n\n2\nC1qa\nC1qa\n0.139770\n0.135632\nCd93\nCd93\n0.207941\n0.12677\nInhibitory neurons\nAstrocytes\n0.173855\n1.000\n\n\n\n\n\n\n\n\nmy_plot = li.pl.tileplot(adata = sub_adata_svg,\n                         fill='means',\n                         label='props',\n                         label_fun=lambda x: f'{x:.2f}',\n                         top_n=20,\n                         orderby='cellphone_pvals',\n                         orderby_ascending=True,\n                         source_labels=['Astrocytes', 'Excitatory neurons', 'Inhibitory neurons', 'Microglia', 'OPC', 'Oligodendrocytes'],\n                         target_labels=['Astrocytes'],\n                         uns_key='cpdb_res', # NOTE: default is 'liana_res'\n                         source_title='Ligand',\n                         target_title='Receptor',\n                         figure_size=(8, 7)\n                         )\nmy_plot\n\nFontsize 0.00 &lt; 1.0 pt not allowed by FreeType. Setting fontsize = 1 pt\n\n\n\n\n\n\n\n\n\nTODO: Plot genes in space to see whether they are visually close.\nChange the expr_prop in the CellPhoneDB function and try out some other tools like CellChat. How does it effect the results?.\nCompare the results for the healthy control or different time points. Do the CCC across cell types change?.\nWhat could be an alternative post-hoc analysis instead of using spatially variable gene detection to have a spatially informed CCC?"
  },
  {
    "objectID": "day_4/practical_6/workdir/practical_6_ccc.html#misty",
    "href": "day_4/practical_6/workdir/practical_6_ccc.html#misty",
    "title": "Practical 6: Cell-Cell Communication",
    "section": "3. MISTY",
    "text": "3. MISTY\nMISTy is a framework that helps understand how different features, such as genes or cell types interact with each other in space. For this MISTy uses so called views, each describing a different spatial context.\n\n\nimport scanpy as sc\nimport decoupler as dc\nimport plotnine as p9\nimport liana as li\n\n# Import Helper functions needed to create MISTy objects\nfrom liana.method import MistyData, genericMistyData, lrMistyData\n\n#Import predefined single view models\nfrom liana.method.sp import RandomForestModel, LinearModel, RobustLinearModel\n\n\n3.1 Estimate pathway activities\nBefore we run MISTy, let’s estimate pathway activities as a way to make the data a bit more interpretable. We will use decoupler-py with pathways genesets from PROGENy. See this tutorial for details.\n\nprogeny = dc.get_progeny(organism='mouse', top=500)\n\nDownloading annotations for all proteins from the following resources: `['PROGENy']`\n\n\n\ndc.run_mlm(\n    mat=adata,\n    net=progeny,\n    source='source',\n    target='target',\n    weight='weight',\n    verbose=True,\n    use_raw=False,\n)\n\nRunning mlm on mat with 350209 samples and 347 targets for 11 sources.\n\n\n100%|██████████| 36/36 [00:04&lt;00:00,  7.39it/s]\n\n\n\n# extract progeny activities as an AnnData object\nacts_progeny = li.ut.obsm_to_adata(adata, 'mlm_estimate')\nacts_progeny\n\nAnnData object with n_obs × n_vars = 350209 × 11\n    obs: 'cell_id', 'transcript_counts', 'control_probe_counts', 'control_codeword_counts', 'unassigned_codeword_counts', 'total_counts', 'cell_area', 'nucleus_area', 'region', 'cell_labels', 'condition', 'time', 'batch_key', 'leiden_res0_25', 'leiden_res0_5', 'leiden_res1', 'cell_types', 'sample'\n    uns: 'cell_types_colors', 'dea_leiden_res0_25', 'dendrogram_leiden_res0_25', 'leiden', 'leiden_res0_25_colors', 'leiden_res0_5_colors', 'leiden_res1_colors', 'neighbors', 'umap'\n    obsm: 'X_pca', 'X_umap', 'spatial', 'mlm_estimate', 'mlm_pvals'\n    obsp: 'connectivities', 'distances'\n\n\n\nacts_progeny.var_names\n\nIndex(['Androgen', 'Estrogen', 'JAK-STAT', 'MAPK', 'NFkB', 'PI3K', 'TGFb',\n       'TNFa', 'VEGF', 'WNT', 'p53'],\n      dtype='object')\n\n\n\n# Check how the pathway activities look like\nfor library_id in acts_progeny.obs[\"batch_key\"].unique():\n    adata_subset = acts_progeny[acts_progeny.obs[\"batch_key\"] == library_id]\n    print(f'Condition: {np.unique(adata_subset.obs[\"condition\"])[0]} and time: {np.unique(adata_subset.obs[\"time\"])[0]}')\n    sc.pl.spatial(\n        adata_subset, \n        color=['Androgen', 'Estrogen', 'TGFb', 'TNFa', 'VEGF', 'WNT', 'p53'], \n        cmap='RdBu_r', \n        spot_size=10,\n    )\n\nCondition: TgCRND8 and time: 2_5\n\n\n\n\n\n\n\n\n\nCondition: TgCRND8 and time: 5_7\n\n\n\n\n\n\n\n\n\nCondition: TgCRND8 and time: 17_9\n\n\n\n\n\n\n\n\n\nCondition: wildtype and time: 2_5\n\n\n\n\n\n\n\n\n\nCondition: wildtype and time: 5_7\n\n\n\n\n\n\n\n\n\nCondition: wildtype and time: 13_4\n\n\n\n\n\n\n\n\n\n\n\n3.2. Format MISTy object\nMISTy objects are in the MuData (Bredikhin et al., 2021) object with one modality per view.\nThe intra view is the target variable\n\nadata\n\nAnnData object with n_obs × n_vars = 350209 × 347\n    obs: 'cell_id', 'transcript_counts', 'control_probe_counts', 'control_codeword_counts', 'unassigned_codeword_counts', 'total_counts', 'cell_area', 'nucleus_area', 'region', 'cell_labels', 'condition', 'time', 'batch_key', 'leiden_res0_25', 'leiden_res0_5', 'leiden_res1', 'cell_types', 'sample'\n    var: 'gene_ids', 'feature_types', 'genome'\n    uns: 'cell_types_colors', 'dea_leiden_res0_25', 'dendrogram_leiden_res0_25', 'leiden', 'leiden_res0_25_colors', 'leiden_res0_5_colors', 'leiden_res1_colors', 'neighbors', 'umap'\n    obsm: 'X_pca', 'X_umap', 'spatial', 'mlm_estimate', 'mlm_pvals'\n    layers: 'counts', 'median_ft'\n    obsp: 'connectivities', 'distances'\n\n\n\ncell_assignments = adata.obs['cell_types'].astype(str)\n\n\nnp.unique(cell_assignments)\n\narray(['Astrocytes', 'Excitatory neurons', 'Inhibitory neurons',\n       'Microglia', 'OPC', 'Oligodendrocytes', 'nan'], dtype=object)\n\n\n\nimport pandas as pd\nimport anndata as ad\n\none_hot_data = pd.get_dummies(cell_assignments)\n\n\n# Step 3: Create AnnData object\nadata_ct = ad.AnnData(\n    X=one_hot_data.values,  # One-hot encoding matrix\n    obs=pd.DataFrame(index=adata.obs_names),  # Cells as `.obs`\n    var=pd.DataFrame(index=np.unique(cell_assignments)),  # Cell types as `.var`\n)\nadata_ct.obsm['spatial'] = adata.obsm['spatial']\n\n\n# check key cell types\n# sc.pl.spatial(adata_ct,\n#               color=['OPC'],\n#               size=1.3, ncols=2, alpha_img=0,\n#               spot_size = 10\n#               )\n\n\nmisty = genericMistyData(intra=adata_ct, extra=acts_progeny, cutoff=0.05, bandwidth=200, n_neighs=6)\nmisty\n\n/home/icb/francesca.drummer/miniconda3/envs/ccc_liana/lib/python3.9/site-packages/anndata/_core/anndata.py:522: FutureWarning: The dtype argument is deprecated and will be removed in late 2024.\n/home/icb/francesca.drummer/miniconda3/envs/ccc_liana/lib/python3.9/site-packages/anndata/_core/anndata.py:522: FutureWarning: The dtype argument is deprecated and will be removed in late 2024.\n/home/icb/francesca.drummer/miniconda3/envs/ccc_liana/lib/python3.9/site-packages/anndata/_core/anndata.py:522: FutureWarning: The dtype argument is deprecated and will be removed in late 2024.\n/home/icb/francesca.drummer/miniconda3/envs/ccc_liana/lib/python3.9/site-packages/mudata/_core/mudata.py:491: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n/home/icb/francesca.drummer/miniconda3/envs/ccc_liana/lib/python3.9/site-packages/liana/method/sp/_misty/_Misty.py:80: ImplicitModificationWarning: Setting element `.layers['weighted']` of view, initializing view as actual.\n/home/icb/francesca.drummer/miniconda3/envs/ccc_liana/lib/python3.9/site-packages/liana/method/sp/_misty/_Misty.py:80: ImplicitModificationWarning: Setting element `.layers['weighted']` of view, initializing view as actual.\n\n\nMuData object with n_obs × n_vars = 350209 × 27\n  3 modalities\n    intra:  350209 x 5\n      obsm: 'spatial'\n    juxta:  350209 x 11\n      obsm: 'spatial'\n      layers:   'weighted'\n      obsp: 'spatial_connectivities'\n    para:   350209 x 11\n      obsm: 'spatial'\n      layers:   'weighted'\n      obsp: 'spatial_connectivities'"
  },
  {
    "objectID": "day_4/practical_6/workdir/practical_6_ccc.html#learn-relationship-with-misty",
    "href": "day_4/practical_6/workdir/practical_6_ccc.html#learn-relationship-with-misty",
    "title": "Practical 6: Cell-Cell Communication",
    "section": "3.3 Learn relationship with MISTy",
    "text": "3.3 Learn relationship with MISTy\nNow that we have constructed the object, we can learn the relationships across views.\nReationships can be learned by different models (e.i. RandomForrest, LinearModel). The fastest is the Linear model which we will fit here for each target in the intra-view, using the juxta and para views as predictors.\n\nmisty(model=LinearModel, k_cv=10, seed=1337, bypass_intra=True, verbose = True)\n\nNow learning: nan: 100%|██████████| 5/5 [00:44&lt;00:00,  8.89s/it]               \n\n\nBy default the results are saved in the misty object because inplace = True.\nThe misty object does now contain two DataFrames:\n\ntarget_metrics\ninteractions\n\n\nli.pl.target_metrics(misty, stat='gain_R2', return_fig=True)\n\n\n\n\n\n\n\n\n\nli.pl.contributions(misty, return_fig=True)\n\nFontsize 0.00 &lt; 1.0 pt not allowed by FreeType. Setting fontsize = 1 pt\n\n\n\n\n\n\n\n\n\n\n(\n    li.pl.interactions(misty, view='juxta', return_fig=True, figure_size=(7,5)) +\n    p9.scale_fill_gradient2(low = \"blue\", mid = \"white\", high = \"red\", midpoint = 0)\n)\n\nFontsize 0.00 &lt; 1.0 pt not allowed by FreeType. Setting fontsize = 1 pt\n\n\n\n\n\n\n\n\n\nFit a RandomForestModel instead. How does it effect the results and their interpretability?."
  }
]