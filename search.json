[
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "Overview",
    "text": "Overview\nThis course delves into the cutting-edge field of Spatial Omics, focusing on Spatially-Resolved Transcriptomics (SRT) technology which provides unprecedented insights into the spatial organization of gene expression within tissues. The rapid and recent advances in SRT technology are transforming our understanding of biological systems, and this course is designed to equip researchers with the tools to harness the power of SRT, adding significant value to biological knowledge and opening new avenues for scientific discovery.\nParticipants will explore both imaging-based and sequencing-based SRT technologies, learning to navigate the entire workflow of SRT data analysis. The course covers essential topics such as pre-processing techniques for data cleaning, normalization, and quality control, methods for identifying and characterizing spatial domains within tissues, strategies for integrating SRT data with single-cell RNA sequencing data, and statistical approaches to analyze spatial patterns and relationships. Additionally, participants will investigate interactions between cells within their spatial context. By the end of this course, participants will be equipped with the knowledge and skills to construct a complete workflow for SRT data analysis, from raw data to meaningful biological insights. The course combines lectures with practical sessions, ensuring a balanced approach to theory and hands-on experience.\nThe course materials will be on the dedicated GitHub page."
  },
  {
    "objectID": "index.html#audience",
    "href": "index.html#audience",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "Audience",
    "text": "Audience\nThis 3-day course is addressed to PhD students, postdocs, and researchers who are involved (or will be in the near future) in projects including spatially-resolved transcriptomics data, and want to acquire the skills to get started with spatial data analysis."
  },
  {
    "objectID": "index.html#learning-outcomes",
    "href": "index.html#learning-outcomes",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "Learning outcomes",
    "text": "Learning outcomes\nAt the end of the course, the participants will be able to:\n\nIdentify and recall key concepts and terminology related to imaging- and sequencing-based SRT technologies.\nAssess and evaluate quality of SRT data.\nPerform standard SRT data analysis, including data cleaning, normalization, quality control.\nExamine and interpret spatial patterns and relationships within SRT data using statistical and machine learning approaches.\nConstruct a comprehensive workflow for SRT data analysis, from raw data to meaningful biological insights."
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nKnowledge / competencies\nParticipants should be proficient in Python and R, for basic data analysis.\nParticipants should be familiar with NGS technologies, have experience with analyzing (spatial/single-cell) transcriptomics data as well as basic knowledge of machine learning.\nParticipants should also have a basic understanding of working with command line tools on Unix-based systems. You can test your skills with Unix with the quiz here. If you do not feel comfortable with UNIX commands, please take our Unix fundamentals e-learning module.\n\n\nTechnical\nParticipants are required to bring your own laptop.\nWe will be mainly working on an Amazon Web Services (AWS) Elastic Cloud (EC2) server. Our Ubuntu server behaves like a ‘normal’ remote server, and can be approached through a web browser (safari, firefox, chrome etc.). All participants will be granted access to a personal workspace to be used during the course. The web interface will be approached through http (not https!), so make sure you can access http sites. You can validate it here.\nPlease perform these installations PRIOR to the course and contact us if you have any trouble."
  },
  {
    "objectID": "index.html#schedule---cet-time-zone",
    "href": "index.html#schedule---cet-time-zone",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "Schedule - CET time zone",
    "text": "Schedule - CET time zone\nDay 1 (13:00 -17:00)\n\nOverview of technologies\nImaging-based data preprocessing\nSegmentation-free analysis\n\nDay 2 (09:00 -17:00)\n\nSequence-based data preprocessing\nIntegration with scRNA-seq\nMulti-omics spatial data analysis\n\nDay 3 (09:00 -17:00)\n\nGraph representations and Niche reconstruction\nSpatial domain identification/spatial annotation\nSpatial statistics\n\nDay 4 (09:00 -12:30)\n\nCell-cell communication"
  },
  {
    "objectID": "index.html#the-trainers",
    "href": "index.html#the-trainers",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "The trainers",
    "text": "The trainers\nThe course will feature the following lecturers and trainers:\n\nLars Borm (Katholieke Universiteit (KU) Leuven & Vlaams Instituut voor Biotechnologie (VIB), BE)\nHelena Crowell (Centro Nacional de Análisis Genómico (CNAG), ES)\nFrancesca Drummer (Helmholtz Zentrum München, DE)\nGeorge Gavrillidis (Centre for Research and Technology Hellas (CERTH), GR)\nGeert van Geest (SIB Swiss Institute of Bioinformatics, CH)\nNaveed Ishaque (Berlin Institute of Health (BIH), DE)\nAhmed Mahfouz (Leiden University Medical Center (LUMC), NL)\nMark Robinson (University of Zurich (UZH) & SIB, CH)\nYvan Saeys (University of Ghent (UGent) & Vlaams Instituut voor Biotechnologie (VIB), BE)\nRasool Saghaleyni (SciLifeLab, SE)\nAnna Schaar (Helmholtz Zentrum München, DE)\nMarco Varrone (University of Lausanne (UNIL) & SIB, CH)"
  },
  {
    "objectID": "index.html#application",
    "href": "index.html#application",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "Application",
    "text": "Application\nRegistration fees are 150 CHF for academics and 750 CHF for for-profit companies.\nParticipants will be selected based on several criteria. Selection criteria include correct entry requirements, motivation to attend the course as well as gender and ELIXIR nodes balance.\nTo apply to this course and enter the selection process, please fill in this questionnaire.\nApplications will close 01/11/2024. The applications selection will start the week of the 05/11/2024. Accepted applicants will be notified by email by during the week of the 11/11/2024 and they will have until 27/11/2024 to confirm their attendance by paying the fees within 5 days.\nDeadline for free-of-charge cancellation is set to 27/11/2024. Cancellation after this date will not be reimbursed."
  },
  {
    "objectID": "index.html#venue-and-time",
    "href": "index.html#venue-and-time",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "Venue and Time",
    "text": "Venue and Time\nThis course will take place at the University of Lausanne, in the Synathlon building of the campus.\nThe course will start the first day at 13:00. A lunch will be provided before the start of the course as well as at the end of the course on the last day.\nAll participants are invited to the social dinner, organized on 21 January 2024.\nPrecise information will be provided to the participants in due time."
  },
  {
    "objectID": "index.html#additional-information",
    "href": "index.html#additional-information",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "Additional information",
    "text": "Additional information\nThis is an international course hosted by the SIB Swiss Institute of Bioinformatics (ELIXIR-CH) in collaboration with the ELIXIR Single-Cell Omics community, and trainers’ own institutions and affiliations to ELIXIR nodes (KU Leuven, VIB, CNAG, Helmholtz Zentrum München, CERTH, SIB, BIH, LUMC, UZH, UGent, SciLifeLab, UNIL).\nCourse organizers:\n\nAhmed Mahfouz, Leiden University Medical Center (LUMC), ELIXIR - Netherlands\nDiana Marek, SIB Training group, ELIXIR - Switzerland\nPatricia Palagi, SIB Training group, ELIXIR - Switzerland\nEija Korpelainen, CSC, ELIXIR - Finland\n\nThis course is partially funded by an ELIXIR Staff Exchange Programme.\nWe will recommend 0.75 ECTS credits for this course (given a passed assessment).\nYou are welcome to register to the SIB courses mailing list to be informed of all future courses and workshops, as well as all important deadlines using the form here.\nPlease note that participation in SIB courses is subject to our general conditions.\nCourse organizers and trainers abide by the ELIXIR Code of Conduct. Participants are also required to abide by the same code."
  },
  {
    "objectID": "day_1/practical_1/imaging_based_data_analysis.html",
    "href": "day_1/practical_1/imaging_based_data_analysis.html",
    "title": "Practical 1: Imaging-Based Data Analysis with Xenium (Mouse Brain, Cancer)",
    "section": "",
    "text": "Author: Rasool Saghaleyni\n\n##\nimport os\nfrom pathlib import Path\nimport subprocess\n\nurls = [\n    \"https://cf.10xgenomics.com/samples/xenium/2.0.0/Xenium_V1_humanLung_Cancer_FFPE/Xenium_V1_humanLung_Cancer_FFPE_he_image.ome.tif\",\n    \"https://cf.10xgenomics.com/samples/xenium/2.0.0/Xenium_V1_humanLung_Cancer_FFPE/Xenium_V1_humanLung_Cancer_FFPE_he_imagealignment.csv\",\n    \"https://cf.10xgenomics.com/samples/xenium/2.0.0/Xenium_V1_humanLung_Cancer_FFPE/Xenium_V1_humanLung_Cancer_FFPE_outs.zip\",\n]\n\n##\n# download the data\nfor url in urls:\n    filename = Path(url).name\n    os.makedirs(\"data\", exist_ok=True)\n    command = f\"curl -o {'data/' + filename} {url}\"\n    subprocess.run(command, shell=True, check=True)\n\n# ##\n# unzip the data\nsubprocess.run(\n    f\"unzip -o data/Xenium_V1_humanLung_Cancer_FFPE_outs.zip -d data/xenium_2.0.0_io\",\n    shell=True,\n    check=True,\n)\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 1135M  100 1135M    0     0  35.6M      0  0:00:31  0:00:31 --:--:-- 37.8M\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100   126  100   126    0     0    817      0 --:--:-- --:--:-- --:--:--   818\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 7617M  100 7617M    0     0  36.3M      0  0:03:29  0:03:29 --:--:-- 35.4M\n\n\nArchive:  data/Xenium_V1_humanLung_Cancer_FFPE_outs.zip\n extracting: data/xenium_2.0.0_io/analysis.zarr.zip  \n  inflating: data/xenium_2.0.0_io/cell_boundaries.csv.gz  \n  inflating: data/xenium_2.0.0_io/cell_boundaries.parquet  \n  inflating: data/xenium_2.0.0_io/cell_feature_matrix.h5  \n extracting: data/xenium_2.0.0_io/cell_feature_matrix.zarr.zip  \n  inflating: data/xenium_2.0.0_io/cells.csv.gz  \n  inflating: data/xenium_2.0.0_io/cells.parquet  \n extracting: data/xenium_2.0.0_io/cells.zarr.zip  \n  inflating: data/xenium_2.0.0_io/experiment.xenium  \n  inflating: data/xenium_2.0.0_io/gene_panel.json  \n  inflating: data/xenium_2.0.0_io/metrics_summary.csv  \n  inflating: data/xenium_2.0.0_io/nucleus_boundaries.csv.gz  \n  inflating: data/xenium_2.0.0_io/nucleus_boundaries.parquet  \n  inflating: data/xenium_2.0.0_io/transcripts.csv.gz  \n  inflating: data/xenium_2.0.0_io/transcripts.parquet  \n extracting: data/xenium_2.0.0_io/transcripts.zarr.zip  \n  inflating: data/xenium_2.0.0_io/analysis_summary.html  \n  inflating: data/xenium_2.0.0_io/morphology.ome.tif  \n  inflating: data/xenium_2.0.0_io/analysis.tar.gz  \n  inflating: data/xenium_2.0.0_io/aux_outputs.tar.gz  \n  inflating: data/xenium_2.0.0_io/cell_feature_matrix.tar.gz  \n   creating: data/xenium_2.0.0_io/morphology_focus/\n  inflating: data/xenium_2.0.0_io/morphology_focus/morphology_focus_0000.ome.tif  \n  inflating: data/xenium_2.0.0_io/morphology_focus/morphology_focus_0001.ome.tif  \n  inflating: data/xenium_2.0.0_io/morphology_focus/morphology_focus_0002.ome.tif  \n  inflating: data/xenium_2.0.0_io/morphology_focus/morphology_focus_0003.ome.tif  \n\n\nCompletedProcess(args='unzip -o data/Xenium_V1_humanLung_Cancer_FFPE_outs.zip -d data/xenium_2.0.0_io', returncode=0)\n\n\n\nfrom spatialdata_io import xenium\nimport spatialdata as sd\nfrom pathlib import Path\nimport shutil\n\npath = Path().resolve() / \"data/xenium_2.0.0_io\"\nassert path.exists(), f\"Path {path} does not exist.\"\npath_read = path \npath_write = Path().resolve() / \"data.zarr\"\nprint(\"Parsing the data... \", end=\"\")\nsdata = xenium(\n    path=str(path_read),\n    n_jobs=8,\n    cell_boundaries=True,\n    nucleus_boundaries=True,\n    morphology_focus=True,\n    cells_as_circles=True,\n)\nif path_write.exists():\n    shutil.rmtree(path_write)\nsdata.write(path_write)\n# Reading and verifying the output\nsdata = sd.SpatialData.read(str(path_write))\nprint(sdata)\n\nReading data from: /Users/rasools/Library/CloudStorage/OneDrive-Chalmers/Documents/github/ELIXIR-SCO-spatial-transcriptomics/day_1/practical_1/data/xenium_2.0.0_io\nWriting data to: /Users/rasools/Library/CloudStorage/OneDrive-Chalmers/Documents/github/ELIXIR-SCO-spatial-transcriptomics/day_1/practical_1/data.zarr\nParsing the data... INFO     reading                                                                                                   \n         /Users/rasools/Library/CloudStorage/OneDrive-Chalmers/Documents/github/ELIXIR-SCO-spatial-transcriptomics/\n         day_1/practical_1/data/xenium_2.0.0_io/cell_feature_matrix.h5                                             \n\n\n/var/folders/8l/yj6nz8296zd7wwj0xy6pw3880000gn/T/ipykernel_2082/1897399642.py:22: DeprecationWarning: `cell_boundaries` is being deprecated as an argument to `xenium.xenium` in SpatialData version 0.1, switch to `cells_boundaries` instead.\n  sdata = xenium(\n\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[8], line 22\n     20 # Parsing the data\n     21 print(\"Parsing the data... \", end=\"\")\n---&gt; 22 sdata = xenium(\n     23     path=str(path_read),\n     24     n_jobs=8,\n     25     cell_boundaries=True,\n     26     nucleus_boundaries=True,\n     27     morphology_focus=True,\n     28     cells_as_circles=True,\n     29 )\n     30 print(\"done\")\n     32 # Writing the data to the output path\n\nFile ~/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/spatialdata_io/_utils.py:46, in deprecation_alias.&lt;locals&gt;.deprecation_decorator.&lt;locals&gt;.wrapper(*args, **kwargs)\n     44 class_name = f.__qualname__\n     45 rename_kwargs(f.__name__, kwargs, aliases, class_name)\n---&gt; 46 return f(*args, **kwargs)\n\nFile ~/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/spatialdata_io/readers/xenium.py:334, in xenium(path, cells_boundaries, nucleus_boundaries, cells_as_circles, cells_labels, nucleus_labels, transcripts, morphology_mip, morphology_focus, aligned_images, cells_table, n_jobs, imread_kwargs, image_models_kwargs, labels_models_kwargs)\n    330 assert (\n    331     \"c_coords\" not in image_models_kwargs\n    332 ), \"The channel names for the morphology focus images are handled internally\"\n    333 image_models_kwargs[\"c_coords\"] = list(channel_names.values())\n--&gt; 334 images[\"morphology_focus\"] = _get_images(\n    335     morphology_focus_dir,\n    336     XeniumKeys.MORPHOLOGY_FOCUS_CHANNEL_IMAGE.format(0),\n    337     imread_kwargs,\n    338     image_models_kwargs,\n    339 )\n    340 del image_models_kwargs[\"c_coords\"]\n    341 logger.removeFilter(IgnoreSpecificMessage())\n\nFile ~/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/spatialdata_io/readers/xenium.py:564, in _get_images(path, file, imread_kwargs, image_models_kwargs)\n    558 if \"c_coords\" in image_models_kwargs and \"dummy\" in image_models_kwargs[\"c_coords\"]:\n    559     # Napari currently interprets 4 channel images as RGB; a series of PRs to fix this is almost ready but they will\n    560     # not be merged soon.\n    561     # Here, since the new data from the xenium analyzer version 2.0.0 gives 4-channel images that are not RGBA,\n    562     # let's add a dummy channel as a temporary workaround.\n    563     image = da.concatenate([image, da.zeros_like(image[0:1])], axis=0)\n--&gt; 564 return Image2DModel.parse(\n    565     image, transformations={\"global\": Identity()}, dims=(\"c\", \"y\", \"x\"), rgb=None, **image_models_kwargs\n    566 )\n\nFile ~/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/spatialdata/models/models.py:189, in RasterSchema.parse(cls, data, dims, transformations, scale_factors, method, chunks, **kwargs)\n    183         raise ValueError(\n    184             f\"Cannot transpose arrays to match `dims`: {dims}.\",\n    185             \"Try to reshape `data` or `dims`.\",\n    186         ) from e\n    188 # finally convert to spatial image\n--&gt; 189 data = to_spatial_image(array_like=data, dims=cls.dims.dims, **kwargs)\n    190 # parse transformations\n    191 _parse_transformations(data, transformations)\n\nTypeError: to_spatial_image() got an unexpected keyword argument 'rgb'\n\n\n\n\nxenium_path = \"./data/xenium_2.0.0.zarr\"\n\n\n%%time\nimport spatialdata as sd\n\nsdata = sd.read_zarr(xenium_path)\nsdata\n\nCPU times: user 1.81 ms, sys: 3.87 ms, total: 5.67 ms\nWall time: 13.5 ms\n\n\nSpatialData object, with associated Zarr store: /Users/rasools/Library/CloudStorage/OneDrive-Chalmers/Documents/github/ELIXIR-SCO-spatial-transcriptomics/day_1/practical_1/data/Xenium_V1_FFPE_TgCRND8_17_9_months_outs\nwith coordinate systems:\n\nwith the following elements in the Zarr store but not in the SpatialData object:\n    ▸ gene (Density)\n    ▸ 5 (Cell_groups)\n    ▸ 4 (Grids)\n    ▸ 3 (Cell_groups)\n    ▸ 9 (Cell_groups)\n    ▸ 5 (Grids)\n    ▸ 8 (Cell_groups)\n    ▸ 1 (Cell_groups)\n    ▸ 2 (Grids)\n    ▸ 0 (Cell_groups)\n    ▸ 7 (Cell_groups)\n    ▸ 0 (Grids)\n    ▸ 4 (Cell_groups)\n    ▸ 3 (Grids)\n    ▸ 1 (Grids)\n    ▸ 2 (Cell_groups)\n    ▸ 6 (Cell_groups)\n\n\n\nimport scanpy as sc\n\nsc.pp.normalize_total(sdata.tables[\"table\"])\nsc.pp.log1p(sdata.tables[\"table\"])\nsc.pp.highly_variable_genes(sdata.tables[\"table\"])\nsdata.tables[\"table\"].var.sort_values(\"means\")\n\n\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\nCell In[38], line 3\n      1 import scanpy as sc\n----&gt; 3 sc.pp.normalize_total(sdata.tables[\"table\"])\n      4 sc.pp.log1p(sdata.tables[\"table\"])\n      5 sc.pp.highly_variable_genes(sdata.tables[\"table\"])\n\nFile ~/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/collections/__init__.py:1058, in UserDict.__getitem__(self, key)\n   1056 if hasattr(self.__class__, \"__missing__\"):\n   1057     return self.__class__.__missing__(self, key)\n-&gt; 1058 raise KeyError(key)\n\nKeyError: 'table'\n\n\n\n\ndocker build --no-cache --platform=linux/amd64 -t docker.io/rasoolsnbis/estc_2025:p1 -f \"day_1/practical_1/Dockerfile\" \"day_1/practical_1\""
  },
  {
    "objectID": "day_1/practical_1/3D Nucleus Segmentation with Cellpose.html",
    "href": "day_1/practical_1/3D Nucleus Segmentation with Cellpose.html",
    "title": "ELIXIR-SCO-spatial-transcriptomics",
    "section": "",
    "text": "Introduction Provide an overview of the objective: Segmenting nuclei in a 3D image stack. Briefly describe Cellpose and why it’s used for segmentation. Link to any relevant resources, including the 10x Genomics guide.\nImport Libraries python Copy code\n\n\nimport tifffile\nimport matplotlib.pyplot as plt\nfrom cellpose import models, io\nimport numpy as np\nfrom skimage.transform import rescale\n\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11&gt;=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy&lt;2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in &lt;module&gt;\n    app.launch_new_instance()\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n    app.start()\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n    self.io_loop.start()\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n    self._run_once()\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n    handle._run()\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n    await self.process_one()\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n    await dispatch(*args)\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n    await result\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n    await super().execute_request(stream, ident, parent)\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n    reply_content = await reply_content\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n    res = shell.run_cell(\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n    result = self._run_cell(\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n    result = runner(coro)\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/var/folders/8l/yj6nz8296zd7wwj0xy6pw3880000gn/T/ipykernel_94482/3112621286.py\", line 3, in &lt;module&gt;\n    from cellpose import models, io\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/cellpose/__init__.py\", line 1, in &lt;module&gt;\n    from cellpose.version import version, version_str\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/cellpose/version.py\", line 8, in &lt;module&gt;\n    import torch\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in &lt;module&gt;\n    from .functional import *  # noqa: F403\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/torch/functional.py\", line 9, in &lt;module&gt;\n    import torch.nn.functional as F\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in &lt;module&gt;\n    from .modules import *  # noqa: F403\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in &lt;module&gt;\n    from .transformer import TransformerEncoder, TransformerDecoder, \\\n  File \"/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in &lt;module&gt;\n    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n/Users/rasools/miniconda3/envs/cellpose_env/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n\n\n\nLoad and Explore the 3D Image Data\nLoad the .tif image stack and visualize a few slices to understand the structure of the data.\n\n# Load the 3D image\nimage_path = 'data/xenium_2.0.0_io/morphology.ome.tif'\nimage_stack = tifffile.imread(image_path)\n\n# Display the original dimensions of the image stack\nprint(\"Original image stack dimensions (slices, height, width):\", image_stack.shape)\n\n# Display a few slices to explore the data\nfig, axes = plt.subplots(1, 3, figsize=(12, 4))\nfor i, slice_idx in enumerate([0, len(image_stack)//2, -1]):\n    axes[i].imshow(image_stack[slice_idx], cmap='gray')\n    axes[i].set_title(f'Slice {slice_idx}')\n    axes[i].axis('off')\nplt.show()\n\n\n\nSelect a Smaller Volume of Interest\nChoose a subset of slices and a specific region within each slice.\n\n# Define parameters for volume of interest\nstart_slice = 10         # Starting slice index\nend_slice = 20           # Ending slice index\n\n# Calculate the center coordinates and define a region around the center\nheight, width = image_stack.shape[1], image_stack.shape[2]\ncenter_y, center_x = height // 2, width // 2\ncrop_size = 500  # Size of the square region to extract (adjust as needed)\n\n# Define the cropping boundaries around the center\ny_start = center_y - crop_size // 2\ny_end = center_y + crop_size // 2\nx_start = center_x - crop_size // 2\nx_end = center_x + crop_size // 2\n\n# Select the smaller volume of interest from the center of each slice\nvolume_of_interest = image_stack[start_slice:end_slice, y_start:y_end, x_start:x_end]\nprint(\"Selected volume dimensions (slices, height, width):\", volume_of_interest.shape)\n\n# Display a few slices of the selected volume\nfig, axes = plt.subplots(1, 3, figsize=(12, 4))\nfor i, slice_idx in enumerate([0, len(volume_of_interest)//2, -1]):\n    axes[i].imshow(volume_of_interest[slice_idx], cmap='gray')\n    axes[i].set_title(f\"Slice {slice_idx + start_slice} (Center Region)\")\n    axes[i].axis('off')\nplt.show()\n\n\nSelected volume dimensions (slices, height, width): (1, 5000, 5000)\n\n\n\n\n\n\n\n\n\n\n\nSet Up the Cellpose Model for Segmentation\nLoad the Cellpose model for nucleus segmentation and define parameters.\n\n# Load Cellpose model for nuclei segmentation\nmodel = models.Cellpose(gpu=False, model_type='nuclei')  # Use gpu=False if no GPU available\n\n# Define segmentation parameters\ndiameter = 10  # Adjust based on the size of the nuclei\nchannels = [0, 0]  # Grayscale images typically use [0, 0]\n\n\n\nPerform Segmentation on the Selected Volume\nRun Cellpose segmentation on the selected volume of interest."
  },
  {
    "objectID": "day_1/practical_1/practical_1_2.html",
    "href": "day_1/practical_1/practical_1_2.html",
    "title": "Loading packages",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\nimport seaborn as sns\nimport scanpy as sc\nimport squidpy as sq\nimport scipy.sparse as sp\nfrom scipy.stats import gaussian_kde\nfrom scipy.signal import find_peaks, argrelextrema\nfrom scipy.sparse import issparse, csr_matrix\nfrom diptest import diptest\nimport statsmodels.api as sm\nfrom shapely.geometry import Point, Polygon, MultiPoint\nfrom scipy.spatial import ConvexHull\nimport sys\nsys.path.append('/Users/rasools/Library/CloudStorage/OneDrive-Chalmers/Documents/github/ELIXIR-SCO-spatial-transcriptomics/day_1/practical_1/custom')\nimport tenx_method_nb_helper_functions as hf"
  },
  {
    "objectID": "day_1/practical_1/practical_1_2.html#loading-data-and-primary-inspections",
    "href": "day_1/practical_1/practical_1_2.html#loading-data-and-primary-inspections",
    "title": "Loading packages",
    "section": "Loading data and primary inspections",
    "text": "Loading data and primary inspections\nMaking adata object considering the transcripts that should be used for the analysis. Running analysis on the transcripts that are only in the nucleus.\n\nsample_path = \"/Users/rasools/Library/CloudStorage/OneDrive-Chalmers/Documents/github/ELIXIR-SCO-spatial-transcriptomics/day_1/practical_1/data/xenium_2.0.0_io\"\ntranscripts_csv_path = os.path.join(sample_path, \"transcripts.csv\")\ntranscripts_df = pd.read_csv(transcripts_csv_path)\nnucleus_boundaries_gz_path = os.path.join(sample_path, \"nucleus_boundaries.csv.gz\")\nnucleus_df = pd.read_csv(nucleus_boundaries_gz_path, compression='gzip')\n\n\nMaking the adata object\n\nadata = hf.create_adata(sample_path, nucleus_genes_only = False)\nadata\n\nAnnData object with n_obs × n_vars = 162254 × 377\n    obs: 'cell_id', 'x_centroid', 'y_centroid', 'transcript_counts', 'control_probe_counts', 'control_codeword_counts', 'unassigned_codeword_counts', 'deprecated_codeword_counts', 'total_counts', 'cell_area', 'nucleus_area'\n    var: 'gene_ids', 'feature_types', 'genome'\n    obsm: 'spatial'\n\n\nThe AnnData object, adata, contains a structured dataset with cells as observations (n_obs = 162254) and genes as variables (n_vars = 377). Here’s a breakdown of the main components within adata:\nobs (Observations): This table contains metadata about each cell, where each row corresponds to a cell, and each column holds information about a specific attribute:\n\ncell_id: Unique identifier for each cell.\nx_centroid and y_centroid: Coordinates of each cell’s center in the spatial layout, indicating where each cell is located within the tissue.\ntranscript_counts: Total transcript counts for each cell, showing the overall gene expression level.\ncontrol_probe_counts and control_codeword_counts: Counts related to control probes and codewords, which are often used for quality control in spatial transcriptomics.\nunassigned_codeword_counts and deprecated_codeword_counts: Counts of unassigned or deprecated codewords, indicating low-confidence or outdated identifiers.\ntotal_counts: Total counts across all measured attributes, representing the cell’s total signal.\ncell_area and nucleus_area: Physical measurements of the cell and its nucleus area, in pixels or micrometers.\n\nvar (Variables): This table contains metadata about each gene, where each row is a gene and each column is an attribute:\n\ngene_ids: Unique identifiers for each gene, often in Ensembl or another standardized format.\nfeature_types: Type of feature associated with each gene, such as “gene” or “transcript.”\ngenome: Information about the genome source of each gene, like “human” or “mouse.”\n\nobsm (Multi-dimensional Observations): This slot contains multi-dimensional data related to cells. Here, spatial stores spatial coordinates for each cell, allowing visualization and spatial analysis of cells in their tissue context.\n\nadata.obs['total_counts'] = adata.X.sum(axis=1)\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['total_counts'], kde=True, bins=50)\nplt.xlabel(\"Total Transcript Counts per Cell\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Total Transcript Counts per Cell\")\nplt.show()\n\n\n\n\n\n\n\n\nWe calculate the total transcript counts for each cell by summing gene expression values across all genes and the number of genes detected in each cell. The resulting distributions gives us an overview of the data quality and cellular diversity in terms of RNA content.\nThese provide a measure of each cell’s transcriptional activity or RNA content. High total counts typically indicate cells with higher transcriptional activity, while very low total counts may suggest low-quality cells or empty spots with minimal RNA. Examining this distribution helps us assess data quality and identify potential outliers:\n\nCells with Very Low Counts: These may represent low-quality cells or background noise, which could be filtered out in subsequent steps to improve analysis accuracy.\nCells with Very High Counts: High total counts may indicate cell types with naturally high transcriptional activity or potential doublets (two cells counted as one).\n\nThis plot provides a quick check of the dataset’s quality and helps inform any initial filtering steps. A typical goal is to ensure the data has a reasonable distribution of RNA counts per cell, without excessive noise or artifacts that might skew downstream analysis.\n\nadata.obs['n_genes'] = (adata.X &gt; 0).sum(axis=1)\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['n_genes'], kde=True, bins=50)\nplt.xlabel(\"Number of Genes Detected per Cell\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Genes Detected per Cell\")\nplt.show()\n\n\n\n\n\n\n\n\nNow lets find genes with the highest expression across the whole dataset. We calculate the mean expression level of each gene across all cells and identify the top 10 most highly expressed genes, then plot them to understand which genes dominate the transcriptional landscape. This helps us quickly identify genes with the highest abundance, which are often either essential housekeeping genes or specific markers that define particular cell types. Examining the top expressed genes serves both technical and biological purposes: it allows us to check for any potential technical artifacts (e.g., genes with unusually high background expression) and offers biological insight by highlighting key genes likely involved in core cellular functions or distinguishing cell types.\n\n#calculate mean expression for each gene\nmean_expression = adata.X.mean(axis=0).A1\ntop_genes_idx = mean_expression.argsort()[::-1][:10]\ntop_genes = adata.var_names[top_genes_idx]\ntop_expression = mean_expression[top_genes_idx]\nplt.figure(figsize=(10, 5))\nsns.barplot(x=top_genes, y=top_expression)\nplt.xlabel(\"Genes\")\nplt.ylabel(\"Mean Expression\")\nplt.title(\"Top 10 Most Expressed Genes\")\nplt.xticks(rotation=45)\nplt.show()\n\n\n\n\n\n\n\n\nWe can also look into the distributions of cell and nucleus areas to assess segmentation quality and examine cell size diversity across the dataset. These distributions provide an overview of the range of cell and nucleus sizes, helping to identify segmentation artifacts or inconsistencies, such as unusually small areas (which may indicate partial cells or segmentation errors) or large areas (potentially indicating doublets or merged cells).\n\n#distribution of cell and nucleus areas\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['cell_area'], kde=True, bins=50)\nplt.xlabel(\"Cell Area\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Cell Areas\")\nplt.show()\n\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['nucleus_area'], kde=True, bins=50)\nplt.xlabel(\"Nucleus Area\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Nucleus Areas\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCell Area vs Nucleus Area\n\nplt.figure(figsize=(8, 6))\nplt.scatter(adata.obs['cell_area'], adata.obs['nucleus_area'], alpha=0.5)\nplt.xlabel(\"Cell Area\")\nplt.ylabel(\"Nucleus Area\")\nplt.title(\"Cell Area vs Nucleus Area\")\nplt.show()\n\n\n\n\n\n\n\n\nCalculate cell-to-nucleus area ratio and plot it. This ratio provides a measure of the relative size of the nucleus compared to the whole cell, which can be informative for understanding cell morphology and the distribution of nuclear material within cells. A high ratio may indicate cells with large nuclei relative to their overall size, which could be relevant for cell type classification or biological interpretation. Examining this ratio helps identify potential outliers or unusual cell morphologies that may require further investigation or filtering.\n\nadata.obs['area_ratio'] = adata.obs['nucleus_area'] / adata.obs['cell_area']\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['area_ratio'], kde=True, bins=50)\nplt.xlabel(\"Nucleus-to-Cell Area Ratio\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Nucleus-to-Cell Area Ratios\")\nplt.show()\n\n\n\n\n\n\n\n\nScatter plot of Cell Area vs Total Counts\n\nplt.figure(figsize=(8, 6))\nplt.scatter(adata.obs['cell_area'], adata.obs['total_counts'], alpha=0.5)\nplt.xlabel(\"Cell Area\")\nplt.ylabel(\"Total Transcript Counts\")\nplt.title(\"Cell Area vs Total Transcript Counts\")\nplt.show()\n\n\n\n\n\n\n\n\nSpatial plot of cell and nucleus areas.\n\n# Spatial plot of cell area\nsc.pl.spatial(adata, color='cell_area', spot_size=10, title=\"Spatial Distribution of Cell Area\")\n\n# Spatial plot of nucleus area (if available)\nsc.pl.spatial(adata, color='nucleus_area', spot_size=10, title=\"Spatial Distribution of Nucleus Area\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLooking to spatial distibution of one of the genes. For example the gene “MALL”\n\nsc.pl.spatial(adata, color=['MALL'], spot_size=10, title=\"MALL Gene Expression\")\n\n\n\n\n\n\n\n\n\n# Filter cells with nucleus area &lt; 5\ninitial_cells_count = adata.n_obs\nadata = adata[adata.obs['nucleus_area'] &gt;= 5].copy()\nfiltered_cells_count = adata.n_obs\nprint(f\"Filtered out {initial_cells_count - filtered_cells_count} cells with nucleus_area &lt; 5. Remaining cells: {filtered_cells_count}\")\n\nFiltered out 6241 cells with nucleus_area &lt; 5. Remaining cells: 156013\n\n\nPlot distribution of total transcript counts per cell and distribution of Nucleus area after filtering\n\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['total_counts'], kde=True, bins=50)\nplt.xlabel(\"Total Transcript Counts per Cell\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Total Transcript Counts per Cell After Filtering\")\nplt.show()\n\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['nucleus_area'], kde=True, bins=50)\nplt.xlabel(\"Nucleus Area\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Nucleus Area After Filtering\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwe can also look into the control probe counts and their spatial distribution to assess background noise and technical quality in the dataset. First, we plot the distribution of control probe counts across cells to understand how frequently control probes are detected. This distribution provides insights into potential technical noise or background signals, as higher-than-expected control counts may suggest artifacts or contamination. Next, we create a spatial plot of control probe counts, which allows us to see if any regions in the tissue exhibit unexpectedly high control counts, possibly indicating localized technical issues.\n\n# Plot distribution of control probe counts\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['control_probe_counts'], kde=True, bins=50)\nplt.xlabel(\"Control Probe Counts\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Control Probe Counts\")\nplt.show()\n\n# Spatial plot of control probe counts\nsc.pl.spatial(adata, color='control_probe_counts', spot_size=10, title=\"Spatial Distribution of Control Probe Counts\")"
  },
  {
    "objectID": "day_1/practical_1/practical_1_2.html#filtering-normalizing-and-cleaning-data",
    "href": "day_1/practical_1/practical_1_2.html#filtering-normalizing-and-cleaning-data",
    "title": "Loading packages",
    "section": "Filtering, Normalizing and Cleaning data",
    "text": "Filtering, Normalizing and Cleaning data\nFilter out the cells that have nuclei smaller than 7 microns.\nWhat do you think could be a good cutoff for filtering out lowly expressed genes and cells with low transcript count? Lets removes low-quality cells and genes from the dataset, which helps reduce noise and computational load in downstream analyses. This filtering step ensures that the dataset is focused on cells and genes with a minimum level of expression, which are more likely to be biologically relevant.\n\n# Cell and gene filtering\ninitial_cells_count = adata.n_obs\ninitial_genes_count = adata.n_vars\n\nsc.pp.filter_cells(adata, min_counts=10, inplace=True)\nsc.pp.filter_genes(adata, min_cells=5, inplace=True)\n\nfiltered_cells_count = adata.n_obs\nfiltered_genes_count = adata.n_vars\nprint(f\"Filtered {initial_cells_count - filtered_cells_count} (out of intial {initial_cells_count} cells)\")\nprint(f\"Filtered {initial_genes_count - filtered_genes_count} (out of intial {initial_genes_count} genes)\")\n\nFiltered 7137 (out of intial 156013 cells)\nFiltered 0 (out of intial 377 genes)\n\n\n\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['total_counts'], kde=True, bins=50)\nplt.xlabel(\"Total Transcript Counts per Cell\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Total Transcript Counts per Cell After Filtering\")\nplt.show()\n\nplt.figure(figsize=(8, 5))\nsns.histplot(adata.obs['nucleus_area'], kde=True, bins=50)\nplt.xlabel(\"Nucleus Area\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Distribution of Nucleus Area After Filtering\")\nplt.show()"
  },
  {
    "objectID": "day_1/practical_1/practical_1_2.html#normaliation-and-scaling",
    "href": "day_1/practical_1/practical_1_2.html#normaliation-and-scaling",
    "title": "Loading packages",
    "section": "Normaliation and scaling",
    "text": "Normaliation and scaling\nNormalization adjusts for cell-specific technical differences, and log transformation makes the data easier to analyze by reducing the effects of extreme values. This normalization and transformation make the dataset more appropriate for dimensionality reduction, clustering, and other analyses.\n\nadata.raw = adata.copy()\nsc.pp.normalize_total(adata, target_sum=1e4)\nsc.pp.log1p(adata)\n\nComparing the effect of normalization\n\noriginal_counts = adata.raw.X.sum(axis=1)\nnormalized_counts = adata.X.sum(axis=1)\n#plt distributions\nplt.figure(figsize=(10, 5))\nsns.histplot(original_counts.A1, color=\"blue\", label=\"Before Normalization\", kde=True) \nsns.histplot(normalized_counts.A1, color=\"orange\", label=\"After Normalization\", kde=True)\nplt.xlabel(\"Total Transcript Counts per Cell\")\nplt.ylabel(\"Number of Cells\")\nplt.title(\"Effect of Normalization on Total Transcript Counts per Cell\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nHow the normalization and scaling of the data affects the distribution of gene expression values in the dataset. We can have a look at the distribution of gene expression values before and after normalization and scaling for MALL gene.\n\ngene_name = \"MALL\"\nif gene_name in adata.var_names:\n    # Extract MALL expression values before normalization\n    original_mall_expression = adata.raw[:, gene_name].X.toarray().flatten()  # Use `.toarray()` for sparse matrices\n\n    # Extract MALL expression values after normalization\n    normalized_mall_expression = adata[:, gene_name].X.toarray().flatten()  # Use `.toarray()` for sparse matrices\n\n    # Plot distributions\n    plt.figure(figsize=(10, 5))\n    sns.histplot(original_mall_expression, color=\"blue\", label=\"Before Normalization\", kde=True, bins=50)\n    sns.histplot(normalized_mall_expression, color=\"orange\", label=\"After Normalization\", kde=True, bins=50)\n    plt.xlabel(f\"{gene_name} Expression\")\n    plt.ylabel(\"Number of Cells\")\n    plt.title(f\"Effect of Normalization and Scaling on {gene_name} Expression\")\n    plt.legend()\n    plt.show()"
  },
  {
    "objectID": "day_1/practical_1/practical_1_2.html#dimensionality-reduction",
    "href": "day_1/practical_1/practical_1_2.html#dimensionality-reduction",
    "title": "Loading packages",
    "section": "Dimensionality reduction",
    "text": "Dimensionality reduction\nWe use dimensionality reduction, clustering, and visualization techniques to analyze the structure of our dataset, group similar cells, and visualize their relationships. First, we apply Principal Component Analysis (PCA) to reduce the high-dimensional gene expression data into a smaller set of principal components, retaining the main patterns of variation while reducing noise. Then, we create a neighbors graph, which identifies connections between cells based on their similarity in the reduced PCA space, capturing local relationships essential for clustering. Using the Leiden clustering algorithm, we group cells into clusters based on these connections, allowing us to identify groups of similar cells that may represent distinct cell types or states. We then apply UMAP (Uniform Manifold Approximation and Projection), a technique that reduces the data to two dimensions for visualization, preserving both local and global structures in the data. Finally, we generate a UMAP plot with cells colored by their assigned clusters, providing an overview of the dataset’s structure and making it easy to spot distinct cell populations or clusters. This visualization gives us an interpretable view of the relationships within our data, helping us understand its organization before further analysis.\n\nsc.pp.pca(adata)\nsc.pp.neighbors(adata)\nsc.tl.leiden(adata)\nsc.tl.umap(adata)\nsc.pl.umap(adata, color='leiden', title='UMAP before filtering suspected false positives')\n\n/Users/rasools/miniconda3/envs/imaging_based_data_analysis_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n/var/folders/8l/yj6nz8296zd7wwj0xy6pw3880000gn/T/ipykernel_60411/2991834093.py:4: FutureWarning: In the future, the default backend for leiden will be igraph instead of leidenalg.\n\n To achieve the future defaults please pass: flavor=\"igraph\" and n_iterations=2.  directed must also be False to work with igraph's implementation.\n  sc.tl.leiden(adata)"
  },
  {
    "objectID": "day_1/practical_1/practical_1_2.html#systematic-filtering-of-suspected-false-positives",
    "href": "day_1/practical_1/practical_1_2.html#systematic-filtering-of-suspected-false-positives",
    "title": "Loading packages",
    "section": "Systematic Filtering of Suspected False Positives",
    "text": "Systematic Filtering of Suspected False Positives\nIn Xenium data, some genes may appear to be “expressed” across large areas or in many cells due to background noise or technical artifacts, rather than true biological expression. To address this, we are implementing a gene-specific filtering approach to identify and remove suspected false positives systematically. By filtering out these spurious signals, we can focus our analysis on more reliable gene expression patterns, improving the quality of downstream analyses.\n\n1- Calculate the Mean Expression per Gene per Cluster\nIn the first step, we calculate the mean expression of each gene within each cluster. Clustering organizes cells into groups that likely share biological characteristics, and taking the average expression of each gene within clusters provides a baseline for typical expression levels. This allows us to identify clusters where a gene has unusually low expression, which might indicate noise rather than true expression.\n\nmean_expression = adata.to_df().groupby(adata.obs['leiden']).mean()\n\n/var/folders/8l/yj6nz8296zd7wwj0xy6pw3880000gn/T/ipykernel_60411/2069805196.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  mean_expression = adata.to_df().groupby(adata.obs['leiden']).mean()\n\n\n\n\n2- Determine the Maximum Expression Level of Each Gene Across Clusters\nThen, we find the maximum expression level for each gene across all clusters. This maximum value serves as a reference point for each gene’s typical expression level in the dataset. The highest expression level of each gene is assumed to represent meaningful expression, while lower values may be more likely to represent noise or background.\n\nmax_expression_levels = mean_expression.max(axis=0)\n\n\n\n3- Calculate Spurious Expression Threshold for Each Gene\nWe define a threshold, here set at 5%, which will be used to identify potential false positives. This threshold means that if a gene’s expression in a given cluster is below 5% of its highest expression level across all clusters, we will consider it to be a likely false positive. This step allows us to systematically identify clusters where the gene’s expression is likely due to background noise rather than true biological signal. Then, we calculate a spurious expression threshold for each gene, which is 5% of its maximum expression level. This threshold provides a cut-off below which we consider expression values to be suspected false positives. By applying this threshold, we can filter out clusters where a gene’s expression level is unlikely to be biologically meaningful.\n\nthreshold = 0.05\nspurious_expression_threshold = max_expression_levels * threshold\n\n\n\n4- Identify Suspected False Positives for Each Cluster and Gene\nNext we creat a dictionary, suspected_false_positives, to store suspected false positive genes for each cluster. For each cluster, it checks each gene’s mean expression level within that cluster. If the gene’s mean expression is below the spurious expression threshold (5% of its maximum expression), the gene is flagged as a suspected false positive in that cluster.\n\nsuspected_false_positives = {}\nfor cluster in mean_expression.index:\n    suspected_genes = []\n    for gene in adata.var_names:\n        if mean_expression.at[cluster, gene] &lt; spurious_expression_threshold[gene]:\n            suspected_genes.append(gene)\n    suspected_false_positives[cluster] = suspected_genes\n\nNow we can see a quick summary of the suspected false positives across clusters\n\n#Showing first 10 genes for brevity\nfor cluster, genes in suspected_false_positives.items():\n    print(f\"Cluster {cluster} has {len(genes)} suspected false positive genes: {genes[:10]}\")\n\ncluster_counts = {cluster: len(genes) for cluster, genes in suspected_false_positives.items()}\nclusters = list(cluster_counts.keys())\ncounts = list(cluster_counts.values())\nplt.figure(figsize=(12, 6))\nsns.barplot(x=clusters, y=counts, palette='viridis')\nplt.title('Count of Suspected False Positive Genes per Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Count of Suspected False Positive Genes')\nplt.xticks(rotation=45)\nplt.show()\n\nCluster 0 has 22 suspected false positive genes: ['ADGRL4', 'C1orf194', 'C20orf85', 'C6orf118', 'C7', 'CCDC39', 'CCL19', 'CD27', 'CD79A', 'CLEC14A']\nCluster 1 has 67 suspected false positive genes: ['ACKR1', 'ADGRL4', 'ANGPT2', 'ASPN', 'BTNL9', 'C1orf194', 'C20orf85', 'C6orf118', 'C7', 'CCDC39']\nCluster 2 has 27 suspected false positive genes: ['ACKR1', 'ADGRL4', 'ANGPT2', 'C1orf194', 'C20orf85', 'C6orf118', 'C7', 'CCDC39', 'CCL19', 'CD2']\nCluster 3 has 33 suspected false positive genes: ['ACE2', 'AGR3', 'AQP9', 'C1orf194', 'C20orf85', 'C6orf118', 'CCDC39', 'CCDC78', 'CFAP53', 'COL17A1']\nCluster 4 has 56 suspected false positive genes: ['ACE2', 'AGR3', 'ARFGEF3', 'BASP1', 'C1orf194', 'C20orf85', 'C6orf118', 'CAPN8', 'CCDC39', 'CCDC78']\nCluster 5 has 31 suspected false positive genes: ['BTNL9', 'C1orf194', 'C20orf85', 'C6orf118', 'CA4', 'CCDC39', 'CCDC78', 'CFAP53', 'CLEC14A', 'CLIC6']\nCluster 6 has 39 suspected false positive genes: ['ACE2', 'AGR3', 'ANPEP', 'C1orf194', 'C20orf85', 'C6orf118', 'CCDC39', 'CCDC78', 'CD27', 'CD79A']\nCluster 7 has 64 suspected false positive genes: ['ACE2', 'AGR3', 'ARFGEF3', 'C1orf194', 'C20orf85', 'C6orf118', 'CA4', 'CAPN8', 'CCDC39', 'CCDC78']\nCluster 8 has 61 suspected false positive genes: ['ACE2', 'AGR3', 'AQP9', 'BTNL9', 'C1orf194', 'C20orf85', 'C6orf118', 'CA4', 'CAPN8', 'CCDC39']\nCluster 9 has 30 suspected false positive genes: ['ADGRL4', 'ANGPT2', 'ASPN', 'C1orf194', 'C20orf85', 'C6orf118', 'C7', 'CA4', 'CCDC39', 'CCL19']\nCluster 10 has 49 suspected false positive genes: ['ACKR1', 'ADGRL4', 'ASPN', 'C7', 'CD163', 'CD27', 'CD68', 'CD70', 'CD79A', 'CLEC14A']\nCluster 11 has 71 suspected false positive genes: ['ACE2', 'ACKR1', 'ADH1C', 'AGR3', 'ANPEP', 'AQP9', 'ARFGEF3', 'BMX', 'BTNL9', 'C1orf194']\n\n\n/var/folders/8l/yj6nz8296zd7wwj0xy6pw3880000gn/T/ipykernel_60411/3901056732.py:11: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x=clusters, y=counts, palette='viridis')\n\n\n\n\n\n\n\n\n\n\nall_suspected_fp_genes = set()\nfor genes in suspected_false_positives.values():\n    all_suspected_fp_genes.update(genes)\nall_suspected_fp_genes_list = sorted(all_suspected_fp_genes)\nclusters = list(suspected_false_positives.keys())\nheatmap_data = pd.DataFrame(0, index=list(all_suspected_fp_genes_list), columns=clusters)\n\nfor cluster, genes in suspected_false_positives.items():\n    heatmap_data.loc[genes, cluster] = 1\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(heatmap_data, cmap=\"viridis\", cbar_kws={'label': 'Presence of Suspected False Positives'})\nplt.title(\"Heatmap of Suspected False Positive Genes Across Clusters\")\nplt.xlabel(\"Cluster\")\nplt.ylabel(\"Gene\")\nplt.show()\n\n\n\n\n\n\n\n\n\nbackground_noise_counts = {gene: 0 for gene in adata.var_names}\nfor gene in adata.var_names:\n    for cluster in mean_expression.index:\n        if mean_expression.at[cluster, gene] &lt; spurious_expression_threshold[gene]:\n            background_noise_counts[gene] += 1\n\n# Find the gene with the highest background noise\nhighest_noise_gene = max(background_noise_counts, key=background_noise_counts.get)\nhighest_noise_count = background_noise_counts[highest_noise_gene]\n\nprint(f\"The gene with the highest background noise is '{highest_noise_gene}', detected below the threshold in {highest_noise_count} clusters.\")\n\nThe gene with the highest background noise is 'C1orf194', detected below the threshold in 11 clusters.\n\n\n\n\n5- Adjusting gene expression values across the dataset (background noise reduction)\nNow, we aim to reduce background noise by adjusting gene expression levels across all cells based on suspected false positives. Specifically, if a gene has low expression (below the spurious expression threshold) in any cluster, we take the highest of those low expression levels and subtract it from all cells for that gene. This method removes unspecific, potentially spurious expression, which can help improve cluster separation and make biologically relevant expression patterns clearer.\n\nadata_app_1 = adata.copy()\n\nmax_filtered_expression = {}\nadata_df = adata_app_1.to_df()\n\nfor gene in adata_app_1.var_names:\n    below_threshold_values = []\n    for cluster in mean_expression.index:\n        expression_level = mean_expression.at[cluster, gene]\n        if expression_level &lt; spurious_expression_threshold[gene]:\n            below_threshold_values.append(expression_level)\n            \n    if below_threshold_values:\n        max_filtered_expression[gene] = max(below_threshold_values)\n    else:\n        max_filtered_expression[gene] = 0  \n        #no values below threshold = no subtraction needed\n\n#subtract the maximum filtered expression value from all cells for each gene\nfor gene in adata_app_1.var_names:\n    max_expr = max_filtered_expression[gene]\n    if max_expr &gt; 0:\n        adata_df[gene] -= max_expr\n        #ensure that no negative values are introduced\n        adata_df[gene] = np.maximum(adata_df[gene], 0)\n\n#update AnnData object with adjusted gene expressions\nadata_app_1 = sc.AnnData(X=adata_df.values, obs=adata_app_1.obs, var=adata_app_1.var, obsm=adata_app_1.obsm)\nsc.pp.pca(adata_app_1)\nsc.pp.neighbors(adata_app_1)\nsc.tl.leiden(adata_app_1)\nsc.tl.umap(adata_app_1)\nsc.pl.umap(adata_app_1, color='leiden', title='UMAP after filtering suspected false positives')\n\n\n\n\n\n\n\n\n\ngene_of_interest = \"C1orf194\"\nsc.pl.spatial(adata, color=[gene_of_interest], spot_size=10, title=f'{gene_of_interest} Expression Before Adjustment')\nsc.pl.spatial(adata_app_1, color=[gene_of_interest], spot_size=10, title=f'{gene_of_interest} Expression After Adjustment')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\noriginal_expression = adata.to_df()[gene_of_interest]\nadjusted_expression = adata_app_1.to_df()[gene_of_interest]\n\nplt.figure(figsize=(10, 5))\nsns.kdeplot(original_expression, label=\"Original\", color=\"blue\")\nsns.kdeplot(adjusted_expression, label=\"Adjusted\", color=\"orange\")\nplt.xlabel(f'Expression of {gene_of_interest}')\nplt.ylabel('Density')\nplt.title(f'Expression Distribution of {gene_of_interest} Before and After Adjustment')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Calculate mean expression per gene\nmean_expression_original = adata.to_df().mean(axis=0)\nmean_expression_adjusted = adata_app_1.to_df().mean(axis=0)\n\n# Plot a scatter plot comparing mean expression before and after adjustment\nplt.figure(figsize=(8, 8))\nplt.scatter(mean_expression_original, mean_expression_adjusted, alpha=0.5)\nplt.plot([0, max(mean_expression_original)], [0, max(mean_expression_adjusted)], color=\"red\", linestyle=\"--\")\nplt.xlabel('Mean Expression (Original)')\nplt.ylabel('Mean Expression (Adjusted)')\nplt.title('Mean Gene Expression Before and After Adjustment')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSecond approach\nCheck the histogram of the gene expression for every gene and if it has a multimodal expression distribution to set based on that histogram a thereshold below which we consider the expression to be background. And we could remove from all cells the expression below that therahold. First making helper functions performing dip test and plotting the histogram of the gene expression. I’ve used dip test to check if the distribution is multimodal or not. If the p-value is smaller than 0.05 we consider the distribution to be multimodal. A question here would be that should we only consider non-zero expression values for this analysis or should we consider all expression values? If consider all values we might get a multimodal distribution all for genes, however if we only consider non-zero values we might miss some genes that are suspected to have multimodal distribution. What do you think?\n\ngenes_to_analyze = adata.var_names[0:len(adata.var_names)]\nthresholds = {}\nfor gene in genes_to_analyze:\n    threshold = hf.analyze_gene_expressions(adata, gene, bandwidth=0.05, plot=False, filter_zeros=False)\n    if threshold is not None:\n        thresholds[gene] = threshold\n\nSort genes by threshold values in descending order and display the top genes with the highest thresholds\n\nsorted_thresholds = sorted(thresholds.items(), key=lambda x: x[1], reverse=True)\nprint(\"Top genes with the highest thresholds:\")\nfor gene, threshold_value in sorted_thresholds[:10]:\n    print(f\"{gene}: {threshold_value}\")\n\n\ngene_of_interest = \"CYP2B6\"\nhf.analyze_gene_expressions(adata, gene_of_interest, bandwidth=0.05, plot=True, filter_zeros=False)\n\nNow we can do the subtraction of genes with a background expression from their original values in each cell.\n\n# 1. Reverse the log1p transformation on adata.X\nadata_app_2 = adata.copy()\nif sp.issparse(adata_app_2.X):\n    adata_app_2.X = sp.csr_matrix(np.expm1(adata_app_2.X.toarray()))\nelse:\n    adata_app_2.X = np.expm1(adata_app_2.X)\n\n# 2. Reverse the log1p transformation on thresholds\nthresholds = {gene: np.expm1(thresh) for gene, thresh in thresholds.items()}\n\n# 3. Perform the subtraction and ensure non-negative values\nfor gene, threshold in thresholds.items():\n    if gene in adata_app_2.var_names:  # Ensure the gene exists in adata\n        gene_index = adata_app_2.var_names.get_loc(gene)\n        \n        # Extract the column as a dense numpy array\n        gene_data = adata_app_2[:, gene].X\n        if sp.issparse(gene_data):\n            gene_data = gene_data.toarray().flatten()\n\n        # Perform the subtraction and ensure non-negative values\n        updated_gene_data = np.maximum(gene_data - threshold, 0)\n\n        # Update the AnnData object\n        if sp.issparse(adata_app_2.X):\n            adata_app_2[:, gene_index].X = sp.csr_matrix(updated_gene_data[:, np.newaxis])\n        else:\n            adata_app_2[:, gene_index].X = updated_gene_data[:, np.newaxis]\n\n# 4. Reapply the log1p transformation\nsc.pp.log1p(adata_app_2)\n\n\ngene_of_interest = \"CYP2B6\"\n\nsc.pl.spatial(adata, color=[gene_of_interest], spot_size=10, title=f'{gene_of_interest} Expression Before Adjustment')\nsc.pl.spatial(adata_app_2, color=[gene_of_interest], spot_size=10, title=f'{gene_of_interest} Expression After Adjustment')\n\n\noriginal_expression = adata.to_df()[gene_of_interest]\nadjusted_expression = adata_app_2.to_df()[gene_of_interest]\n\n# Plot expression distributions\nplt.figure(figsize=(10, 5))\nsns.kdeplot(original_expression, label=\"Original\", color=\"blue\")\nsns.kdeplot(adjusted_expression, label=\"Adjusted\", color=\"orange\")\nplt.xlabel(f'Expression of {gene_of_interest}')\nplt.ylabel('Density')\nplt.title(f'Expression Distribution of {gene_of_interest} Before and After Adjustment')\nplt.legend()\nplt.show()\n\n\n# Principal component analysis for dimension reduction\nsc.pp.pca(adata_app_2)\nsc.pp.neighbors(adata_app_2)\nsc.tl.leiden(adata_app_2)\nsc.tl.umap(adata_app_2)\nsc.pl.umap(adata_app_2, color='leiden', title='UMAP after filtering suspected false positives (approach 2)')"
  },
  {
    "objectID": "day_2/practical_3/workdir/practical_3.html",
    "href": "day_2/practical_3/workdir/practical_3.html",
    "title": "Computational analysis of spatial transcriptomics data",
    "section": "",
    "text": "1. Spatial data download and format\n2. Spatial imputation with SpaGE\n3. Spatial clusering with BANKSY\n4. Cell-cell communication with LIANA+"
  },
  {
    "objectID": "day_2/practical_3/workdir/practical_3.html#brainomics-2.0---day-3",
    "href": "day_2/practical_3/workdir/practical_3.html#brainomics-2.0---day-3",
    "title": "Computational analysis of spatial transcriptomics data",
    "section": "",
    "text": "1. Spatial data download and format\n2. Spatial imputation with SpaGE\n3. Spatial clusering with BANKSY\n4. Cell-cell communication with LIANA+"
  }
]