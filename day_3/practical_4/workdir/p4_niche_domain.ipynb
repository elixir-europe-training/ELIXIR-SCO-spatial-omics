{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Niche reconstruction and spatial domain detection\n",
    "\n",
    "Authors: Francesca Drummer, Marco Varrone\n",
    "\n",
    "In this notebook we will cover:\n",
    "\n",
    "1. Graph construction and analysis of spatial transcriptomics data using Squidpy\n",
    "2. CellCharter\n",
    "3. BANKSY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis and ML imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# single-cell imports\n",
    "import squidpy as sq\n",
    "import scanpy as sc\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Dataset\n",
    "\n",
    "We will use the Xenium AD dataset from the previous notebooks here.\n",
    "\n",
    "As a reminder the dataset consists of 6 coronal mouse brain slices from 2 different conditions (wildtype - ctrl vs TgCRND8 - AD) across 3 timepoints. In this practical, we additionally have information about cell types available in  `adata.obs['cell_types']`. Please note that these annotation are not perfect. For example, there are quite some cells that could not be assigned to a cell type (NaN or \"unkown\"). These annotations have been made with on leiden clustering and marker genes reported in [this](https://pages.10xgenomics.com/rs/446-PBO-704/images/10x_LIT000210_App-Note_Xenium-In-Situ_Letter_Digital.pdf) document. \n",
    "\n",
    "In this practical we aim to understand the differences of the mouse brain between the two conditions and across the timepoints using niches and spatial domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/data/spatial_workshop/day3/practical_4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load adata\n",
    "adata = sc.read_h5ad(Path(PATH, 'xenium_mouse_ad_annotated_rotated.h5ad'))\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame from 'split', 'fov', and 'condition'\n",
    "df = adata.obs[['condition', 'time', 'batch_key']]\n",
    "value_counts = pd.DataFrame(df.values, columns=df.columns).value_counts()\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"Unknown\" as a category\n",
    "adata.obs[\"cell_types\"] = adata.obs[\"cell_types\"].cat.add_categories(\"Unknown\")\n",
    "\n",
    "# Fill NaN values with \"Unknown\"\n",
    "adata.obs[\"cell_types\"] = adata.obs[\"cell_types\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cell neighborhood detection via graph construction\n",
    "\n",
    "Spatial transcriptomics data can be represented as graphs with cells as nodes and edges as relations. Depending on the technology (imaging-based or sequencing-based) different assumptions can be made for the graph structure. \n",
    "Here we will explore graph construction and cell neighborhood analysis using the squidpy `sq.gr.spatial_neighbors` module on imaging-based data. \n",
    "\n",
    "*Information for graph reconstruciton for sequencing-based data can be found [here](https://squidpy.readthedocs.io/en/stable/notebooks/examples/graph/compute_spatial_neighbors.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For image-based technologies we construct a graph with `coord_type=generic`, meaning that the nodes / cells will preserve their spatial location and will not be re-arranged in a spatial grid. For generic graph approaches we can choose to set a fixed radius `radius` or number of neighbors to connect to (`n_neighs`).\n",
    "\n",
    "Below we try both graph construction methods and give them a different `key` to add to the `adata` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'cell_types_colors' in adata.uns:\n",
    "    del adata.uns['cell_types_colors']\n",
    "    \n",
    "sq.gr.spatial_neighbors(adata, n_neighs=10, coord_type=\"generic\", key_added = 'neighs_based_spatial')\n",
    "sq.pl.spatial_scatter(\n",
    "    adata,\n",
    "    shape=None,\n",
    "    library_key = 'sample',\n",
    "    color=[\"cell_types\"],\n",
    "    connectivity_key=\"neighs_based_spatial_connectivities\",\n",
    "    title=adata.obs['sample'].cat.categories,\n",
    "    ncols=3,\n",
    "    size = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.spatial_neighbors(adata, radius=0.3, coord_type=\"generic\", key_added = 'radius_based_spatial')\n",
    "sq.pl.spatial_scatter(\n",
    "    adata,\n",
    "    shape=None,\n",
    "    library_key = 'sample', \n",
    "    color=\"cell_types\",\n",
    "    connectivity_key=\"radius_based_spatial_connectivities\",\n",
    "    title=adata.obs['sample'].cat.categories,\n",
    "    ncols=3,\n",
    "    size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First differences across the graphs can be observed by visual inspection, e.i. the cells that are further away from the clear brain structures are connected in the clostest neighbor approach but unconnected in the radius-based approach. Some other differences are harder to observe like dependencies in the more dense connected regions. For this Squidpy provides a number of statistics to better the differences between the connectivities of cells.\n",
    "\n",
    "Using the cell type information we can formulate some hypothesis from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">**Task 1:** Try out some analysis from Squidpy to identify distinctions between the graphs e.i. using the [centrality score](https://squidpy.readthedocs.io/en/stable/notebooks/examples/graph/compute_centrality_scores.html) and [neighborhood enrichment](https://squidpy.readthedocs.io/en/stable/notebooks/examples/graph/compute_nhood_enrichment.html). </span>\n",
    "\n",
    "Example questions to answer could be: What are the average number of connections per cell type? Which cell types tend to cluster together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.nhood_enrichment(adata, cluster_key=\"cell_types\", library_key = 'condition', connectivity_key = \"neighs_based_spatial\")\n",
    "sq.pl.nhood_enrichment(\n",
    "    adata, cluster_key=\"cell_types\", method=\"average\", figsize=(5, 5)\n",
    ")  # `method` compute the hierarchic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.nhood_enrichment(adata, cluster_key=\"cell_types\", library_key = 'condition', connectivity_key = \"radius_based_spatial\")\n",
    "sq.pl.nhood_enrichment(\n",
    "    adata, cluster_key=\"cell_types\", method=\"average\", figsize=(5, 5)\n",
    ")  # `method` compute the hierarchic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.centrality_scores(adata, cluster_key = \"cell_types\", connectivity_key = \"neighs_based_spatial\")\n",
    "sq.pl.centrality_scores(adata, cluster_key = \"cell_types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.centrality_scores(adata, cluster_key = \"cell_types\", connectivity_key = \"radius_based_spatial\")\n",
    "sq.pl.centrality_scores(adata, cluster_key = \"cell_types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">**Task 2:** How do the scores change when increasing or decreasing the number of neighbors `n_neighs = 50` or `radius=200`? </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spatial Domain detection with CellCharter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scvi\n",
    "import scanpy as sc\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import squidpy as sq\n",
    "import numpy as np\n",
    "import cellcharter as cc\n",
    "import os\n",
    "import logging\n",
    "logger = logging.getLogger('pytorch_lightning.utilities.rank_zero')\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scvi.settings.seed = 12345\n",
    "scvi.settings.num_threads = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be cells with very low counts. We will filter them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_cells(adata, min_counts=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Dimensionality reduction\n",
    "\n",
    "First, we need to run the dimensionality reduction. We will use [scVI](https://docs.scvi-tools.org/en/latest/api/reference/scvi.model.SCVI.html) for this.\n",
    "\n",
    "Make sure that `adata.X` contains count data, as it is required by scVI. <br>\n",
    "In some tutorials you will see that the count data is stored in an AnnData layer called `counts`. Here we will use the `X` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scvi.model.SCVI.setup_anndata(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_MODEL = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the parameters of the neural network. Here we use 1 layer and an embedding size of 10.<br>\n",
    "These are very common parameters, but you can play with them to see how they affect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_MODEL:\n",
    "    model = scvi.model.SCVI.load(os.path.join(PATH, 'scvi_model'), adata=adata)\n",
    "else:\n",
    "    model = scvi.model.SCVI(\n",
    "        adata,\n",
    "        n_layers=1,\n",
    "        n_latent=10,\n",
    "        use_layer_norm=\"both\",\n",
    "        use_batch_norm=\"none\",\n",
    "    )\n",
    "    model.train(early_stopping=True, enable_progress_bar=True, max_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that the training has converged, we can plot the training history.<br>\n",
    "Here we is important to focus on the (validation) reconstruction loss. This shows how well the model is able to reconstruct the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(\n",
    "    model.history[f\"reconstruction_loss_train\"],\n",
    "    label=\"train\",\n",
    "    color=\"darkgreen\",\n",
    "    linewidth=1.25\n",
    ")\n",
    "plt.plot(\n",
    "    model.history[f\"reconstruction_loss_validation\"],\n",
    "    label=\"validation\",\n",
    "    color=\"firebrick\",\n",
    "    linewidth=1.25\n",
    "    )\n",
    "plt.legend()\n",
    "plt.title(\"reconstruction_loss\")  \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the latent representation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm['X_scVI'] = model.get_latent_representation(adata).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Neighborhood aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, all the analyses have been done ignoring the spatial information. <br>\n",
    "Now we will use the spatial information to perform the clustering.\n",
    "\n",
    "First, we need to create a network where cells are connected if they are close to each other using the Delaunay triangulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.spatial_neighbors(adata, library_key='sample', coord_type='generic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.pl.spatial_scatter(\n",
    "    adata, \n",
    "    shape=None, \n",
    "    library_key='sample',\n",
    "    library_id=adata.obs['sample'].cat.categories[0],\n",
    "    color=\"sample\", \n",
    "    size=1, \n",
    "    figsize=(10,10),\n",
    "    connectivity_key=\"spatial_connectivities\",\n",
    "    ncols=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the Delaunay triangulation generates very long edges for a few cells. <br>\n",
    "The most appropriate approach would be to estimate the most biologically relevant distance between cells and use it to remove the edges longer than that distance.\n",
    "\n",
    "A quick alternative solution is that, since those long edges are sort of outlines, the measure the 99th percentile of the edge lengths and remove the edges longer than that distance. <br>\n",
    "This process will lead to some isolated cells, but that's not a problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.spatial_neighbors(adata, library_key='sample', coord_type='generic', percentile=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.pl.spatial_scatter(\n",
    "    adata, \n",
    "    shape=None, \n",
    "    library_key='sample',\n",
    "    library_id=adata.obs['sample'].cat.categories[0],\n",
    "    color=\"sample\", \n",
    "    size=1, \n",
    "    figsize=(10,10),\n",
    "    connectivity_key=\"spatial_connectivities\",\n",
    "    ncols=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct the neighborhood aggregated representation by combining every cell's features with the ones of first 3 layers of neighbors.<br>\n",
    "We will use the scVI latent representation as features and the new features will be stored in `adata.obsm['X_cellcharter']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.gr.aggregate_neighbors(adata, n_layers=3, use_rep='X_scVI', out_key='X_cellcharter_temp', sample_key='sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">**Task 3:** Given that `X_scVI` contains 10 features, how many features does `X_cellcharter` contain?<br>\n",
    "Guess the answer and then write the code to check it.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's cluster the cells and find their spatial domains.<br>\n",
    "We will use 18 clusters, we will see later why this is a good choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = cc.tl.Cluster(n_clusters=18, random_state=12345)\n",
    "gmm.fit(adata, use_rep='X_cellcharter_temp')\n",
    "adata.obs['spatial_domain_temp'] = gmm.predict(adata, use_rep='X_cellcharter_temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot domains and cell types back to back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'spatial_domain_temp_colors' in adata.uns:\n",
    "    del adata.uns['spatial_domain_temp_colors']\n",
    "\n",
    "sq.pl.spatial_scatter(\n",
    "    adata, \n",
    "    shape=None, \n",
    "    library_key='sample', \n",
    "    color=[\"spatial_domain_temp\", \"cell_types\"], \n",
    "    size=1,\n",
    "    figsize=(10,10),\n",
    "    title=np.repeat(adata.obs['sample'].cat.categories, 2),\n",
    "    ncols=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Downstream analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last section was to show how CellCharter can be used to obtain spatial domains.\n",
    "\n",
    "However, to have an easier discussion and interpretation of the results, we want everyone to have the same results.\n",
    "\n",
    "Therefore, we will use the spatial domains computed in advance using the `ClusterAutoK` model that also runs the stability analysis to find the optimal number of clusters.\n",
    "The model has been computed using 3 layers of neighbors (it took 25 minutes on a GPU).\n",
    "\n",
    "We have to:\n",
    "1. load the features from the pretrained scvi model to generate the same features used by fitted `ClusterAutoK`\n",
    "2. aggregate the neighborhood features using the same number of layers as used by `ClusterAutoK` (3 layers of neighbors)\n",
    "3. load the `ClusterAutoK` model\n",
    "4. plot the stability curve\n",
    "5. look for the peak(s) to identify the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = scvi.model.SCVI.load(os.path.join(PATH, 'scvi_model'), adata=adata)\n",
    "adata.obsm['X_scVI'] = model.get_latent_representation(adata).astype(np.float32)\n",
    "cc.gr.aggregate_neighbors(adata, n_layers=3, use_rep='X_scVI', out_key='X_cellcharter', sample_key='sample')\n",
    "\n",
    "autok = cc.tl.ClusterAutoK.load(Path(PATH, 'autok_l3'))\n",
    "cc.pl.autok_stability(autok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't see a clear single peak, but we can see that the highest stability is for 18 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['spatial_domain_18'] = autok.predict(adata, use_rep='X_cellcharter', k=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'spatial_domain_18_colors' in adata.uns:\n",
    "    del adata.uns['spatial_domain_18_colors']\n",
    "\n",
    "sq.pl.spatial_scatter(\n",
    "    adata, \n",
    "    shape=None, \n",
    "    library_key='sample', \n",
    "    color=[\"spatial_domain_18\", \"cell_types\"], \n",
    "    size=1,\n",
    "    figsize=(10,10),\n",
    "    title=np.repeat(adata.obs['sample'].cat.categories, 2),\n",
    "    ncols=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the spatial domains, we can look at the cell type enrichment in each domain.\n",
    "\n",
    "This function measures the likelihood of a cell type being found in a domain compared to random chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.gr.enrichment(\n",
    "    adata,\n",
    "    group_key='spatial_domain_18',\n",
    "    label_key='cell_types',\n",
    ")\n",
    "cc.pl.enrichment(\n",
    "    adata,\n",
    "    group_key='spatial_domain_18',\n",
    "    label_key='cell_types',\n",
    "    dot_scale=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">**Task 4:**\n",
    "The [Allen Brain Atlas](https://atlas.brain-map.org/atlas?atlas=1&plate=100960076#atlas=1&plate=100960520&resolution=6.98&x=5512.001546223959&y=3967.997233072917&zoom=-2) provides images and annotation of mouse brain samples at multiple depths.<br><br>\n",
    "Choose one of the six samples, go to the atlas and try to find the image that better matches the regions shown by CellCharter.</span>\n",
    "\n",
    "<span style=\"color: red;\">1. Which of the 132 images is the closest one?</span><br>\n",
    "<span style=\"color: red;\">2. After identifying the closest image, try to match the domains obtained with the annotated regions in the atlas.</span><br>\n",
    "<span style=\"color: red;\">3. Do you find anatomical differences between the two conditions? are there differences in spatial domain compositions? Are there unique domains in one of the two conditions (Alzheimer vs wildtype)?</span><br>\n",
    "<span style=\"color: red;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Focus, in particular on comparing samples from mice of the same age.</span><br>\n",
    "<span style=\"color: red;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- If you find difference between the two samples, what do you think is the cause?</span><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">**Task 5:** Now, save the spatial domains corresponding to 9 and 23 clusters into the `adata.obs` column `spatial_domain_9` and `spatial_domain_23`.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.pl.spatial_scatter(\n",
    "    adata, \n",
    "    shape=None, \n",
    "    library_key='sample', \n",
    "    color=[\"spatial_domain_9\", \"spatial_domain_18\", \"spatial_domain_23\"], \n",
    "    size=1,\n",
    "    figsize=(10,10),\n",
    "    title=np.repeat(adata.obs['sample'].cat.categories, 3),\n",
    "    ncols=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three levels of clustering form a sort of hierarchical structure.<br>\n",
    "9-cluster domains tend to separate into subdomains in the 18 clusters, and so on.\n",
    "\n",
    "<span style=\"color: red;\">**Task 6:** Go back to the Allen Brain Atlas and look if some of the hierarchical structure is reflected in the atlas.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape characterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to look at the shapes of the domains we obtained.\n",
    "\n",
    "We first find the local components of the domains.\n",
    "This is done by first finding the connected components of the spatial graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.gr.connected_components(adata, cluster_key='spatial_domain_18', min_cells=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hackfix: squidpy's spatial_scatter has some issues with categorical data with NaNs.\n",
    "adata.obs['component_tmp'] = adata.obs['component'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'component_tmp_colors' in adata.uns:\n",
    "    del adata.uns['component_tmp_colors']\n",
    "\n",
    "sq.pl.spatial_scatter(\n",
    "    adata[(adata.obs['sample'].isin(['TgCRND8_17_9', 'TgCRND8_2_5']))], \n",
    "    shape=None, \n",
    "    library_key='sample', \n",
    "    color=[\"component_tmp\", \"spatial_domain_18\"], \n",
    "    size=1,\n",
    "    figsize=(10,10),\n",
    "    title=np.repeat(['TgCRND8_17_9', 'TgCRND8_2_5'], 2),\n",
    "    ncols=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then draw a boundary around every component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.tl.boundaries(adata, alpha_start=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellcharter_utils import plot_boundaries, plot_shape_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boundaries(adata, sample='wildtype_5_7', show_cells=True, cells_radius=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, by computing some shape metrics that we will use to compare the domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.tl.curl(adata)\n",
    "cc.tl.linearity(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the shape metrics of one of the cortex layers, domain 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_shape_metrics(adata, cluster_key='spatial_domain_18', figsize=(6,3), cluster_id=8, metrics=['curl', 'linearity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">**Task 7:** Look at the spatial domain 0.</span><br>\n",
    "<span style=\"color: red;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Is it going to have lower, same or higher linearity than domain 8?</span><br>\n",
    "<span style=\"color: red;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- What about curl?</span>\n",
    "\n",
    "<span style=\"color: red;\">After you have answered, plot the shape metrics for domain 0 and check if it matches your expectations.</span>\n",
    "\n",
    "Tip: you can pass multiple cluster ids to `plot_shape_metrics` in the form of a list to plot multiple domains at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">**Task 8:** Look at spatial domain 12.</span><br>\n",
    "<span style=\"color: red;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- What do you expect to see in terms of curl and linearity?</span><br>\n",
    "<span style=\"color: red;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- What about elongation?</span>\n",
    "\n",
    "<span style=\"color: red;\">After answering, compute the elongation and compare the shape metrics for domains 8 and 12.</span>\n",
    "\n",
    "You can check [CellCharter's documentation](https://cellcharter.readthedocs.io/en/latest/tools.html) for the elongation metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. BANKSY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are using the Python implementation of [BANSKY](https://github.com/prabhakarlab/Banksy_py). \n",
    "\n",
    "Let's reload the data to restore the original version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(Path(PATH, 'xenium_mouse_ad_annotated_rotated.h5ad'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run BANKSY on a example section, select a section that you find interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_section = adata[(adata.obs['time'] == '5_7') & (adata.obs['condition'] == 'wildtype')]\n",
    "adata_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_section.obsm['spatial'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add x and y coordinate to .obs (needed for plot later)\n",
    "adata_section.obs['x'] = adata_section.obsm['spatial'][:, 0]\n",
    "adata_section.obs['y'] = adata_section.obsm['spatial'][:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from banksy_utils.load_data import load_adata, display_adata\n",
    "\n",
    "from banksy_utils.filter_utils import normalize_total, filter_hvg, print_max_min\n",
    "\n",
    "# Normalizes the AnnData object\n",
    "adata_section = normalize_total(adata_section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BANSKY unifies spatially informed cell type and domain segmentation. In this notebook we will focus on the domain segmentation part. \n",
    "\n",
    "![../figures/BANKSY_fig1A.png](../figures/BANKSY_fig1A.png)\n",
    "\n",
    "The idea is to create a representation of a cell using 1) its own transcriptomic profile (purple) and 2) local microenvironment (red + light pink). The local microenvironment is represented through a pair of spatial kernels that represent the mean gene expression of the local microenvironment (red) and its gradient calculated with the azimuthal Gabor filter (AGF) (light pink). \n",
    "\n",
    "The relative contribution of the microenvironment is captured by $\\lambda$. Smaller settings of $\\lambda$ decrease the influence of the cells within the microenvironment ($\\lambda = 0$ reduces to nonspatial informed clustering). $G(r)$ is a radially symmetric Gaussian kernel that decays from magnitude 1 at distance = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main BANSKY algorithm requires: \n",
    "\n",
    "1. Creating a kNN graph by setting a spatial number of neighbords `num_neighbors` (`k_geom`) parameter. \n",
    "2. Assigning weights to the edges of the conected spatial graph. By default, we use the `gaussian decay` option, where weights decay as a function of distance to the index cell with $\\sigma$ `= sigma`.\n",
    "3. Defining whether to use the Azumithal Gabor Filter kernel (`max_m = 1`) or just the mean expression (`max_m = 0`).\n",
    "\n",
    "First, we set the required parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_keys = ('x', 'y', 'spatial')\n",
    "\n",
    "# set parameters \n",
    "plot_graph_weights = True\n",
    "k_geom = 15 # number of neighbors\n",
    "max_m = 1 # azumithal transform up to kth order\n",
    "nbr_weight_decay = \"scaled_gaussian\" # can also be \"reciprocal\", \"uniform\" or \"ranked\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the $k_{geom}$-NN graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from banksy.main import median_dist_to_nearest_neighbour\n",
    "\n",
    "# Find median distance to closest neighbours, the median distance will be `sigma`\n",
    "nbrs = median_dist_to_nearest_neighbour(adata_section, key = coord_keys[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate spatial weights from distance\n",
    "\n",
    "Here, we generate the spatial weights using the gaussian decay function from the median distance to the k-th nearest neighbours as specified earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from banksy.initialize_banksy import initialize_banksy\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "banksy_dict = initialize_banksy(\n",
    "    adata_section,\n",
    "    coord_keys,\n",
    "    k_geom,\n",
    "    nbr_weight_decay=nbr_weight_decay,\n",
    "    max_m=max_m,\n",
    "    plt_edge_hist=True,\n",
    "    plt_nbr_weights=True,\n",
    "    plt_agf_angles=False, # takes long time to plot\n",
    "    plt_theta=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate BANKSY matrix\n",
    "\n",
    "The BANKSY matrix considers a cells transcriptomic profile and local microenvironment (Figure 1). \n",
    "\n",
    "As mentioned before, $\\lambda$ is a mixing parameter that controls the importance of cells’ own expression and neighborhood expression effects, it takes values from 0, being spatial information not used in the clustering, to 1, giving the maximum importance to the neighborhood expression.\n",
    "\n",
    "o generate the BANKSY matrix, we proceed with the following:\n",
    "\n",
    "1. Matrix multiply sparse CSR weights matrix with cell-gene matrix to get **neighbourhood matrix** and the **AGF matrix** if `max_m > 1`\n",
    "\n",
    "2. Z-score both matrices along **genes**\n",
    "\n",
    "3. Multiply each matrix by a weighting factor $\\lambda$ (We refer to this parameter as lambda in our manuscript and code)\n",
    "\n",
    "4. Concatenate the matrices along the genes dimension in the form -> `horizontal_concat(cell_mat, nbr_mat, agf_mat)`\n",
    "\n",
    "Here, we save all the results in the dictionary (banksy_dict), which contains the results from the subsequent operations for BANKSY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from banksy.embed_banksy import generate_banksy_matrix\n",
    "\n",
    "# The following are the main hyperparameters for BANKSY\n",
    "lambda_list = [0.6] # list of lambda parameters\n",
    "\n",
    "banksy_dict, banksy_matrix = generate_banksy_matrix(adata_section, banksy_dict, lambda_list, max_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from banksy.main import concatenate_all\n",
    "\n",
    "banksy_dict[\"nonspatial\"] = {\n",
    "    # Here we simply append the nonspatial matrix (adata.X) to obtain the nonspatial clustering results\n",
    "    0.0: {\"adata\": concatenate_all([adata_section.X], 0, adata=adata_section), }\n",
    "}\n",
    "\n",
    "print(banksy_dict['nonspatial'][0.0]['adata'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce dimensions of each data matrix\n",
    "\n",
    "We utilize two common methods for dimensionality reduction:\n",
    "\n",
    "1. PCA (using `scikit-learn`), we reduce the size of thematrix from $3 * N_{genes}$ to `pca_dims`. As a default settings, we reduce to 20 dimensions.\n",
    "\n",
    "3. UMAP (`UMAP` package), which we use to visualize expressions of clusters in the umap space (2-D space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define hyperparameters\n",
    "\n",
    "resolutions = [0.1] # clustering resolution for UMAP\n",
    "pca_dims = [20] # Dimensionality in which PCA reduces to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from banksy_utils.umap_pca import pca_umap\n",
    "\n",
    "pca_umap(banksy_dict,\n",
    "         pca_dims = pca_dims,\n",
    "         add_umap = True,\n",
    "         plt_remaining_var = False,\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster cells using a partition algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then cluster cells using the **leiden** algorithm partition methods. Other clustering algorithms include *louvain* (another resolution based clustering algorithm), or *mclust* (a clustering based on gaussian mixture model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from banksy.cluster_methods import run_Leiden_partition\n",
    "seed = 0\n",
    "results_df, max_num_labels = run_Leiden_partition(\n",
    "    banksy_dict,\n",
    "    resolutions,\n",
    "    num_nn = 50,\n",
    "    num_iterations = -1,\n",
    "    partition_seed = seed,\n",
    "    match_labels = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from banksy.plot_banksy import plot_results\n",
    "import time\n",
    "\n",
    "c_map =  'tab20' # specify color map\n",
    "weights_graph =  banksy_dict['scaled_gaussian']['weights'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banksy_path = f'./outputs/banksy_output/' \n",
    "\n",
    "plot_results(\n",
    "    results_df,\n",
    "    weights_graph,\n",
    "    c_map,\n",
    "    match_labels = True,\n",
    "    coord_keys = coord_keys,\n",
    "    max_num_labels  =  max_num_labels, \n",
    "    save_path = os.path.join(banksy_path, 'tmp_png'),\n",
    "    save_fig = True, # save the spatial map of all clusters\n",
    "    save_seperate_fig = True, # save the figure of all clusters plotted seperately\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <div class=\"alert alert-block alert-danger\">\n",
    "    <b>Task:</b> Explore the robustness of BANSKY. \n",
    "    <ol>\n",
    "        <li>What do you expect would happen when we increase <code>k_geom</code> (to 80)?</li>\n",
    "        <li>What would you expect the <b>spatial clusters</b> and <b>cell type composition</b> to look like if we increase <code>lambda=0.99</code>?</li>\n",
    "        <li>How do you expect the <b>spatial clusters</b> and <b>cell type composition</b> to change if <code>lambda</code> is decreasing? Set <code>lambda=0</code> </li>\n",
    "    </ol>\n",
    "</div>\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate Cell Type composition in each Banksy-defined Spatial Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sd_vs_cell_type_composition(res_df,idx):\n",
    "    \"\"\"\n",
    "    Plots the cell type composition as a percentage across different SD (standard deviation) values.\n",
    "    The data is visualized as a stacked bar plot.\n",
    "\n",
    "    Parameters:\n",
    "    - results_df_lambda05: DataFrame containing the data with columns 'labels_scaled_gaussian_pc20_nc0.50_r0.10', 'class', and others.\n",
    "    - idx: string of column of interest in the DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Step 1: Add a 'Count' column to facilitate pivoting (each row contributes a count of 1)\n",
    "    res_df.obs['Count'] = 1\n",
    "\n",
    "    # Step 2: Create a pivot table with SD as the index, cell types as columns, and the sum of counts as values\n",
    "    pivot_df = res_df.obs.pivot_table(\n",
    "        index=idx,  # Group by SD\n",
    "        columns='cell_types',  # Columns represent cell types\n",
    "        values='Count',  # Aggregate the 'Count' column\n",
    "        aggfunc='sum',  # Sum up counts for each combination\n",
    "        fill_value=0  # Fill missing combinations with 0\n",
    "    )\n",
    "\n",
    "    # Ensure SD values are numeric\n",
    "    pivot_df.index = pivot_df.index.astype(float)\n",
    "\n",
    "    # Step 3: Convert counts to percentages for each SD\n",
    "    # Divide each row by the row sum to get percentages, then multiply by 100\n",
    "    pivot_df = pivot_df.div(pivot_df.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Step 4: Set up the plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # Define figure size\n",
    "\n",
    "    # Plot stacked bars\n",
    "    bottom = None  # Keeps track of the cumulative height of the bars\n",
    "    for cell_type in pivot_df.columns:  # Loop through each cell type\n",
    "        ax.bar(\n",
    "            pivot_df.index,  # X-axis: SD values\n",
    "            pivot_df[cell_type],  # Y-axis: Percentages for this cell type\n",
    "            label=cell_type,  # Legend label\n",
    "            bottom=bottom  # Stack on top of previous bars\n",
    "        )\n",
    "        # Update 'bottom' to include the current cell type's values\n",
    "        bottom = pivot_df[cell_type] if bottom is None else bottom + pivot_df[cell_type]\n",
    "\n",
    "    # Step 5: Add labels and title\n",
    "    ax.set_xlabel('SD')  # Label for the x-axis\n",
    "    ax.set_ylabel('Cell Type Composition (%)')  # Label for the y-axis\n",
    "    ax.set_title('SD vs. Cell Type Composition')  # Title of the plot\n",
    "    ax.set_ylim(0, 100)  # Set y-axis limits to [0, 100] to represent percentages\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend(\n",
    "        title=\"Cell Type\",  # Title of the legend\n",
    "        bbox_to_anchor=(1.05, 1),  # Position the legend outside the plot\n",
    "        loc='upper left'  # Align the legend at the upper left corner\n",
    "    )\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    # Step 6: Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[idx]['adata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx='scaled_gaussian_pc20_nc0.60_r0.10'\n",
    "results_df_lambda05 = results_df.loc[idx]['adata']\n",
    "label_idx = f'labels_{idx}'\n",
    "plot_sd_vs_cell_type_composition(results_df_lambda05, label_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare CellCharter vs BANSKY\n",
    "\n",
    "<!-- <div class=\"alert alert-block alert-danger\">\n",
    "    <b>Task:</b> Explore similarities and difference between CellCharter and BANSKY.\n",
    "    <ol>\n",
    "        <li>What are common assumptions that both methods make or rely on?</li>\n",
    "        <li>WWhat advantages or limitations can you find between the methods (e.i. runtime, visualization, spatial domains)?</li>\n",
    "    </ol>\n",
    "</div>\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Varrone, M., Tavernari, D., Santamaria-Martínez, A., Walsh, L. A. & Ciriello, G. CellCharter reveals spatial cell niches associated with tissue remodeling and cell plasticity. Nat Genet 56, 74–84 (2024).\n",
    "\n",
    "[2] Singhal, V. et al. BANKSY unifies cell typing and tissue domain segmentation for scalable spatial omics data analysis. Nat Genet 56, 431–441 (2024).\n",
    "\n",
    "[3] https://github.com/BrainOmicsCourse/BrainOmics2024/tree/main/3_Day3. Last access: 18.12.2024\n",
    "\n",
    "[4] https://github.com/NBISweden/workshop-spatial/blob/main/labs/07b_spatial_domains.ipynb: Last access: 14.01.2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
